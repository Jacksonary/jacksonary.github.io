<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jacksonary&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jacksonary.github.io/"/>
  <updated>2022-11-08T10:04:54.513Z</updated>
  <id>https://jacksonary.github.io/</id>
  
  <author>
    <name>Jacksonary</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python杂记.md</title>
    <link href="https://jacksonary.github.io/posts/276f7e50.html"/>
    <id>https://jacksonary.github.io/posts/276f7e50.html</id>
    <published>2022-09-14T14:06:48.000Z</published>
    <updated>2022-11-08T10:04:54.513Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近被抓壮丁去搞了一个 python 项目，中间记录了一些生产上遇到的一些问题以及翻到的一些资料，当然里面除了 python，也会涉及由此衍生的一些内容。</p></blockquote><p>&emsp;python 基础语法就不扯了，线上一大堆，直接进入主题。win11 平台 cmd 中 python 命令弹出 appStore，解决方式: 删除 winAppStore 的环境变量;<a id="more"></a></p><h2 id="1-python-项目打包"><a href="#1-python-项目打包" class="headerlink" title="1. python 项目打包"></a>1. python 项目打包</h2><p>&emsp;python 打包推私服给其他项目使用，总结步骤如下(在工程目录下操作)：</p><ol><li>安装对应的工具: <code>pip install --upgrade setuptools wheel</code>, 安装推送工具 <code>pip install twine</code></li><li>准备打包必备的一些文件: <code>README.md</code>、<code>LICENSE</code>、<code>setup.py</code>，具体见下面的示例</li><li>打包: <code>python setup.py sdist bdist_wheel</code>，会生成<code>build</code>、<code>dist</code> 2 个目录，核心内容在 dist 目录中</li><li>推送远程仓库，默认推送官方仓库，也可以推送到私服:<ol><li>推送官方仓库: <code>twine upload dist/*</code>, 用户名密码需要<a href="https://pypi.org/" rel="external nofollow noopener noreferrer" target="_blank">注册</a>, 安装自己的依赖需要指定 pip 的源 <code>https://pypi.python.org/simple</code> 来验证;</li><li>推送私服: <code>twine upload dist/* --repository-url https://artifactory.xxx.works/artifactory/api/pypi/pypi-xxx</code>，<font color="red">不要带 <code>/simple</code> 后缀</font>;</li></ol></li><li>若要打包一些非 py 文件，需要在根目录下添加 <code>MANIFEST.in</code>，添加如<code>include requirements.txt</code></li></ol><p>示例文件:</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/free_software_licenses.png" alt="主流开源凭证选择方式"></p><p>LICENSE(mit凭证)，上图来源于网络</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">MIT License</span><br><span class="line"></span><br><span class="line">Copyright (c) [year] [fullname]</span><br><span class="line"></span><br><span class="line">Permission is hereby granted, free of charge, to any person obtaining a copy</span><br><span class="line">of this software and associated documentation files (the &quot;Software&quot;), to deal</span><br><span class="line">in the Software without restriction, including without limitation the rights</span><br><span class="line">to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span><br><span class="line">copies of the Software, and to permit persons to whom the Software is</span><br><span class="line">furnished to do so, subject to the following conditions:</span><br><span class="line"></span><br><span class="line">The above copyright notice and this permission notice shall be included in all</span><br><span class="line">copies or substantial portions of the Software.</span><br><span class="line"></span><br><span class="line">THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span><br><span class="line">IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span><br><span class="line">FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span><br><span class="line">AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span><br><span class="line">LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span><br><span class="line">OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span><br><span class="line">SOFTWARE.</span><br></pre></td></tr></table></figure><p>setup.py</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> setuptools</span><br><span class="line"></span><br><span class="line">setuptools.setup(</span><br><span class="line">    name=<span class="string">'project_demo'</span>,</span><br><span class="line">    version=<span class="string">'1.0.0'</span>,</span><br><span class="line">    author=<span class="string">'jacky'</span>,</span><br><span class="line">    author_email=<span class="string">'xxx@163.com'</span>,</span><br><span class="line">    description=<span class="string">'test python packaging'</span>,</span><br><span class="line">    url=<span class="string">'https://pypi.org/'</span>,</span><br><span class="line">    packages=setuptools.find_packages(),</span><br><span class="line">    python_requires=<span class="string">'&gt;=3.6'</span>,</span><br><span class="line">    <span class="comment"># 安装 lib 时会连带安装此处的依赖，不需要引入依赖方再去安装</span></span><br><span class="line">    install_requires=[</span><br><span class="line">        <span class="string">'beautifulsoup4 == 4.11.1'</span>,</span><br><span class="line">        <span class="string">'bleach == 5.0.1'</span>,</span><br><span class="line">        <span class="string">'bs4 == 0.0.1'</span>,</span><br><span class="line">        <span class="string">'certifi == 2022.6.15'</span>,</span><br><span class="line">        <span class="string">'commonmark == 0.9.1'</span>,</span><br><span class="line">        <span class="string">'docutils == 0.19'</span>,</span><br><span class="line">        <span class="string">'idna == 3.3'</span>,</span><br><span class="line">        <span class="string">'jaraco.classes == 3.2.2'</span>,</span><br><span class="line">        <span class="string">'keyring == 23.9.0'</span>,</span><br><span class="line">        <span class="string">'lxml == 4.9.1'</span>,</span><br><span class="line">        <span class="string">'numpy == 1.19.0'</span>,</span><br><span class="line">        <span class="string">'pkginfo == 1.8.3'</span>,</span><br><span class="line">        <span class="string">'Pygments == 2.13.0'</span>,</span><br><span class="line">        <span class="string">'requests == 2.28.1'</span>,</span><br><span class="line">        <span class="string">'rfc3986 == 2.0.0'</span>,</span><br><span class="line">        <span class="string">'rich == 12.5.1'</span>,</span><br><span class="line">        <span class="string">'six == 1.16.0'</span>,</span><br><span class="line">        <span class="string">'soupsieve == 2.3.2.post1'</span>,</span><br><span class="line">        <span class="string">'twine == 4.0.1'</span>,</span><br><span class="line">        <span class="string">'typing_extensions == 4.3.0'</span>,</span><br><span class="line">        <span class="string">'urllib3 == 1.26.12'</span>,</span><br><span class="line">        <span class="string">'webencodings == 0.5.1'</span>,</span><br><span class="line">        <span class="string">'zipp == 3.8.1'</span></span><br><span class="line">    ],</span><br><span class="line">    install_package_data=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>注：<br><a href="https://zhuanlan.zhihu.com/p/460233022" rel="external nofollow noopener noreferrer" target="_blank">打包材料1-setuptools</a><br><a href="https://note.qidong.name/2018/01/python-setup-requires/" rel="external nofollow noopener noreferrer" target="_blank">打包材料-setup-require说明</a><br><a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/" rel="external nofollow noopener noreferrer" target="_blank">打包材料3-官方文档</a><br><a href="https://www.51cto.com/article/621458.html" rel="external nofollow noopener noreferrer" target="_blank">打包材料4-综合打包</a><br><a href="https://www.ruanyifeng.com/blog/2011/05/how_to_choose_free_software_licenses.html" rel="external nofollow noopener noreferrer" target="_blank">开源许可证1</a><br><a href="https://www.gnu.org/licenses/license-list.html" rel="external nofollow noopener noreferrer" target="_blank">开源许可证2</a></p><h2 id="2-依赖管理"><a href="#2-依赖管理" class="headerlink" title="2. 依赖管理"></a>2. 依赖管理</h2><p>&emsp;依赖冲突可以通过 pipdeptree 来排查，<code>pip install pipdeptree</code> 安装依赖树依赖，查看依赖树指令 <code>pipdeptree</code>。这次项目中使用 poetry 来做依赖的管理。</p><h3 id="1-poetry"><a href="#1-poetry" class="headerlink" title="1. poetry"></a>1. poetry</h3><p>&emsp;使用 poetry 管理 python 依赖，先安装 poetry:</p><ol><li>配置 poetry 安装目录: 添加环境变量 <code>POETRY_HOME=D:\ProgramFiles\Python\Poetry</code>，自定义安装必要的步骤，默认安装路径可以跳过;</li><li>通过脚本一键安装 <code>curl https://install.python-poetry.org | python</code>，这里会读取1中的环境变量 <code>POETRY_HOME</code> 进行安装;</li><li>配置 poetry 的远程仓库，如<code>poetry config repositories.tuna https://pypi.tuna.tsinghua.edu.cn/simple</code>，国内多个源可以选择：<ol><li><code>https://pypi.tuna.tsinghua.edu.cn/simple</code>(清华源)</li><li><code>https://mirrors.aliyun.com/pypi/simple</code>(阿里源-慢-慎用)</li><li><code>https://pypi.doubanio.com/simple</code>(豆瓣源)</li><li><code>https://mirrors.cloud.tencent.com/pypi/simple</code>(腾讯源-快-主推);</li></ol></li><li>配置 poetry 的缓存目录: <code>poetry config cache-dir &quot;E:\python-local-repo\pypoetry\Cache&quot;</code>，非必要，poetry 创建的虚拟环境和安装的依赖都在这里，需要自定义的话需要配置一下，长期使用建议配置，默认 C 盘；</li></ol><p>&emsp;其中一些必要的指令:</p><ol><li>创建新工程: <code>poetry new poetry-demo</code>;</li><li>初始化已存在的工程: <code>poetry init</code>;</li><li>从项目中读取依赖并安装 <code>poetry install</code>,从<code>pyproject.toml</code>文件中读取依赖;</li><li>使用指定的解释器 <code>poetry env use python3.7</code>,这里的解释器可以使用 python 的绝对路径</li><li>激活虚拟环境的shell <code>poetry shell</code>,此时控制台中操作的就是激活的 python 版本</li><li>查看虚拟环境信息 <code>poetry env info</code></li><li>显示虚拟环境列表 <code>poetry env list</code></li><li>显示虚拟环境绝对路径 <code>poetry env list --full-path</code></li><li>删除虚拟环境 <code>poetry env remove python3.7</code></li><li>查看python版本 <code>poetry run python -V</code></li><li>安装指定版本的依赖 <code>poetry add flask=2.22.0</code>,若不指定版本默认安装最新版本</li><li>卸载依赖包 <code>poetry remove flask</code></li></ol><h3 id="2-pip"><a href="#2-pip" class="headerlink" title="2. pip"></a>2. pip</h3><ol><li>项目中进行本地安装依赖: <code>pip install xxx-x.x.x.tar.gz</code></li><li>使用 pip 安装指定依赖可以指定源: <code>pip install xxx==xxx -i https://xxxx</code></li><li>显示安装的包: <code>pip list</code></li><li>展示当前依赖清单: <code>pip freeze</code></li><li>将当前安装的依赖清单导出到指定文件中: <code>pip freeze &gt; requirements.txt</code></li><li>通过文件批量安装: <code>pip install -r aa.txt</code></li><li>卸载依赖: <code>pip uninstall -y</code></li><li>命令行配置pip 源: <code>pip config set global.index-url https://mirrors.cloud.tencent.com/pypi/simple</code></li><li>命令行配置多个源:<ol><li>主源: <code>pip config set global.index-url https://mirrors.cloud.tencent.com/pypi/simple</code></li><li>备源: <code>pip config set global.extra-index-url &quot;&lt;私服&gt; https://pypi.douban.com/simple https://pypi.tuna.tsinghua.edu.cn/simple https://pypi.python.org/simple&quot;</code></li><li>配置 host: <code>pip config set install.trusted-host &quot;mirrors.cloud.tencent.com &lt;私服&gt; pypi.douban.com pypi.tuna.tsinghua.edu.cn pypi.python.org&quot;</code></li></ol></li><li>配置多个 pip 源，修改用户目录下的 \pip\pip.ini 文件，修改为如下的内容</li></ol><p>pip.ini</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[global]</span></span><br><span class="line"><span class="section">[global]</span></span><br><span class="line"><span class="attr">index-url</span>=https://mirrors.cloud.tencent.com/pypi/simple</span><br><span class="line"></span><br><span class="line"><span class="attr">extra-index-url</span> = </span><br><span class="line">https://pypi.douban.com/simple</span><br><span class="line">https://pypi.tuna.tsinghua.edu.cn/simple/</span><br><span class="line">https://pypi.python.org/simple</span><br><span class="line"></span><br><span class="line"><span class="section">[install]</span></span><br><span class="line"><span class="attr">trusted-host</span> = </span><br><span class="line">mirrors.cloud.tencent.com</span><br><span class="line">pypi.douban.com</span><br><span class="line">pypi.tuna.tsinghua.edu.cn</span><br><span class="line">pypi.python.org</span><br></pre></td></tr></table></figure><h2 id="动态加载"><a href="#动态加载" class="headerlink" title="动态加载"></a>动态加载</h2><ol><li><code>__init__</code>是一个 python 模块的标识，作用很强，初始化和依赖管理可以放到这里:<ol><li><a href="https://www.jianshu.com/p/73f7fbf75183" rel="external nofollow noopener noreferrer" target="_blank">init文件作用</a></li><li><a href="https://zhuanlan.zhihu.com/p/115350758" rel="external nofollow noopener noreferrer" target="_blank">init文件用法</a></li></ol></li><li>动态导入材料:<ol><li><a href="https://blog.csdn.net/py_tester/article/details/102062594" rel="external nofollow noopener noreferrer" target="_blank">材料1</a></li><li><a href="https://blog.51cto.com/u_6315133/3026959?abTest=51cto" rel="external nofollow noopener noreferrer" target="_blank">材料2</a></li></ol></li></ol><p>python 版本符号约定：</p><ol><li><code>==</code>：等于</li><li><code>&gt;</code>：大于版本</li><li><code>&gt;=</code>：大于等于</li><li><code>&lt;</code>：小于版本</li><li><code>&lt;=</code>：小于等于版本</li><li><code>~=</code>：兼容版本，使用任何大于或等于指定版本，但不大于当前发行系列的版本，例如 ~=1.4.3 可以匹配 1.4.3 到 1.4.9，但是不能匹配 1.5.0</li></ol>]]></content>
    
    <summary type="html">
    
      生产环境 python 项目上的一些实操经验
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Python" scheme="https://jacksonary.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus接入</title>
    <link href="https://jacksonary.github.io/posts/f14fb0ce.html"/>
    <id>https://jacksonary.github.io/posts/f14fb0ce.html</id>
    <published>2022-05-13T15:36:05.000Z</published>
    <updated>2022-11-08T09:07:57.367Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;主要记录利用 Prometheus 进行资源监控和告警，监控的资源主要包含 aws 的相关资源：rds、msk、es 等，自有集群资源 Node、Container。之前的同事直接利用 rancher 上的 monitor 插件装了 Prometheus，rancher-monitoring 包含下面几个组件：</p><ul><li>Prometheus</li><li>Grafana</li><li>Alertmanager</li><li>Prometheus Operator</li><li>Prometheus 适配器<a id="more"></a></li></ul><p><a href="https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/alert/prometheus-alert-rule" rel="external nofollow noopener noreferrer" target="_blank">参考文档</a></p><h2 id="1-资源监控"><a href="#1-资源监控" class="headerlink" title="1. 资源监控"></a>1. 资源监控</h2><p>&emsp;K8S 节点的指标由 node-exporter(作为守护 Pod 存在，每个 worknode 存在一个) 提供指标。aws 云上的一些产品指标由中间的 middleware-monitor-cloudwatch-exporter 将指标数据转为 prometheus 可以识别的格式，参考</p><ul><li><a href="https://github.com/prometheus/cloudwatch_exporter" rel="external nofollow noopener noreferrer" target="_blank">CloudWatch Exporter</a></li><li><a href="https://github.com/nerdswords/yet-another-cloudwatch-exporter" rel="external nofollow noopener noreferrer" target="_blank">yet-another-cloudwatch-exporter</a></li></ul><p>向 prometheus 中添加新的 exporter，rancher 仪表盘 -&gt; monitoring -&gt; service monitors，创建即可，示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceMonitor</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">kubectl.kubernetes.io/last-applied-configuration:</span> <span class="string">|</span></span><br><span class="line"><span class="string">      &#123;"apiVersion":"monitoring.coreos.com/v1","kind":"ServiceMonitor","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"app.kubernetes.io/name":"prod-middleware-monitor"&#125;,"name":"prod-middleware-monitor","namespace":"prod"&#125;,"spec":&#123;"endpoints":[&#123;"interval":"60s","path":"/metrics","port":"metrics"&#125;],"jobLabel":"prod-middleware-monitor-job","selector":&#123;"matchLabels":&#123;"app.kubernetes.io/component":"prod-middleware-monitor"&#125;&#125;&#125;&#125;</span></span><br><span class="line"><span class="string"></span><span class="attr">  creationTimestamp:</span> <span class="string">"2021-03-29T06:17:19Z"</span></span><br><span class="line"><span class="attr">  generation:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">prod-middleware-monitor</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prod-middleware-monitor</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">prod</span></span><br><span class="line"><span class="attr">  resourceVersion:</span> <span class="string">"70193748"</span></span><br><span class="line"><span class="attr">  uid:</span> <span class="number">18</span><span class="string">c86981-6ce7-4f5b-bc6c-ca7070f3326d</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  endpoints:</span></span><br><span class="line"><span class="attr">  - interval:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">    port:</span> <span class="string">metrics</span></span><br><span class="line"><span class="attr">  jobLabel:</span> <span class="string">prod-middleware-monitor-job</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line">      <span class="string">app.kubernetes.io/component:</span> <span class="string">prod-middleware-monitor</span></span><br></pre></td></tr></table></figure><h3 id="1-1-aws-资源"><a href="#1-1-aws-资源" class="headerlink" title="1.1 aws 资源"></a>1.1 aws 资源</h3><p>&emsp;aws 上的云上产品有些是提供了 Prometheus 的 exporter, 导出即可，若没有提供支持，尝试通过 cloudwatch 拉取并通过 middleware 进行中转即可。核心是各个参数的含义，这里记录一下之前相关产品参数沟通的结论:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># 1. ES (OpenSearch)相关信息，这里的单位为 MB </span><br><span class="line"># HELP aws_es_free_storage_space_average Help is not implemented yet.</span><br><span class="line"># TYPE aws_es_free_storage_space_average gauge</span><br><span class="line">aws_es_free_storage_space_average&#123;account_id=&quot;143967271279&quot;,dimension_ClientId=&quot;143967271279&quot;,dimension_DomainName=&quot;dev-nebula&quot;,dimension_NodeId=&quot;&quot;,name=&quot;arn:aws-cn:es:cn-north-1:143967271279:domain/dev-nebula&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-nebula&quot;&#125; 459133.0955</span><br><span class="line">aws_es_free_storage_space_average&#123;account_id=&quot;143967271279&quot;,dimension_ClientId=&quot;143967271279&quot;,dimension_DomainName=&quot;dev-nebula&quot;,dimension_NodeId=&quot;F-ccw1XvQVmGlda5VA_v2Q&quot;,name=&quot;arn:aws-cn:es:cn-north-1:143967271279:domain/dev-nebula&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-nebula&quot;&#125; 459158.25</span><br><span class="line">aws_es_free_storage_space_average&#123;account_id=&quot;143967271279&quot;,dimension_ClientId=&quot;143967271279&quot;,dimension_DomainName=&quot;dev-nebula&quot;,dimension_NodeId=&quot;tZP11VOVT7OpYIH2Miu3Eg&quot;,name=&quot;arn:aws-cn:es:cn-north-1:143967271279:domain/dev-nebula&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-nebula&quot;&#125; 459107.941</span><br><span class="line"># HELP aws_es_info Help is not implemented yet.</span><br><span class="line"># TYPE aws_es_info gauge</span><br><span class="line">aws_es_info&#123;name=&quot;arn:aws-cn:es:cn-north-1:143967271279:domain/dev-nebula&quot;,tag_Name=&quot;dev-nebula&quot;&#125; 0</span><br><span class="line"></span><br><span class="line"># 2. lambda 相关信息</span><br><span class="line"># HELP aws_lambda_concurrent_executions_average Help is not implemented yet.</span><br><span class="line"># TYPE aws_lambda_concurrent_executions_average gauge</span><br><span class="line">aws_lambda_concurrent_executions_average&#123;account_id=&quot;143967271279&quot;,dimension_FunctionName=&quot;&quot;,dimension_Resource=&quot;&quot;,name=&quot;global&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;&quot;&#125; 1.3246753246753247</span><br><span class="line"># HELP aws_lambda_info Help is not implemented yet.</span><br><span class="line"># TYPE aws_lambda_info gauge</span><br><span class="line">aws_lambda_info&#123;name=&quot;arn:aws-cn:lambda:cn-north-1:143967271279:function:dev-galactic-telemetry-streaming-emit-lambda&quot;,tag_Name=&quot;dev-galactic-telemetry-streaming-emit-lambda&quot;,tag_Team=&quot;m56&quot;&#125; 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 3. RDS 相关信息，转换关系不是 1024，而是 1000 计算</span><br><span class="line"># HELP aws_rds_free_storage_space_average Help is not implemented yet.</span><br><span class="line"># TYPE aws_rds_free_storage_space_average gauge</span><br><span class="line">aws_rds_free_storage_space_average&#123;account_id=&quot;143967271279&quot;,dimension_DBInstanceIdentifier=&quot;&quot;,dimension_DatabaseClass=&quot;&quot;,dimension_EngineName=&quot;&quot;,name=&quot;global&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;&quot;&#125; 1.2374417408e+10</span><br><span class="line">aws_rds_free_storage_space_average&#123;account_id=&quot;143967271279&quot;,dimension_DBInstanceIdentifier=&quot;&quot;,dimension_DatabaseClass=&quot;&quot;,dimension_EngineName=&quot;mysql&quot;,name=&quot;global&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;&quot;&#125; 1.2374417408e+10</span><br><span class="line">aws_rds_free_storage_space_average&#123;account_id=&quot;143967271279&quot;,dimension_DBInstanceIdentifier=&quot;&quot;,dimension_DatabaseClass=&quot;db.t2.medium&quot;,dimension_EngineName=&quot;&quot;,name=&quot;global&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;&quot;&#125; 1.2374417408e+10</span><br><span class="line">aws_rds_free_storage_space_average&#123;account_id=&quot;143967271279&quot;,dimension_DBInstanceIdentifier=&quot;dev-nebula&quot;,dimension_DatabaseClass=&quot;&quot;,dimension_EngineName=&quot;&quot;,name=&quot;arn:aws-cn:rds:cn-north-1:143967271279:db:dev-nebula&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-nebula&quot;&#125; 1.3245227008e+10</span><br><span class="line"># HELP aws_rds_info Help is not implemented yet.</span><br><span class="line"># TYPE aws_rds_info gauge</span><br><span class="line">aws_rds_info&#123;name=&quot;arn:aws-cn:rds:cn-north-1:143967271279:db:dev-nebula&quot;,tag_Name=&quot;dev-nebula&quot;,tag_workload_type=&quot;其他&quot;&#125; 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 4. SQS 相关信息</span><br><span class="line"># HELP aws_sqs_approximate_number_of_messages_not_visible_average Help is not implemented yet.</span><br><span class="line"># TYPE aws_sqs_approximate_number_of_messages_not_visible_average gauge</span><br><span class="line">aws_sqs_approximate_number_of_messages_not_visible_average&#123;account_id=&quot;143967271279&quot;,dimension_QueueName=&quot;dev-sqs-queue-galactic-device-event-tucana&quot;,name=&quot;arn:aws-cn:sqs:cn-north-1:143967271279:dev-sqs-queue-galactic-device-event-tucana&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-sqs-queue-galactic-device-event-tucana&quot;&#125; NaN</span><br><span class="line">aws_sqs_approximate_number_of_messages_not_visible_average&#123;account_id=&quot;143967271279&quot;,dimension_QueueName=&quot;dev-sqs-queue-galactic-device-warning-tucana&quot;,name=&quot;arn:aws-cn:sqs:cn-north-1:143967271279:dev-sqs-queue-galactic-device-warning-tucana&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-sqs-queue-galactic-device-warning-tucana&quot;&#125; NaN</span><br><span class="line"># HELP aws_sqs_approximate_number_of_messages_visible_average Help is not implemented yet.</span><br><span class="line"># TYPE aws_sqs_approximate_number_of_messages_visible_average gauge</span><br><span class="line">aws_sqs_approximate_number_of_messages_visible_average&#123;account_id=&quot;143967271279&quot;,dimension_QueueName=&quot;dev-sqs-queue-galactic-device-event-tucana&quot;,name=&quot;arn:aws-cn:sqs:cn-north-1:143967271279:dev-sqs-queue-galactic-device-event-tucana&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-sqs-queue-galactic-device-event-tucana&quot;&#125; NaN</span><br><span class="line">aws_sqs_approximate_number_of_messages_visible_average&#123;account_id=&quot;143967271279&quot;,dimension_QueueName=&quot;dev-sqs-queue-galactic-device-warning-tucana&quot;,name=&quot;arn:aws-cn:sqs:cn-north-1:143967271279:dev-sqs-queue-galactic-device-warning-tucana&quot;,region=&quot;cn-north-1&quot;,tag_Name=&quot;dev-sqs-queue-galactic-device-warning-tucana&quot;&#125; NaN</span><br><span class="line"># HELP aws_sqs_info Help is not implemented yet.</span><br><span class="line"># TYPE aws_sqs_info gauge</span><br><span class="line">aws_sqs_info&#123;name=&quot;arn:aws-cn:sqs:cn-north-1:143967271279:dev-sqs-queue-galactic-device-event-tucana&quot;,tag_Name=&quot;dev-sqs-queue-galactic-device-event-tucana&quot;&#125; 0</span><br><span class="line">aws_sqs_info&#123;name=&quot;arn:aws-cn:sqs:cn-north-1:143967271279:dev-sqs-queue-galactic-device-warning-tucana&quot;,tag_Name=&quot;dev-sqs-queue-galactic-device-warning-tucana&quot;&#125; 0</span><br><span class="line"></span><br><span class="line"># 5. cloudwatch 相关信息</span><br><span class="line"># HELP yace_cloudwatch_apigatewayapi_requests_total</span><br></pre></td></tr></table></figure><p>aws 的 msk 通过提供了<a href="https://docs.amazonaws.cn/msk/latest/developerguide/metrics-details.html" rel="external nofollow noopener noreferrer" target="_blank">Prometheus 支持</a>，手动开启即可（无需通过 cloud-watcher-explorter 进行中转），注意这里提供了2个端口，核心关注的信息在 1102 端口，端口信息如下：</p><ul><li>11001：上使用 JMX MBean 名称提供消费者滞后指标kafka.consumer.group:type=ConsumerLagMetrics</li><li>11002：端口中获取代理的 CPU 和磁盘指标。</li></ul><p>MSK 需要在集群监控配置的中开启 prometheus 指标的开关（操作-&gt; 编辑监控 -&gt; 开启prometheus 和 export），IP可以直接 ping kafka 来获取。msk(kafka) 指标示例，对应的 service monitor 为 dev-msk-monitor，指标示例到 prometheus 中的 targets 端点查看。</p><p>1101 核心信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kafka_server_FetcherLagMetrics_Value&#123;name=&quot;ConsumerLag&quot;,clientId=&quot;ReplicaFetcherThread-1-2&quot;,topic=&quot;DLQ_TEST.DLT&quot;,partition=&quot;1&quot;,&#125; 0.0</span><br><span class="line">kafka_server_FetcherLagMetrics_Value&#123;name=&quot;ConsumerLag&quot;,clientId=&quot;ReplicaFetcherThread-1-2&quot;,topic=&quot;__consumer_offsets&quot;,partition=&quot;30&quot;,&#125; 0.0</span><br><span class="line">kafka_server_FetcherLagMetrics_Value&#123;name=&quot;ConsumerLag&quot;,clientId=&quot;ReplicaFetcherThread-1-2&quot;,topic=&quot;crux.message.jt808.device-message&quot;,partition=&quot;0&quot;,&#125; 0.0</span><br><span class="line">kafka_server_FetcherLagMetrics_Value&#123;name=&quot;ConsumerLag&quot;,clientId=&quot;ReplicaFetcherThread-1-2&quot;,topic=&quot;__amazon_msk_canary&quot;,partition=&quot;0&quot;,&#125; 0.0</span><br><span class="line">kafka_server_FetcherLagMetrics_Value&#123;name=&quot;ConsumerLag&quot;,clientId=&quot;ReplicaFetcherThread-0-2&quot;,topic=&quot;crux.message.jt808.transaction-message&quot;,partition=&quot;9&quot;,&#125; 0.0</span><br></pre></td></tr></table></figure><p>1102 核心信息（磁盘参数监控：node_filesystem_avail_bytes 单位是 Bytes 字节）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># HELP node_exporter_build_info A metric with a constant &apos;1&apos; value labeled by version, revision, branch, and goversion from which node_exporter was built.</span><br><span class="line"># TYPE node_exporter_build_info gauge</span><br><span class="line">node_exporter_build_info&#123;branch=&quot;&quot;,goversion=&quot;go1.14.3&quot;,revision=&quot;&quot;,version=&quot;&quot;&#125; 1</span><br><span class="line"># HELP node_filesystem_avail_bytes Filesystem space available to non-root users in bytes.</span><br><span class="line"># TYPE node_filesystem_avail_bytes gauge  |  非root用户的Filesystem space available</span><br><span class="line">node_filesystem_avail_bytes&#123;device=&quot;/dev/nvme1n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/applogs&quot;&#125; 9.8121445376e+10            98121445376 = 91.38G</span><br><span class="line">node_filesystem_avail_bytes&#123;device=&quot;/dev/nvme2n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/datalogs&quot;&#125; 1.0137837568e+11           101378375680 = 94.41G</span><br><span class="line"></span><br><span class="line"># HELP node_filesystem_device_error Whether an error occurred while getting statistics for the given device.</span><br><span class="line"># TYPE node_filesystem_device_error gauge</span><br><span class="line">node_filesystem_device_error&#123;device=&quot;/dev/nvme1n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/applogs&quot;&#125; 0</span><br><span class="line">node_filesystem_device_error&#123;device=&quot;/dev/nvme2n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/datalogs&quot;&#125; 0</span><br><span class="line"></span><br><span class="line"># HELP node_filesystem_files Filesystem total file nodes.</span><br><span class="line"># TYPE node_filesystem_files gauge</span><br><span class="line">node_filesystem_files&#123;device=&quot;/dev/nvme1n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/applogs&quot;&#125; 6.5536e+06                  6553600</span><br><span class="line">node_filesystem_files&#123;device=&quot;/dev/nvme2n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/datalogs&quot;&#125; 6.619136e+06             6619136</span><br><span class="line"># HELP node_filesystem_files_free Filesystem total free file nodes.</span><br><span class="line"># TYPE node_filesystem_files_free gauge</span><br><span class="line">node_filesystem_files_free&#123;device=&quot;/dev/nvme1n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/applogs&quot;&#125; 6.553571e+06        6553571</span><br><span class="line">node_filesystem_files_free&#123;device=&quot;/dev/nvme2n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/datalogs&quot;&#125; 6.617966e+06       6617966</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># HELP node_filesystem_free_bytes Filesystem free space in bytes.</span><br><span class="line"># TYPE node_filesystem_free_bytes gauge  |  Filesystem free space in bytes，包含了所有用户</span><br><span class="line">node_filesystem_free_bytes&#123;device=&quot;/dev/nvme1n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/applogs&quot;&#125; 1.03506931712e+11         103506931712 = 96.398G</span><br><span class="line">node_filesystem_free_bytes&#123;device=&quot;/dev/nvme2n1&quot;,fstype=&quot;&quot;,mountpoint=&quot;/kafka/datalogs&quot;&#125; 1.05743695872e+11        105743695872=98.48G</span><br></pre></td></tr></table></figure><h3 id="1-2-集群资源"><a href="#1-2-集群资源" class="headerlink" title="1.2 集群资源"></a>1.2 集群资源</h3><p>&emsp;容器内部的运行指标，使用 CAdvisor，详细指标说明在<a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md" rel="external nofollow noopener noreferrer" target="_blank">github</a>。下面是一些CAdvisor中获取到的典型监控指标：</p><table><thead><tr><th>指标名称</th><th>类型</th><th>含义</th></tr></thead><tbody><tr><td>container_cpu_load_average_10s</td><td>gauge</td><td>过去10秒容器CPU的平均负载</td></tr><tr><td>container_cpu_usage_seconds_total</td><td>counter</td><td>容器在每个CPU内核上的累积占用时间 (单位：秒)</td></tr><tr><td>container_cpu_system_seconds_total</td><td>counter</td><td>System CPU累积占用时间（单位：秒）</td></tr><tr><td>container_cpu_user_seconds_total</td><td>counter</td><td>User CPU累积占用时间（单位：秒）</td></tr><tr><td>container_fs_usage_bytes</td><td>gauge</td><td>容器中文件系统的使用量(单位：字节)</td></tr><tr><td>container_fs_limit_bytes</td><td>gauge</td><td>容器可以使用的文件系统总量(单位：字节)</td></tr><tr><td>container_fs_reads_bytes_total</td><td>counter</td><td>容器累积读取数据的总量(单位：字节)</td></tr><tr><td>container_fs_writes_bytes_total</td><td>counter</td><td>容器累积写入数据的总量(单位：字节)</td></tr><tr><td>container_memory_max_usage_bytes</td><td>gauge</td><td>容器的最大内存使用量（单位：字节）</td></tr><tr><td>container_memory_usage_bytes</td><td>gauge</td><td>容器当前的内存使用量（单位：字节</td></tr><tr><td>container_spec_memory_limit_bytes</td><td>gauge</td><td>容器的内存使用量限制</td></tr><tr><td>machine_memory_bytes</td><td>gauge</td><td>当前主机的内存总量</td></tr><tr><td>container_network_receive_bytes_total</td><td>counter</td><td>容器网络累积接收数据总量（单位：字节）</td></tr><tr><td>container_network_transmit_bytes_total</td><td>counter</td><td>容器网络累积传输数据总量（单位：字节）</td></tr></tbody></table><p>参考 <a href="http://www.xuyasong.com/?p=1717#i" rel="external nofollow noopener noreferrer" target="_blank">cadvisor指标说明</a></p><p>容器监控指标：<code>container_memory_usage_bytes{namespace=&quot;dev&quot;,pod=~&quot;.*(app).*&quot;,container!=&quot;POD&quot;,container!=&quot;istio-proxy&quot;}/container_spec_memory_limit_bytes</code></p><h2 id="2-告警"><a href="#2-告警" class="headerlink" title="2. 告警"></a>2. 告警</h2><p>&emsp;利用 Prometheus 可以配置一些规则进行告警，通过 webhook 或者自建告警中心来发送到指定工作群，这里记录一下核心操作内容。<br>告警：rules -&gt; route -&gt; receiver，需要自定义规则</p><p>route 配置（注：这里是正则，使用统一的前缀进行通知）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  receiver:</span> <span class="string">weiguo</span></span><br><span class="line"><span class="attr">  group_by:</span></span><br><span class="line"><span class="attr">  group_wait:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">  group_interval:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">  repeat_interval:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  match:</span></span><br><span class="line">    <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">  match_re:</span></span><br><span class="line"><span class="attr">    alertname:</span> <span class="string">^(hhu_).*</span></span><br></pre></td></tr></table></figure><p>receiver 配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">weiguo</span></span><br><span class="line"><span class="attr">  email_configs:</span></span><br><span class="line"><span class="comment">#    - to: string</span></span><br><span class="line"><span class="comment">#      send_resolved: boolean</span></span><br><span class="line"><span class="comment">#      from: string</span></span><br><span class="line"><span class="comment">#      smarthost: string</span></span><br><span class="line"><span class="comment">#      require_tls: boolean</span></span><br><span class="line"><span class="comment">#      auth_username: string</span></span><br><span class="line"><span class="comment">#      auth_password: string</span></span><br><span class="line"><span class="attr">  slack_configs:</span></span><br><span class="line"><span class="comment">#    - text: string</span></span><br><span class="line"><span class="comment">#      api_url: string</span></span><br><span class="line"><span class="comment">#      channel: string</span></span><br><span class="line"><span class="comment">#      http_config:</span></span><br><span class="line"><span class="comment">#        proxy_url: string</span></span><br><span class="line"><span class="comment">#      send_resolved: boolean</span></span><br><span class="line"><span class="attr">  pagerduty_configs:</span></span><br><span class="line"><span class="comment">#    - routing_key: string</span></span><br><span class="line"><span class="comment">#      service_key: string</span></span><br><span class="line"><span class="comment">#      http_config:</span></span><br><span class="line"><span class="comment">#        proxy_url: string</span></span><br><span class="line"><span class="comment">#      send_resolved: boolean</span></span><br><span class="line"><span class="attr">  opsgenie_configs:</span></span><br><span class="line"><span class="comment">#    - api_key: string</span></span><br><span class="line"><span class="comment">#      http_config:</span></span><br><span class="line"><span class="comment">#        proxy_url: string</span></span><br><span class="line"><span class="comment">#      send_resolved: boolean</span></span><br><span class="line"><span class="comment">#      responders:</span></span><br><span class="line"><span class="comment">#        - type: string</span></span><br><span class="line"><span class="comment">#          id: string</span></span><br><span class="line"><span class="comment">#          name: string</span></span><br><span class="line"><span class="comment">#          username: string</span></span><br><span class="line"><span class="attr">  webhook_configs:</span></span><br><span class="line"><span class="attr">    - http_config:</span></span><br><span class="line"><span class="attr">        tls_config:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">      send_resolved:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">      url:</span> <span class="string">'http://10.8.117.26:8081/other/cat_alarms/prometheus_alert'</span></span><br><span class="line"><span class="comment">#    - url: string</span></span><br><span class="line"><span class="comment">#      http_config:</span></span><br><span class="line"><span class="comment">#        proxy_url: string</span></span><br><span class="line"><span class="comment">#      send_resolved: boolean</span></span><br></pre></td></tr></table></figure><p>dev 告警规则（注意 min 函数的使用），注这里可以通过 <code></code> 变量获取 promQL 的结果值，会有科学计数法，注意转换，还可以使用变量 <code></code> 获取命中的那条记录，同样可以通过 <code></code> 获取指定属性值。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PrometheusRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line"><span class="attr">    prometheus-operator-validated:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">aws-resource</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cattle-monitoring-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  groups:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">aws-resource.rules</span></span><br><span class="line"><span class="attr">    rules:</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_rds</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'rds_dev 可用空间不足 20G，实例: <span class="template-variable">&#123;&#123;$labels.dimension_DBInstanceIdentifier&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[rds_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">aws_rds_free_storage_space_average&#123;dimension_DBInstanceIdentifier!=''&#125;&lt;20000000000</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_es</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'es_dev 可用空间不足 10G，实例: <span class="template-variable">&#123;&#123;$labels.dimension_DomainName&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[es_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">aws_es_free_storage_space_average&#123;dimension_NodeId=''&#125;&lt;10240</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_msk_lag</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'msk_dev 消息延迟大于 50，主题: <span class="template-variable">&#123;&#123;$labels.topic&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[msk_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">kafka_server_FetcherLagMetrics_Value&gt;50</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_msk_resource</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'msk_dev 磁盘可用容量小于 10G'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[msk_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">min(node_filesystem_avail_bytes&#123;service="dev-msk-node-metrics"&#125;)&lt;107374182400</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将 msk 和 eks 区分开</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_msk_cpu</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'msk_dev 节点 CPU 使用率 80%，实例: <span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[msk_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="number">1</span><span class="bullet">-avg</span> <span class="string">without</span> <span class="string">(mode,cpu)</span> <span class="string">(rate(node_cpu_seconds_total&#123;mode="idle",service="prod-msk-node-metrics"&#125;[5m]))&gt;0.8</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_eks_memory</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'eks_dev 节点可用内存小于 20%，实例: <span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[eks_memory_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">node_memory_MemAvailable_bytes</span> <span class="string">/</span> <span class="string">node_memory_MemTotal_bytes</span> <span class="string">&lt;</span> <span class="number">0.2</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为了将 eks 和 msk 区分开</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_eks_cpu</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'eks_dev 节点 CPU 使用率 80%，实例: <span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[eks_cpu_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="number">1</span><span class="bullet">-avg</span> <span class="string">without</span> <span class="string">(mode,cpu)</span> <span class="string">(rate(node_cpu_seconds_total&#123;mode="idle",service!="prod-msk-node-metrics"&#125;[5m]))&gt;0.8</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br></pre></td></tr></table></figure><p>java 接入后提供存活检测</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PrometheusRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">field.cattle.io/description:</span> <span class="string">java</span> <span class="string">后端指标监控</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">java-application-alertmanager</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cattle-monitoring-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  groups:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">javaalert.rules</span></span><br><span class="line"><span class="attr">    rules:</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">java_up</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'<span class="template-variable">&#123;&#123; $labels.container &#125;&#125;</span> 应用出现不可用实例: <span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[app_dev 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">up&#123;namespace="dev",container!="istio-proxy"&#125;==0</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">10</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">critical</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 监控容器级别的内存使用，注意使用 container_memory_working_set_bytes</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">java_memory</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'<span class="template-variable">&#123;&#123; $labels.container &#125;&#125;</span> 应用出现内存使用超 95% 实例: <span class="template-variable">&#123;&#123; $labels.pod &#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[app_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">container_memory_working_set_bytes&#123;container!~"(ingress|fluent-bi|istio|POD)(.*)",container!="",namespace="prod"&#125;/container_spec_memory_limit_bytes&#123;container!~"(ingress|fluent-bi|istio|POD)(.*)",container!="",namespace="prod"&#125;&gt;0.9</span> <span class="string">and</span> <span class="string">container_spec_memory_limit_bytes!=0</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">10</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">critical</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 监控容器重启次数</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">java_restart</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'<span class="template-variable">&#123;&#123; $labels.pod &#125;&#125;</span> 过去 1h 内出现重启, 重启次数: <span class="template-variable">&#123;&#123; $value &#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[app_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">ceil(increase(kube_pod_container_status_restarts_total&#123;container!="",container!~"(ingress|fluent-bi|istio|POD)(.*)",namespace="prod"&#125;[1h]))&gt;1</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">critical</span></span><br></pre></td></tr></table></figure><p>Pod 级别的资源监控:</p><p>常用算法:</p><ol><li>cpu使用率: <code>sum by(pod_name) (rate(container_cpu_usage_seconds_total{pod_name=~&quot;$pod_name&quot;}[1m]))</code>，单位%</li><li>mem使用: <code>query = sum by(pod_name) (container_memory_working_set_bytes{pod_name=~&quot;$pod_name&quot;}) / 1048576</code>，单位MiB</li><li>计算容器使用的 cpu: <code>sum(irate(container_cpu_usage_seconds_total{container=&quot;bootes2&quot;}[5m])*100)by(pod)/sum(container_spec_cpu_quota{container=&quot;bootes2&quot;}/container_spec_cpu_period{container=&quot;bootes2&quot;})by(pod)</code></li></ol><p>对容器资源监控的参数说明:</p><ul><li>container_spec_cpu_period: 当对容器进行CPU限制时，CFS调度的时间窗口，又称容器CPU的时钟周期通常是100，000微秒;</li><li>container_spec_cpu_quota: 是指容器的使用CPU时间周期总量，如果quota设置的是700,000，就代表该容器可用的CPU时间是7*100,000微秒，通常对应kubernetes的resource.cpu.limits的值;</li><li>container_spec_cpu_share: 是指container使用分配主机CPU相对值，比如share设置的是500m，代表窗口启动时向主机节点申请0.5个CPU，也就是50，000微秒，通常对应kubernetes的resource.cpu.requests的值;</li><li>container_cpu_usage_seconds_total: 统计容器的CPU在一秒内消耗使用率，应注意的是该container所有的CORE;</li><li>container_cpu_system_seconds_total: 统计容器内核态在一秒时间内消耗的CPU;</li><li>container_cpu_user_seconds_total: 统计容器用户态在一秒时间内消耗的CPU;</li><li>kube_pod_container_status_last_terminated_reason: 容器终结的原因</li></ul><p>容器级别的监控:</p><ul><li><a href="https://www.bococ.cn/Prometheus/55.html" rel="external nofollow noopener noreferrer" target="_blank">https://www.bococ.cn/Prometheus/55.html</a></li><li><a href="http://www.xuyasong.com/?p=1781" rel="external nofollow noopener noreferrer" target="_blank">http://www.xuyasong.com/?p=1781</a></li><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/" rel="external nofollow noopener noreferrer" target="_blank">https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/</a></li></ul><p>各个 worker node 节点中容器使用的资源: <code>docker stats</code> (cpu 是指占主机的百分比)，指标属性的含义:</p><ul><li>container_cpu_load_average_10s    gauge    过去 10 秒容器 CPU 的平均负载</li><li>container_cpu_usage_seconds_total    counter    容器在每个 CPU 内核上的累积占用时间 (单位：秒)</li><li>container_cpu_system_seconds_total    counter    System CPU 累积占用时间（单位：秒）</li><li>container_cpu_user_seconds_total    counter    User CPU 累积占用时间（单位：秒）</li><li>container_fs_usage_bytes    gauge    容器中文件系统的使用量 (单位：字节)</li><li>container_fs_limit_bytes    gauge    容器可以使用的文件系统总量 (单位：字节)</li><li>container_fs_reads_bytes_total    counter    容器累积读取数据的总量 (单位：字节)</li><li>container_fs_writes_bytes_total    counter    容器累积写入数据的总量 (单位：字节)</li><li>container_memory_max_usage_bytes    gauge    容器的最大内存使用量（单位：字节）</li><li>container_memory_usage_bytes    gauge    容器当前的内存使用量（单位：字节</li><li>container_spec_memory_limit_bytes    gauge    容器的内存使用量限制</li><li>machine_memory_bytes    gauge    当前主机的内存总量</li><li>container_network_receive_bytes_total    counter    容器网络累积接收数据总量（单位：字节）</li><li>container_network_transmit_bytes_total    counter    容器网络累积传输数据总量（单位：字节）</li></ul><p>监控规则参考：<a href="https://www.yoyoask.com/?p=4548" rel="external nofollow noopener noreferrer" target="_blank">https://www.yoyoask.com/?p=4548</a><br>内存、CPU使用率配置参考 gitlab: <a href="https://docs.gitlab.com/ee/administration/monitoring/prometheus/" rel="external nofollow noopener noreferrer" target="_blank">https://docs.gitlab.com/ee/administration/monitoring/prometheus/</a></p><hr><p>PromQL 语法：<br>参考材料：<a href="https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/promql/prometheus-promql-functions" rel="external nofollow noopener noreferrer" target="_blank">https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/promql/prometheus-promql-functions</a></p><p>注：查询时支持正则，注意使用，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 这里的 pod=~&quot;.*(app).*&quot; 就是正则，注意 ~ 放在引号外面</span><br><span class="line">container_memory_usage_bytes&#123;namespace=&quot;dev&quot;,pod=~&quot;.*(app).*&quot;,container!=&quot;POD&quot;,container!=&quot;istio-proxy&quot;&#125;</span><br></pre></td></tr></table></figure><p>部署的 chart 包需要添加注解（让 serviceMonitor 发现），服务接入需要在部署时打上对应 k8s tag，在 ServiceMonitors 配置文件可以找到，beckend-java-service-monitor，对应的应用的 chart 包 Service 层添加注解：<br><code>app.kubernetes.io/component: beckend-java</code></p><h2 id="3-SpringBoot-应用接入"><a href="#3-SpringBoot-应用接入" class="headerlink" title="3. SpringBoot 应用接入"></a>3. SpringBoot 应用接入</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- springboot 古老版本如 2.1.3 本版需要导入此依赖 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.micrometer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>micrometer-registry-prometheus<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>开启配置 prometheus 格式的数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">management.endpoints.web.exposure.include=health,info,metrics,prometheus</span><br></pre></td></tr></table></figure><p>serviceMonitor配置需要更新 chart 包，所有的都需要打上对应的标签（在service上）</p><p>Prometheus 配置：middleware-monitor(ServiceMonitor)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceMonitor</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">dev-middleware-monitor</span></span><br><span class="line"><span class="attr">  managedFields:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dev-middleware-monitor</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  endpoints:</span></span><br><span class="line"><span class="attr">  - interval:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">    port:</span> <span class="string">metrics</span></span><br><span class="line"><span class="attr">  jobLabel:</span> <span class="string">dev-middleware-monitor-job</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line">      <span class="string">app.kubernetes.io/component:</span> <span class="string">dev-middleware-monitor</span></span><br></pre></td></tr></table></figure><p>dev-msk-monitor</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># msk 是直接从 aws 暴露的端口中取数据，所以先要把这里暴露到集群中</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Endpoints</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prod-msk-jmx-metrics</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">prod-msk-jmx-metrics</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">prod-msk</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">prod</span></span><br><span class="line"><span class="attr">subsets:</span></span><br><span class="line"><span class="attr">  - addresses:</span></span><br><span class="line"><span class="attr">    - ip:</span> <span class="number">10.192</span><span class="number">.0</span><span class="number">.156</span></span><br><span class="line"><span class="attr">      nodeName:</span> <span class="string">b-1.prod-virgo-tel.ga98yl.c4.kafka.cn-north-1.amazonaws.com.cn</span></span><br><span class="line"><span class="attr">    - ip:</span> <span class="number">10.192</span><span class="number">.6</span><span class="number">.191</span></span><br><span class="line"><span class="attr">      nodeName:</span> <span class="string">b-2.prod-virgo-tel.ga98yl.c4.kafka.cn-north-1.amazonaws.com.cn</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">metrics</span></span><br><span class="line"><span class="attr">        port:</span> <span class="number">11001</span></span><br><span class="line"><span class="attr">        protocol:</span> <span class="string">TCP</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">prod-msk-jmx-metrics</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">prod-msk</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prod-msk-jmx-metrics</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">prod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">metrics</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">11001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将上面定义 service 监控起来</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceMonitor</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">dev-msk-monitor</span></span><br><span class="line"><span class="attr">  managedFields:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dev-msk-monitor</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  endpoints:</span></span><br><span class="line"><span class="attr">  - interval:</span> <span class="number">20</span><span class="string">s</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">    port:</span> <span class="string">metrics</span></span><br><span class="line"><span class="attr">  jobLabel:</span> <span class="string">dev-msk-monitor-job</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line">      <span class="string">app.kubernetes.io/component:</span> <span class="string">dev-msk</span></span><br></pre></td></tr></table></figure><p>beckend-java-service-monitor</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceMonitor</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">beckend-java-service-monitor</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">beckend-java-service-monitor</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  endpoints:</span></span><br><span class="line"><span class="attr">  - interval:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/actuator/prometheus</span></span><br><span class="line"><span class="attr">    port:</span> <span class="string">http</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line">      <span class="string">app.kubernetes.io/component:</span> <span class="string">beckend-java</span></span><br></pre></td></tr></table></figure><p>生产环境的配置:</p><ol><li>系统级别的配置</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PrometheusRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">aws-monitoring-resources</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">prod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  groups:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">aws-resource</span></span><br><span class="line"><span class="attr">    rules:</span></span><br><span class="line">    <span class="comment"># rds 磁盘空间</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_rds</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'rds_prod 可用空间不足 20G，实例: <span class="template-variable">&#123;&#123;$labels.dimension_DBInstanceIdentifier&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[rds_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">aws_rds_free_storage_space_average&#123;dimension_DBInstanceIdentifier!=''&#125;&lt;20000000000</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">0</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># es 磁盘空间</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_es</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'es_prod 可用空间不足 20G，实例: <span class="template-variable">&#123;&#123;$labels.dimension_DomainName&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[es_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">aws_es_free_storage_space_average&#123;dimension_NodeId=''&#125;&lt;20480</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># msk: lag + 磁盘空间 + cpu</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_msk_lag</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'msk_prod 消息延迟大于 50，主题: <span class="template-variable">&#123;&#123;$labels.topic&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[msk_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">kafka_server_FetcherLagMetrics_Value&gt;50</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_msk_resource</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">msk_prod</span> <span class="string">磁盘可用容量小于</span> <span class="number">20</span><span class="string">G</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[msk_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">min(node_filesystem_avail_bytes&#123;service="dev-msk-node-metrics"&#125;)&lt;214748364800</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_msk_cpu</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'msk_prod 节点 CPU 使用率 80%，实例: <span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[msk_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="number">1</span><span class="bullet">-avg</span> <span class="string">without</span> <span class="string">(mode,cpu)</span> <span class="string">(rate(node_cpu_seconds_total&#123;mode="idle",service="prod-msk-node-metrics"&#125;[5m]))&gt;0.8</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># eks 内存 + cpu</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_eks_memory</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'eks_prod 节点可用内存小于 10%，实例: <span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[eks_memory_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">node_memory_MemAvailable_bytes</span> <span class="string">/</span> <span class="string">node_memory_MemTotal_bytes</span> <span class="string">&lt;</span> <span class="number">0.1</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">aws_eks_cpu</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'eks_prod 节点 CPU 使用率 95%，实例: <span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[eks_cpu_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="number">1</span><span class="bullet">-avg</span> <span class="string">without</span> <span class="string">(mode,cpu)</span> <span class="string">(rate(node_cpu_seconds_total&#123;mode="idle",service!="prod-msk-node-metrics"&#125;[5m]))&gt;0.95</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br></pre></td></tr></table></figure><ol start="2"><li>应用级别的配置</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PrometheusRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">java-application-alertmanager</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cattle-monitoring-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  groups:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">javaalert.rules</span></span><br><span class="line"><span class="attr">    rules:</span></span><br><span class="line">    <span class="comment"># 容器可用性监控，应用全部上线后放开</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">java_up</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'<span class="template-variable">&#123;&#123; $labels.container &#125;&#125;</span> 应用出现不可用实例: <span class="template-variable">&#123;&#123; $labels.pod &#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[app_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">up&#123;namespace="prod",container!~"(ingress|fluent-bi|istio|POD)(.*)",service!~"(prod-msk)(.*)"&#125;==0</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">warning</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 容器内存监控: 基数为 limit 值</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">java_memory</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'<span class="template-variable">&#123;&#123; $labels.container &#125;&#125;</span> 应用出现内存使用超 95% 实例: <span class="template-variable">&#123;&#123; $labels.pod &#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[app_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">container_memory_working_set_bytes&#123;container!~"(ingress|fluent-bi|istio|POD)(.*)",container!="",namespace="prod"&#125;/container_spec_memory_limit_bytes&#123;container!~"(ingress|fluent-bi|istio|POD)(.*)",container!="",namespace="prod"&#125;&gt;0.95</span></span><br><span class="line">        <span class="string">and</span> <span class="string">container_spec_memory_limit_bytes!=0</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">critical</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 容器重启监控</span></span><br><span class="line"><span class="attr">    - alert:</span> <span class="string">java_restart</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line"><span class="attr">        description:</span> <span class="string">'<span class="template-variable">&#123;&#123; $labels.pod &#125;&#125;</span> 过去 1h 内出现重启, 重启次数: <span class="template-variable">&#123;&#123; $value &#125;&#125;</span>'</span></span><br><span class="line"><span class="attr">        summary:</span> <span class="string">'[app_prod 告警]'</span></span><br><span class="line"><span class="attr">      expr:</span> <span class="string">ceil(increase(kube_pod_container_status_restarts_total&#123;container!="",container!~"(ingress|fluent-bi|istio|POD)(.*)",namespace="prod"&#125;[1h]))&gt;1</span></span><br><span class="line"><span class="attr">      for:</span> <span class="number">60</span><span class="string">s</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        severity:</span> <span class="string">critical</span></span><br></pre></td></tr></table></figure><h2 id="4-关于-Grafana-自定义画图"><a href="#4-关于-Grafana-自定义画图" class="headerlink" title="4. 关于 Grafana 自定义画图"></a>4. 关于 Grafana 自定义画图</h2><p>&emsp;结合上采集的一些数据，可以利用 grafana 画一些趋势图，下面是几个示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 1.Java 服务的状态（0-挂掉 1-正常），将页面定义的变量 up_status 传入表达式以动态查询</span><br><span class="line">up&#123;namespace=&quot;prod&quot;,container!~&quot;(ingress|fluent-bi|istio|POD)(.*)&quot;,service!~&quot;(prod-supernova-msk)(.*)&quot;&#125;==$&#123;up_status&#125;</span><br><span class="line">Legend 为 &#123;&#123;pod&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 2. 1h 内应用的重启次数</span><br><span class="line">ceil(increase(kube_pod_container_status_restarts_total&#123;container!=&quot;&quot;,container!~&quot;(ingress|fluent-bi|istio|POD)(.*)&quot;,namespace=&quot;prod&quot;&#125;[1h]))</span><br><span class="line">Legend 为 &#123;&#123;pod&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 3. 应用内存百分比，将页面定义的变量 mem_min 传入表达式以动态查询</span><br><span class="line">container_memory_working_set_bytes&#123;container!~&quot;(ingress|fluent-bi|istio|POD)(.*)&quot;,container!=&quot;&quot;,namespace=&quot;prod&quot;&#125;/container_spec_memory_limit_bytes&#123;container!~&quot;(ingress|fluent-bi|istio|POD)(.*)&quot;,container!=&quot;&quot;,namespace=&quot;prod&quot;&#125;*100&gt;=$&#123;mem_min&#125; and container_spec_memory_limit_bytes!=0</span><br><span class="line">Legend 为 &#123;&#123;pod&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 4. aws rds 磁盘剩余空间，单位 G</span><br><span class="line">aws_rds_free_storage_space_average&#123;dimension_DBInstanceIdentifier!=&apos;&apos;&#125;/1000000000</span><br><span class="line">Legend 为 &#123;&#123;dimension_DBInstanceIdentifier&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 5. aws es 的磁盘剩余空间，单位：G</span><br><span class="line">aws_es_free_storage_space_average&#123;dimension_NodeId!=&apos;&apos;&#125;/1024</span><br><span class="line">Legend 为 &#123;&#123;dimension_NodeId&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 6. aws msk 的 cpu 占用百分比</span><br><span class="line">(1-avg without (mode,cpu) (rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;,service=&quot;m56-prod-supernova-msk-node-metrics&quot;&#125;[5m])))*100</span><br><span class="line">Legend 为 &#123;&#123;instance&#125;&#125;</span><br></pre></td></tr></table></figure><p>注：</p><ul><li>Legend 为 ，里面的 pod 是表达式结果中的属性，可以是任意合法的属性</li><li>上面的 <code>${up_status}</code> 是在面板上定义的页面输入的变量值，定义路径：dashboard settings -&gt; variables</li></ul>]]></content>
    
    <summary type="html">
    
      通过 Prometheus 进行通用的监控和告警
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="监控" scheme="https://jacksonary.github.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="Prometheus" scheme="https://jacksonary.github.io/tags/Prometheus/"/>
    
      <category term="告警" scheme="https://jacksonary.github.io/tags/%E5%91%8A%E8%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Cat接入</title>
    <link href="https://jacksonary.github.io/posts/fe6f4908.html"/>
    <id>https://jacksonary.github.io/posts/fe6f4908.html</id>
    <published>2022-03-19T22:34:39.000Z</published>
    <updated>2022-11-08T09:07:57.345Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;最近计划将入美团的 Cat 引入，也确实落地了，简单记录下中间的流程和遇到的各种问题和解决方案，接入流程参考<a href="https://github.com/dianping/cat" rel="external nofollow noopener noreferrer" target="_blank">官网</a>。<a id="more"></a></p><h2 id="1-编译"><a href="#1-编译" class="headerlink" title="1. 编译"></a>1. 编译</h2><p>&emsp;由于在打包 Cat 时，遇到编译报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] Plugin org.unidal.maven.plugins:codegen-maven-plugin:2.5.8 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.unidal.maven.plugins:codeg</span><br><span class="line">en-maven-plugin:jar:2.5.8: Could not transfer artifact org.unidal.maven.plugins:codegen-maven-plugin:pom:2.5.8 from/to unidal.releases (http://unidal.org/nexus/content/repositories/relea</span><br><span class="line">ses/): Transfer failed for http://unidal.org/nexus/content/repositories/releases/org/unidal/maven/plugins/codegen-maven-plugin/2.5.8/codegen-maven-plugin-2.5.8.pom: Unknown host unidal.org -&gt; [Help 1]</span><br></pre></td></tr></table></figure><p>官方仓库没有找到，手动指定：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>central<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Maven2 Central Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">layout</span>&gt;</span>default<span class="tag">&lt;/<span class="name">layout</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo1.maven.org/maven2<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>unidal.releases<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://unidal.org/nexus/content/repositories/releases/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure><p>我当时手动指定也没有用，官方的仓库直接爆了，于是自己手动把 plugin 和 framework 给打包了(┬┬﹏┬┬)，源码地址：</p><ul><li><a href="https://github.com/unidal/maven-plugins" rel="external nofollow noopener noreferrer" target="_blank">unidal-maven-plugins</a></li><li><a href="https://github.com/unidal/frameworks" rel="external nofollow noopener noreferrer" target="_blank">unidal-frameworks</a></li></ul><p>导入将本地打包好的 jar 导入本地仓库:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Plugin org.unidal.maven.plugins:codegen-maven-plugin:2.5.8</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\maven\plugins\codegen-maven-plugin\2.5.8\codegen-maven-plugin-2.5.8.jar -DgroupId=org.unidal.maven.plugins -DartifactId=codegen-maven-plugin -Dversion=2.5.8 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Plugin org.unidal.maven.plugins:plexus-maven-plugin:2.5.8</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\maven\plugins\plexus-maven-plugin\2.5.8\plexus-maven-plugin-2.5.8.jar -DgroupId=org.unidal.maven.plugins -DartifactId=plexus-maven-plugin -Dversion=2.5.8 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. org.unidal.framework:foundation-service:jar:2.5.0</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\framework\foundation-service\2.5.0\foundation-service-2.5.0.jar -DgroupId=org.unidal.framework -DartifactId=foundation-service -Dversion=2.5.0 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. org.unidal.framework:test-framework:jar:2.4.0，缺失升级为 2.5.0</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\framework\<span class="built_in">test</span>-framework\2.5.0\<span class="built_in">test</span>-framework-2.5.0.jar -DgroupId=org.unidal.framework -DartifactId=<span class="built_in">test</span>-framework -Dversion=2.5.0 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. org.unidal.framework:web-framework:pom:2.4.0</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\framework\web-framework\2.4.0\web-framework-2.4.0.jar -DgroupId=org.unidal.framework -DartifactId=web-framework -Dversion=2.4.0 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. org.unidal.webres:WebResServer:1.2.1</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\webres\WebResServer\1.2.1\WebResServer-1.2.1.jar -DgroupId=org.unidal.webres -DartifactId=WebResServer -Dversion=1.2.1 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. org.unidal.webres:web-framework:1.2.1</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\webres\WebResServer\1.2.1\WebResServer-1.2.1.jar -DgroupId=org.unidal.webres -DartifactId=WebResServer -Dversion=1.2.1 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8. org.unidal.framework.dal-jdbc:2.4.0</span></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\org\unidal\framework\dal-jdbc\2.4.0\dal-jdbc-2.4.0.jar -DgroupId=org.unidal.framework -DartifactId=dal-jdbc -Dversion=2.4.0 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line">mvn install:install-file -Dfile=E:\myWork\工作归档\2022\0304_基础设施OPP\cat相关依赖jar\plexus-container-default-2.1.1.jar -DgroupId=org.codehaus.plexus -DartifactId=plexus-container-default -Dversion=3.1.0 -Dpackaging=jar</span><br></pre></td></tr></table></figure><h2 id="2-镜像打包"><a href="#2-镜像打包" class="headerlink" title="2. 镜像打包"></a>2. 镜像打包</h2><p>&emsp;在打包镜像时，WSL2 对 centOS6 兼容问题，出现异常：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error response from daemon: The command &apos;/bin/sh -c yum install -y wget&apos; returned a non-zero code: 139</span><br></pre></td></tr></table></figure><p>可以升级基础镜像到7尝试，cat 需要用到 epoll 功能，2.6内核才可以支持 epoll，Dockerfile 如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># centos6 在 WSL2 有兼容性问题，升级为 7，确保内核支持 epoll</span></span><br><span class="line"><span class="keyword">FROM</span> centos:centos7</span><br><span class="line"></span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"></span><br><span class="line"><span class="comment">#UTILITIES</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash">yum install -y wget</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash">yum install -y tar</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#JAVA (OPENJDK 8)</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_VERSION <span class="number">1.8</span>.<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat</span></span><br><span class="line"><span class="keyword">ENV</span> CAT_HOME /data/appdatas/cat/</span><br><span class="line"></span><br><span class="line"><span class="comment"># java</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/lib/jvm/java</span><br><span class="line"></span><br><span class="line"><span class="comment"># datasource</span></span><br><span class="line"><span class="keyword">ENV</span> MYSQL_URL=localhost</span><br><span class="line"><span class="keyword">ENV</span> MYSQL_PORT=<span class="number">3306</span></span><br><span class="line"><span class="keyword">ENV</span> MYSQL_USERNAME=root</span><br><span class="line"><span class="keyword">ENV</span> MYSQL_PASSWD=root</span><br><span class="line"><span class="keyword">ENV</span> MYSQL_SCHEMA=cat</span><br><span class="line"></span><br><span class="line"><span class="comment">#TOMCAT 8</span></span><br><span class="line"><span class="keyword">ENV</span> CATALINA_HOME /usr/local/tomcat</span><br><span class="line"><span class="keyword">ENV</span> PATH $CATALINA_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">ENV</span> CATALINA_OPTS $CATALINA_OPTS -server -DCAT_HOME=$CAT_HOME -Djava.awt.headless=true -Xms2G -Xmx2G -XX:PermSize=<span class="number">256</span>m -XX:MaxPermSize=<span class="number">256</span>m -XX:NewSize=<span class="number">1014</span>m -XX:MaxNewSize=<span class="number">1014</span>m -XX:SurvivorRatio=<span class="number">10</span> -XX:+UseParNewGC -XX:ParallelGCThreads=<span class="number">4</span> -XX:MaxTenuringThreshold=<span class="number">13</span> -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSFullGCsBeforeCompaction=<span class="number">9</span> -XX:CMSInitiatingOccupancyFraction=<span class="number">60</span> -XX:+CMSClassUnloadingEnabled -XX:SoftRefLRUPolicyMSPerMB=<span class="number">0</span> -XX:-ReduceInitialCardMarks -XX:+CMSPermGenSweepingEnabled -XX:CMSInitiatingPermOccupancyFraction=<span class="number">70</span> -XX:+ExplicitGCInvokesConcurrent -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.EPollSelectorProvider -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationConcurrentTime -XX:+PrintHeapAtGC -Xloggc:/data/applogs/heap_trace.txt -XX:-HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/applogs/HeapDumpOnOutOfMemoryError -Djava.util.Arrays.useLegacyMergeSort=true</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p <span class="string">"<span class="variable">$CATALINA_HOME</span>"</span></span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$CATALINA_HOME</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> TOMCAT_MAJOR_VERSION <span class="number">8</span></span><br><span class="line"><span class="keyword">ENV</span> TOMCAT_MINOR_VERSION <span class="number">8.5</span>.<span class="number">77</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget -q https://archive.apache.org/dist/tomcat/tomcat-<span class="variable">$&#123;TOMCAT_MAJOR_VERSION&#125;</span>/v<span class="variable">$&#123;TOMCAT_MINOR_VERSION&#125;</span>/bin/apache-tomcat-<span class="variable">$&#123;TOMCAT_MINOR_VERSION&#125;</span>.tar.gz &amp;&amp; \</span></span><br><span class="line"><span class="bash">    tar zxf apache-tomcat-*.tar.gz &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mv apache-tomcat-<span class="variable">$&#123;TOMCAT_MINOR_VERSION&#125;</span>/* . &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rm -rf apache-tomcat-*</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> java -version</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> cat-3.0.0.war <span class="variable">$CATALINA_HOME</span>/webapps/cat.war</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/workspace/cat</span></span><br><span class="line"><span class="comment"># 将 datasources.xml 拷贝到 /data/appdatas/cat 目录下</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> datasources.xml /data/appdatas/cat/datasources.xml</span></span><br><span class="line"><span class="comment">#ADD datasources.sh /datasources.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">"s/port=\"8080\"/port=\"8080\"\ URIEncoding=\"utf-8\"/g"</span> <span class="variable">$CATALINA_HOME</span>/conf/server.xml</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">"s/MYSQL_URL/<span class="variable">$&#123;MYSQL_URL&#125;</span>/g;s/MYSQL_PORT/<span class="variable">$&#123;MYSQL_PORT&#125;</span>/g;s/MYSQL_SCHEMA/<span class="variable">$&#123;MYSQL_SCHEMA&#125;</span>/g;s/MYSQL_USERNAME/<span class="variable">$&#123;MYSQL_USERNAME&#125;</span>/g;s/MYSQL_PASSWD/<span class="variable">$&#123;MYSQL_PASSWD&#125;</span>/g"</span> /data/appdatas/cat/datasources.xml</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">'Asia/Shanghai'</span> &gt;/etc/timezone</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$CATALINA_HOME</span>/bin</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./catalina.sh"</span>, <span class="string">"run"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8080</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">2280</span></span><br></pre></td></tr></table></figure><p>K8S 资源:</p><p>cat-home 的配置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cat-home</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cat-monitoring</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-home</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line">      <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-home</span></span><br><span class="line">      <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line">        <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-home</span></span><br><span class="line">        <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">cat-home</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">registry.cn-shanghai.aliyuncs.com/hhu/cat:msg_3.0.0</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          env:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_URL</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"cmiwulmj2qzm.rds.cn-north-1.amazonaws.com.cn"</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_PORT</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"3306"</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_USERNAME</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"cat"</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_PASSWD</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"cat"</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">cat-home-2280</span></span><br><span class="line"><span class="attr">              containerPort:</span> <span class="number">2280</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">cat-home-8080</span></span><br><span class="line"><span class="attr">              containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - mountPath:</span> <span class="string">/data</span></span><br><span class="line"><span class="attr">              name:</span> <span class="string">cat-home-volume</span></span><br><span class="line">            <span class="comment"># - mountPath: /data/appdatas/cat</span></span><br><span class="line">            <span class="comment">#   name: cat-data-config-volume</span></span><br><span class="line">            <span class="comment">#   subPath: datasources.xml</span></span><br><span class="line"><span class="attr">          resources:</span></span><br><span class="line"><span class="attr">            limits:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">2000</span><span class="string">m</span></span><br><span class="line"><span class="attr">              memory:</span> <span class="number">3072</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">            requests:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">              memory:</span> <span class="number">1048</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">cat-home-volume</span></span><br><span class="line"><span class="attr">          awsElasticBlockStore:</span></span><br><span class="line"><span class="attr">            volumeID:</span> <span class="string">"vol-0f52ce7d7597"</span></span><br><span class="line"><span class="attr">            fsType:</span> <span class="string">ext4</span></span><br><span class="line">        <span class="comment"># - name: cat-data-config-volume</span></span><br><span class="line">          <span class="comment"># configMap:</span></span><br><span class="line">            <span class="comment"># defaultMode: 644</span></span><br><span class="line">            <span class="comment"># name: cat-data-config</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">"target"</span></span><br><span class="line"><span class="attr">        operator:</span> <span class="string">"Equal"</span></span><br><span class="line"><span class="attr">        effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"cat"</span></span><br><span class="line"><span class="attr">      nodeSelector:</span></span><br><span class="line"><span class="attr">        target:</span> <span class="string">cat</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cat-home-internal</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cat-monitoring</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-home</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">ClusterIP</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="string">cat-home-8080</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">cat-home-8080</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">2280</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="string">cat-home-2280</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">cat-home-2280</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-home</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cat-home-work</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cat-monitoring</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-home-work</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="string">cat-home-8080</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">cat-home-8080</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-home-work</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br></pre></td></tr></table></figure><p>cat-consumer 配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cat-consumer</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cat-monitoring</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-consumer</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line">      <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-consumer</span></span><br><span class="line">      <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line">        <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-consumer</span></span><br><span class="line">        <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">cat-consumer</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">registry.cn-shanghai.aliyuncs.com/hhu/cat:msg_3.0.0</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">          env:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_URL</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"cmiwulmj2qzm.rds.cn-north-1.amazonaws.com.cn"</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_PORT</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"3306"</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_USERNAME</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"cat"</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">MYSQL_PASSWD</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">"cat"</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">cat-con-2280</span></span><br><span class="line"><span class="attr">              containerPort:</span> <span class="number">2280</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">cat-con-8080</span></span><br><span class="line"><span class="attr">              containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - mountPath:</span> <span class="string">/data</span></span><br><span class="line"><span class="attr">              name:</span> <span class="string">cat-consumer-volume</span></span><br><span class="line">            <span class="comment"># - mountPath: /data/appdatas/cat</span></span><br><span class="line">            <span class="comment">#   name: cat-data-config-volume</span></span><br><span class="line">            <span class="comment">#   subPath: datasources.xml</span></span><br><span class="line"><span class="attr">          resources:</span></span><br><span class="line"><span class="attr">            limits:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">2000</span><span class="string">m</span></span><br><span class="line"><span class="attr">              memory:</span> <span class="number">3072</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">            requests:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">              memory:</span> <span class="number">1048</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">cat-consumer-volume</span></span><br><span class="line"><span class="attr">          awsElasticBlockStore:</span></span><br><span class="line"><span class="attr">            volumeID:</span> <span class="string">"vol-071e06abe61072d70"</span></span><br><span class="line"><span class="attr">            fsType:</span> <span class="string">ext4</span></span><br><span class="line">        <span class="comment"># - name: cat-data-config-volume</span></span><br><span class="line">          <span class="comment"># configMap:</span></span><br><span class="line">            <span class="comment"># defaultMode: 644</span></span><br><span class="line">            <span class="comment"># name: cat-data-config</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">"target"</span></span><br><span class="line"><span class="attr">        operator:</span> <span class="string">"Equal"</span></span><br><span class="line"><span class="attr">        effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"cat"</span></span><br><span class="line"><span class="attr">      nodeSelector:</span></span><br><span class="line"><span class="attr">        target:</span> <span class="string">cat</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cat-consumer-internal</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">cat-monitoring</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-consumer</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">ClusterIP</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="string">cat-con-8080</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">cat-con-8080</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">2280</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="string">cat-con-2280</span></span><br><span class="line"><span class="attr">      protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">cat-con-2280</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">cat-consumer</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">cat</span></span><br></pre></td></tr></table></figure><p>首次启动 cat 后手动创建配置文件 <code>vi /data/appdatas/cat/datasources.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">data-sources</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data-source</span> <span class="attr">id</span>=<span class="string">"cat"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">maximum-pool-size</span>&gt;</span>3<span class="tag">&lt;/<span class="name">maximum-pool-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">connection-timeout</span>&gt;</span>1s<span class="tag">&lt;/<span class="name">connection-timeout</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">idle-timeout</span>&gt;</span>10m<span class="tag">&lt;/<span class="name">idle-timeout</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">statement-cache-size</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">statement-cache-size</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">driver</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">driver</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>&lt;![CDATA[jdbc:mysql://cmiwulmj2qzm.rds.cn-north-1.amazonaws.com.cn:3306/cat]]&gt;<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">user</span>&gt;</span>cat<span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">password</span>&gt;</span>cat<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">connectionProperties</span>&gt;</span>&lt;![CDATA[useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;socketTimeout=120000]]&gt;<span class="tag">&lt;/<span class="name">connectionProperties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data-source</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data-sources</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注：主机区域和卷的区域需要在一个区，否则无法挂载。EBS 有有限，EFS 没有区域限制。</p><p>跨 namespace 通信为: [svc].[namespace]<br>同 namespace 通信为: [svc]</p><p>应用层指定 cat 连接地址应该为 cat-home.cat-monitoring，后面的 consumer 可以指定为 slave…<br>主机需要单独额外添加安全规则，tooffice 来暴露到内网。</p><p>客户端接入，在目录 <code>\data\appdatas\cat</code> 创建对应的 <code>client.xml</code> 文件指定服务端的地址：<br>注: cat 服务端集群内也要放置该文件，否则启动后没有 cat 自身的埋点</p><p>这里是跨 namespace 通信，需要注意，configMap 配置在 dev 的空间中。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">config</span> <span class="attr">mode</span>=<span class="string">"client"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servers</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">server</span> <span class="attr">ip</span>=<span class="string">"cat-home-internal.cat-monitoring"</span> <span class="attr">port</span>=<span class="string">"2280"</span> <span class="attr">http-port</span>=<span class="string">"8080"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">server</span> <span class="attr">ip</span>=<span class="string">"cat-consumer-internal.cat-monitoring"</span> <span class="attr">port</span>=<span class="string">"2280"</span> <span class="attr">http-port</span>=<span class="string">"8080"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">servers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">config</span>&gt;</span></span><br></pre></td></tr></table></figure><p>挂载卷时注意指定 subPath，否则无法写，subPath 指定时，mountPath 必须指定到具体的文件，如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- mountPath:</span> <span class="string">/data/appdatas/cat/client.xml</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cat-client-config</span></span><br><span class="line"><span class="attr">  subPath:</span> <span class="string">client.xml</span></span><br></pre></td></tr></table></figure><h2 id="3-cat-后台登录有时登录不上"><a href="#3-cat-后台登录有时登录不上" class="headerlink" title="3. cat 后台登录有时登录不上"></a>3. cat 后台登录有时登录不上</h2><p>&emsp;部署到 K8S 集群后，cat 的登录出现问题，翻了一下源码，现有的 token 生成规则为 <code>admin|admin|1648865374227|10.192.38.248|142532317</code>，中间会有一个 remote Address 的属性，在 K8S 集群中经过 ingress controller 代理后获取客户端的 ip 是代理的 ip，而且我们集群中有多个代理，所以一旦请求不是经过同一个代理，那2次拿到的 ip 就不一样，cat 在认证 token 是就无法通过，最终返回一个 <code>null</code> 值 Token。这个问题可以理一下 <code>com.dianping.cat.system.page.login.Handler#handleInbound</code> 的流程获取信息，然后进入 <code>com.dianping.cat.system.page.login.service.SigninService#signin</code>，随后设置 Token <code>com.dianping.cat.system.page.login.service.TokenManager#setToken</code>，在 <code>com.dianping.cat.system.page.login.service.TokenBuilder#build</code> 中构建 Token 时获取客户端 ip 使用了 <code>ctx.getRequest().getRemoteAddr()</code>，这里多个代理的情况下就出现问题了，需要改掉，使用下面的工具类替换即可。同时也要替换掉 <code>com.dianping.cat.system.page.login.service.TokenBuilder#parse</code> 中的方法（一样的方式）。重新编译打包即可。解决多个代理无法获取真实客户端ip的问题。目前该问题<a href="https://github.com/dianping/cat/pull/2194" rel="external nofollow noopener noreferrer" target="_blank">PR</a>已被接受，最新版应该不会出现该问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServletRequestUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String UNKNOWN = <span class="string">"unknown"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String X_FORWARDED_FOR = <span class="string">"x-forwarded-for"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PROXY_CLIENT_IP = <span class="string">"Proxy-Client-IP"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String WL_PROXY_CLIENT_IP = <span class="string">"WL-Proxy-Client-IP"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getRemoteAddress</span><span class="params">(HttpServletRequest request)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (request == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> UNKNOWN;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String ip = request.getHeader(X_FORWARDED_FOR);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(ip) || UNKNOWN.equalsIgnoreCase(ip)) &#123;</span><br><span class="line">            ip = request.getHeader(PROXY_CLIENT_IP);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(ip) || UNKNOWN.equalsIgnoreCase(ip)) &#123;</span><br><span class="line">            ip = request.getHeader(WL_PROXY_CLIENT_IP);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(ip) || UNKNOWN.equalsIgnoreCase(ip)) &#123;</span><br><span class="line">            ip = request.getRemoteAddr();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ip;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-客户端无法启动"><a href="#4-客户端无法启动" class="headerlink" title="4. 客户端无法启动"></a>4. 客户端无法启动</h2><p>&emsp;应用接入 client 后报错，启动异常如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">2022-04-02 08:30:27.030 [tucana-vehicle-stats-app] [] [] [1] [main] [ERROR] o.s.boot.SpringApplication - Application run failed</span><br><span class="line">java.lang.NoClassDefFoundError: org/codehaus/plexus/component/repository/exception/ComponentLookupException</span><br><span class="line">at ai.momenta.supernova.tucana.vehiclestats.cat.CatLogbackAppender.append(CatLogbackAppender.java:19)</span><br><span class="line">at ai.momenta.supernova.tucana.vehiclestats.cat.CatLogbackAppender.append(CatLogbackAppender.java:14)</span><br><span class="line">at ch.qos.logback.core.AppenderBase.doAppend(AppenderBase.java:82)</span><br><span class="line">at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51)</span><br><span class="line">at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270)</span><br><span class="line">at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257)</span><br><span class="line">at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421)</span><br><span class="line">at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383)</span><br><span class="line">at ch.qos.logback.classic.Logger.log(Logger.java:765)</span><br><span class="line">at org.apache.commons.logging.LogAdapter$Slf4jLocationAwareLog.info(LogAdapter.java:431)</span><br><span class="line">at org.springframework.boot.SpringApplication.logStartupProfileInfo(SpringApplication.java:648)</span><br><span class="line">at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:371)</span><br><span class="line">at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)</span><br><span class="line">at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215)</span><br><span class="line">at org.springframework.boot.SpringApplication.run(SpringApplication.java:1204)</span><br><span class="line">at ai.momenta.supernova.tucana.vehiclestats.Application.main(Application.java:34)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)</span><br><span class="line">at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)</span><br><span class="line">at org.springframework.boot.loader.Launcher.launch(Launcher.java:51)</span><br><span class="line">at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:52)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.codehaus.plexus.component.repository.exception.ComponentLookupException</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:382)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:418)</span><br><span class="line">at org.springframework.boot.loader.LaunchedURLClassLoader.loadClass(LaunchedURLClassLoader.java:93)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:351)</span><br><span class="line">... 24 common frames omitted</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.reflect.InvocationTargetException</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)</span><br><span class="line">at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)</span><br><span class="line">at org.springframework.boot.loader.Launcher.launch(Launcher.java:51)</span><br><span class="line">at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:52)</span><br><span class="line">Caused by: java.lang.NoClassDefFoundError: org/codehaus/plexus/component/repository/exception/ComponentLookupException</span><br><span class="line">at ai.momenta.supernova.tucana.vehiclestats.cat.CatLogbackAppender.append(CatLogbackAppender.java:19)</span><br><span class="line">at ai.momenta.supernova.tucana.vehiclestats.cat.CatLogbackAppender.append(CatLogbackAppender.java:14)</span><br><span class="line">at ch.qos.logback.core.AppenderBase.doAppend(AppenderBase.java:82)</span><br><span class="line">at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51)</span><br><span class="line">at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270)</span><br><span class="line">at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257)</span><br><span class="line">at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421)</span><br><span class="line">at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383)</span><br><span class="line">at ch.qos.logback.classic.Logger.log(Logger.java:765)</span><br><span class="line">at org.apache.commons.logging.LogAdapter$Slf4jLocationAwareLog.error(LogAdapter.java:410)</span><br><span class="line">at org.springframework.boot.SpringApplication.reportFailure(SpringApplication.java:823)</span><br><span class="line">at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:798)</span><br><span class="line">at org.springframework.boot.SpringApplication.run(SpringApplication.java:322)</span><br><span class="line">at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215)</span><br><span class="line">at org.springframework.boot.SpringApplication.run(SpringApplication.java:1204)</span><br><span class="line">at ai.momenta.supernova.tucana.vehiclestats.Application.main(Application.java:34)</span><br><span class="line">... 8 more</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.codehaus.plexus.component.repository.exception.ComponentLookupException</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:382)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:418)</span><br><span class="line">at org.springframework.boot.loader.LaunchedURLClassLoader.loadClass(LaunchedURLClassLoader.java:93)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:351)</span><br><span class="line">... 24 more</span><br></pre></td></tr></table></figure><p>本地启动没有问题，然后尝试将本地 maven 库中的 cat-client 删除重新进入 cat-client 目录进行打包发现报错了，但如果在 cat 根目录下打包安装，嗳，它不报错了。注：在根目录下打包。</p>]]></content>
    
    <summary type="html">
    
      美团 Cat 监控中心接入的案例
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Cat" scheme="https://jacksonary.github.io/tags/Cat/"/>
    
      <category term="监控" scheme="https://jacksonary.github.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>Docker轻量化经验</title>
    <link href="https://jacksonary.github.io/posts/4e05cb2c.html"/>
    <id>https://jacksonary.github.io/posts/4e05cb2c.html</id>
    <published>2022-02-22T15:15:31.000Z</published>
    <updated>2022-11-08T09:07:57.347Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;在打镜像的时候，发现团队某个应用的镜像奇大 &gt;4G，在 agent 上构建时奇慢，尤其是第一次调度到某个未构建过的 agent 上时，无法忍受，于是着手开始优化，应用本身是 python 应用，所以优化时会有些内容是针对 python，但大体通用。本次优化目标是2个：</p><ul><li>加快构建速度</li><li>最小化镜像体积<a id="more"></a>&emsp;大体从两个方向入手，一个是 layer 的层数，另一个是 layer 大小。<a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/" rel="external nofollow noopener noreferrer" target="_blank">官方最佳实践</a>。具体 docker 镜像的分析可以使用 <code>docker history &lt;image-id&gt;</code> 或 <a href="https://github.com/wagoodman/dive" rel="external nofollow noopener noreferrer" target="_blank">dive</a>, 各阶段的优化成果:</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+-------+  -460M   +-------+  -470M   +-------+  -700M   +-------+</span><br><span class="line">| 4.32G | -------&gt; | 3.86G | -------&gt; | 3.39G | -------&gt; | 2.68G |</span><br><span class="line">+-------+          +-------+          +-------+          +-------+</span><br></pre></td></tr></table></figure><h3 id="1-减少-layer-的层数"><a href="#1-减少-layer-的层数" class="headerlink" title="1. 减少 layer 的层数"></a>1. 减少 layer 的层数</h3><p>&emsp;这里我是简单的压缩了 <code>RUN</code> 指令，如下:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原始</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get install gcc automake autoconf build-essential libtool make vim git tree -y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化后：将多个指令通过 &amp;&amp; 压缩到一个 RUN 指令下 </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp;\</span></span><br><span class="line"><span class="bash">    apt-get install gcc automake autoconf build-essential libtool make vim git tree ffmpeg -y --no-install-recommends</span></span><br></pre></td></tr></table></figure><p>在随后的过程中，发现一个 docker 的 squash 特性，它可以开启镜像层的压缩功能，将多个变化的镜像层，压缩成一个新的镜像层，对于我的优化体验还不错，实际可以减小 500M 左右。<a href="https://docs.docker.com/engine/reference/commandline/dockerd/#description" rel="external nofollow noopener noreferrer" target="_blank">开启squash特性</a>，文中提到新特性需要手动启用，这里注意 windows 开启方式不是设置界面上的 Experimental features 进行勾选(┬┬﹏┬┬)，而是在 Docker Engine 中，在配置文件中开启 <code>&quot;experimental&quot;: true</code>，最后打包时带上参数即可 <code>docker build -t &lt;image-name&gt; --squash .</code>。随后又发现了开源工具 <a href="https://github.com/goldmann/docker-squash" rel="external nofollow noopener noreferrer" target="_blank">docker squash</a>，它比原生更灵活，支持任意合并。</p><h3 id="2-减小-layer-体积"><a href="#2-减小-layer-体积" class="headerlink" title="2. 减小 layer 体积"></a>2. 减小 layer 体积</h3><h4 id="2-1-选对基础镜像"><a href="#2-1-选对基础镜像" class="headerlink" title="2.1 选对基础镜像"></a>2.1 选对基础镜像</h4><p>&emsp;这一点时老生常谈了，记得19年老东家刚开始云原生的时候，基础镜像都是选的 ubuntu, 还不是原生的 ubuntu, 是装了一大堆内容的 ubuntu，光一个基础镜像就 &gt; 1G, 后面自己摸索更换了 alpine, 体积才一下子小下来, 所以基础镜像的选择也很重要。我个人常用的就是 alpine, 当然根据场景可以选择合适的基础镜像:</p><ul><li><code>scratch</code>: 空镜像, 不提供任何辅助工具，对于不依赖任何第三方库的程序是合适的，它本身不提供任何 container OS，所以程序是运行在 Docker Host 即宿主机上的，只是利用了 Docker 技术提供的隔离技术而已，直接 <code>FROM scratch</code> 即可</li><li><code>busybox</code>: <code>scratch</code> + BusyBox, 1M 左右, 通过 BusyBox 程序提供一些基础的 Linux 系统操作命令</li><li><code>alpine</code>: <code>scratch</code> + <code>BusyBox</code> + <code>apk</code>, 大小 5M 左右, 提供了 apk 包管理命令，方便安装各类工具及依赖包</li></ul><h4 id="2-2-多阶段构建"><a href="#2-2-多阶段构建" class="headerlink" title="2.2 多阶段构建"></a>2.2 多阶段构建</h4><p>&emsp;<a href="https://docs.docker.com/build/building/multi-stage/" rel="external nofollow noopener noreferrer" target="_blank">multi-stage builds</a> 思想是将仅一个阶段的构建行为拆分成多个阶段，感觉这么说没说到点子上，所谓的多阶段可以理解为分离中间过程和最终产物（两阶段），程序在编译期间的依赖以及临时文件并不是最终打包镜像所需要的，我们在打包镜像时只需要编译的产物。示例：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># syntax=docker/dockerfile:1</span></span><br><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.16</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/alexellis/href-counter/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go get -d -v golang.org/x/net/html  </span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> app.go ./</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:latest  </span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --no-cache add ca-certificates</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/github.com/alexellis/href-counter/app ./</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./app"</span>]</span></span><br></pre></td></tr></table></figure><p>上述 <code>COPY --from=0 /go/src/github.com/alexellis/href-counter/app ./</code> 就是将上一个阶段编译产生的 app 复制到当前阶段中，这里使用阶段编号0来使用(从0开始，每个<code>FROM</code>加1)，也可以对阶段命名方便后面使用（<code>FROM golang:1.16 AS builder</code>，后续就是使用 <code>COPY --from=builder /go/src/github.com/alexellis/href-counter/app ./</code>）。</p><h4 id="2-3-最小化的安装软件和依赖"><a href="#2-3-最小化的安装软件和依赖" class="headerlink" title="2.3 最小化的安装软件和依赖"></a>2.3 最小化的安装软件和依赖</h4><p>&emsp;平时安装软件时会附带安装推荐的软件或者文档，有些时候不同的包管理器可以禁用这些行为:</p><ul><li><code>apt-get</code>: 添加 <code>--no-install-recommends</code> 参数来禁用安装推荐软件的行为，使用 <code>apt-get install xxx -y --no-install-recommends</code></li><li><code>apk</code>: 添加 <code>--no-cache</code>, 使用 <code>apk add xxx --no-cache</code></li><li><code>pip</code>: 添加 <code>--no-cache-dir</code> 参数来禁用缓存行为，使用 <code>pip install &#39;setuptools==58.3.0&#39; --no-cache-dir</code></li><li><code>poetry</code>: 添加 <code>--no-root</code> 可以不用每次都安装自身, <code>poetry install --no-root -vvv</code></li></ul><p>&emsp;安装完软件注意及时清理，而且要在同一个 <code>RUN</code> 中执行:</p><ul><li><code>apt-get</code>: 安装完后使用 <code>apt-get autoclean &amp;&amp; apt-get clean</code> 进行清理，<code>autoclean</code>只删除不能被再次下载的软件包, 会清除已检索包文件的本地仓库，但它只会删除不会再下载且几乎无用的文件。它有助于防止缓存过大。<code>clean</code> 删除包缓存中的所有包, 清除的目录是 <code>/var/cache/apt/archives/</code> 和 <code>/var/cache/apt/archives/partial/</code></li><li><code>pip</code>: 直接删除缓存 <code>rm -rf ~/.cache/pip/*</code></li><li><code>poetry</code>: 直接删除除虚拟环境其他的内容 <code>rm -rf ~/.cache/pypoetry/{cache,artifacts}</code></li></ul>]]></content>
    
    <summary type="html">
    
      生产环境中关于最小化Docker镜像体积的实践经验
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Docker" scheme="https://jacksonary.github.io/tags/Docker/"/>
    
      <category term="最佳实践" scheme="https://jacksonary.github.io/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>GC中的三色标记算法</title>
    <link href="https://jacksonary.github.io/posts/ae6da7cb.html"/>
    <id>https://jacksonary.github.io/posts/ae6da7cb.html</id>
    <published>2021-11-27T03:06:36.000Z</published>
    <updated>2022-11-08T10:04:54.537Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;JVM 中的 GC 一直是一个调优过程中无法逃避的问题，当然现在越来好了，需要我们手动调优的参数也没有以前那么多、那么杂了，但基本原理还是要学习下的。三色分别指黑、灰、白，堆中对对象使用 XX(Y) 表示 ：</p><ol><li>XX 表示节点的唯一标识；</li><li>Y 表示 XX 节点的颜色：<ol><li>W-白-GC未遍历到此节点</li><li>G-灰-GC已经遍历到此节点，但节点至少存在一个子节点还未遍历</li><li>B-黑-GC已经遍历此节点和其所有的子节点</li></ol></li></ol><p>初始状态各个节点都为白色<a id="more"></a></p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/2021-11-26_11-21-14-初始状态.png" alt="初始状态"></p><p>接着 GC 进行遍历标记，由于用户线程和 GC 线程是并发执行的（这里只针对并发标记阶段，不要和初始标记混淆），所以在这过程中会出现错标和漏标的情况，过程如下</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/20211126-120331-错标漏标.png" alt="错标漏标"></p><p>&emsp;第一种错标的场景：这也是所谓的浮动垃圾（节点 22 及其所有子孙节点）产生过程，只能等到下一个新 GC 流程开启，进行初始标记时识别，这也是说 CMS 无法处理浮动垃圾的原因（注意CMS 中初始标记和并发标记的工作内容，这里说的是下一个 GC 流程而不是下一个 GC 阶段，GC 线程和用户线程并发执行，这个过程当然可能会因为线程的交替执行而导致新产生的垃圾（即浮动垃圾）没有被标记到；而 重新标记 的作用只是修改之前 并发标记 所获得的不可达对象，所以是没有办法处理 “浮动垃圾” 的。）。这也是错标后的解决方式，其实就是不解决，延迟到后面的回收流程中。</p><p>&emsp;第二种漏标的场景：结合上图，漏标的核心条件主要有2个：</p><ol><li>灰色节点断开和其还未遍历到的子节点引用关系；</li><li>已经完全遍历的黑色节点新增引用指向 1 中的白色节点；</li></ol><p>相应的解决方式也是从破坏上面2个条件入手：</p><ol><li>破坏条件 1 ，在灰色节点断开何其白色子节点引用关系时，在 22.23 = null 时(屏障位置) 记录他们之间的引用关系，下一次并发标记的时候也会去遍历这些节点，你可以理解为将 23 节点置为灰色，这就是 G1 使用的 STAB(snapshot-at-beginning) 方式;</li><li>破坏条件2，在黑色节点新增引用时，增加写屏障，在进行 11.sub = 23 时(屏障位置)，将节点 11 变为灰色，这样 GC 下次遍历时就继续遍历节点 11，最终标记到之前漏标的 23 节点，这就是 CMS 采用的增量更新；</li></ol><p>&emsp;大概的流程就是上图中表示，然后额外补一张 CMS 初始和并发标记的流程，结合着 CMS 的 4 阶段看应该对 CMS 中标记的阶段来会有额外的收获</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/20211126-120505-CMS并发标记.png" alt="CMS的并发标记"></p><blockquote><p>参考资源：</p><ol><li><a href="https://www.jianshu.com/p/9e70097807ba" rel="external nofollow noopener noreferrer" target="_blank">G1垃圾收集器之SATB</a></li><li><a href="https://segmentfault.com/q/1010000013653267" rel="external nofollow noopener noreferrer" target="_blank">JAVA: CMS垃圾回收中的“浮动垃圾”的理解</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      GC 中的三色标记算法的简单学习以及 CMS 中初始和并发标记的工作内容的区分
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="GC" scheme="https://jacksonary.github.io/tags/GC/"/>
    
      <category term="三色标记" scheme="https://jacksonary.github.io/tags/%E4%B8%89%E8%89%B2%E6%A0%87%E8%AE%B0/"/>
    
      <category term="CMS" scheme="https://jacksonary.github.io/tags/CMS/"/>
    
      <category term="G1" scheme="https://jacksonary.github.io/tags/G1/"/>
    
  </entry>
  
  <entry>
    <title>Redis底层数据结构</title>
    <link href="https://jacksonary.github.io/posts/54cf796.html"/>
    <id>https://jacksonary.github.io/posts/54cf796.html</id>
    <published>2021-11-21T01:34:14.000Z</published>
    <updated>2022-11-08T10:04:54.513Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>过去的几年折腾中，腾讯（List的底层实现）和京东（String底层的动态字符串）的面试中都问过我类似的问题，相比线程模型、哨兵以及持久化、穿透、击穿、雪崩等知识点知之甚少，才有了啃一下冲动，下面描述中不纠结变量是否和Redis源码中是否一致，只是侧重于思想。</p></blockquote><a id="more"></a><h2 id="1-String"><a href="#1-String" class="headerlink" title="1. String"></a>1. String</h2><p>&emsp;Redis 中使用的字符串不是 C 中的字符串（Redis 本身是基于 C 实现的），而是自己实现的一套简单动态字符串（Simple Dynamic String, SDS）机制。</p><p>&emsp;SDS 定义的数据结构中除了正常的 <code>buf[]</code> 数组外，还定义了字符串长度 <code>len</code> 和未使用的字节长度 <code>free</code> 2个核心变量，这两个变量的存在让 Redis 对 String 类型的操作更加友好，主要体现在：</p><ol><li>获取 String 长度时，直接获取 <code>len</code> 变量（O(1)）即可，而不需要去遍历字符串（O(n)）去实现，时间复杂度降低；</li><li>在修改字符串的时候，如果没有分配足够长度的内存空间，会引发缓冲溢出，而对于 SDS 在修改时会去检查 <code>len</code> 和 <code>free</code>，在不满足的情况进行适当的扩容，一定程度上避免了溢出；</li><li>C 中修改字符串时需要重新分配内存（减少字符时不重新分配会有内存泄漏的风险，增加字符串时不重新分配内存会有内存溢出的风险），而 SDS 可以通过上述的 <code>len</code> 和 <code>free</code> 来不重新分配内存的情况对 String 进行修改（准确来说应该是减少内存重新分配的频率，而不是不重新分配，重不重新分配还是看具体情况）：<ol><li>字符串减少：在减少数组元素的同时，让 <code>len</code> 减小以及让 <code>free</code> 增加（<code>free</code>的存在是预分配内存的一种表现）；</li><li>字符串增加：在增加数组元素的同时，让 <code>len</code> 增加以及让 <code>free</code> 减少，当然这么干的前提是 <code>free</code> 长度可以容纳增量，不够的话再进行内存的重新分配；</li></ol></li><li>二进制安全（主要对于字符串结尾字符 <code>\0</code> 的判定）；</li><li>兼容 C 的字符串，遵循C字符串以空字符结尾的惯例：这些API总会将SDS保存的数据的末尾设置为空字符，并且总会在为buf数组分配空间时多分配一个字节来容纳这个空字符，这是为了让那些保存文本数据的SDS可以重用一部分&lt;string.h&gt;库定义的函数。</li></ol><h2 id="2-Hash"><a href="#2-Hash" class="headerlink" title="2. Hash"></a>2. Hash</h2><p>&emsp;Redis 中 hash 的实现方式有两种：ziplist 和 hashtable（hashtable 的底层又是基于字典实现的），优先 ziplist，在下面的条件下 ziplist 会转化成 hashtable:</p><ol><li>元素字符串长度都超过 64 字节（<code>hash-max-ziplist-value</code> 控制）；</li><li>键值对数量超过 512（<code>hash-max-ziplist-entries</code> 控制）；</li></ol><p>&emsp;先来简单记录下会用到的概念：</p><h3 id="2-1-dict"><a href="#2-1-dict" class="headerlink" title="2.1 dict"></a>2.1 dict</h3><p>&emsp;dict 中核心属性包含了：多态字典（包含了 type 和 privdata 属性），哈希表，索引（我去，这玩意结构还挺复杂的/_ \）。其中 type 是指向一个 dictType 结构的指针，每个 dictType 保存了用于操作特定类型键值对的函数，privdata 保存的是需要传给上述特定函数的可选参数。</p><h3 id="2-2-hashtable"><a href="#2-2-hashtable" class="headerlink" title="2.2 hashtable"></a>2.2 hashtable</h3><p>&emsp;hashtable 就是普通的哈希表，底层的表现形式为 数组+链表（指针在字典中），核心属性有：table(就是数组)，size（哈希表的大小，就是 table 的大小），used（哈希表已有的节点数）。数组中的每个元素都是指向 dicEntry 结构的指针，每个 dictEntry 结构中保存着一个键值对。</p><p>&emsp;哈希节点就是上面说的 dicEntry，里面的核心元素主要包含：key，next 指针，value（value并不是一个单独的值，而是复杂对象，里面包含了实际的值value和其他一些属性）。总的来说和 java 中的 hash 相差不大，hash 冲突也是通过拉链法去解决的。</p><h2 id="3-List"><a href="#3-List" class="headerlink" title="3. List"></a>3. List</h2><p>&emsp;Redis 中 list 的实现有两种方式：一个是 ziplist（压缩链表，3.2 版本之前），另一个是 linkedlist（双向链表）。Redis 在 3.2 版本之后 ziplist 不再作为 list 的底层实现之一，而是替换为了 quicklist（快速链表）。考虑空间的原因，Redis 在创建 list 数据时会优先使用 ziplist，只有在必要的时候才会转换成 linkedlist，转换的必要条件为：</p><ol><li>向列表添加字符串元素，且字符串的长度超过 <code>server.list_max_ziplist_value</code> （默认值为 64 ）；</li><li>ziplist 中的节点数超过 <code>server.list_max_ziplist_entries</code> （默认值为 512 ）；</li></ol><h3 id="3-1-ziplist压缩链表"><a href="#3-1-ziplist压缩链表" class="headerlink" title="3.1 ziplist压缩链表"></a>3.1 ziplist压缩链表</h3><p>&emsp;<strong>ziplist</strong>由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构，是一种特殊的双向列表，它没有前驱和后驱指针来指向它的前后元素，而是记录前驱 entry(即data域) 的长度和自身 entry 的长度，然后通过两者推算出前驱或后驱（当前指针指cur向当前节点的头部，那cur-preLen 就是当前节点的前驱，cur+curLen 就是当前节点的后驱），不过这么干确实节省了一部分内存，但却大大降低了链表的遍历速度，这也解释了上述压缩链表在一定条件下会直接转变为双向链表的原因（当字符串长度过长或者节点过多都会造成推算的成本增加）。它的这种特性决定了压缩列表适合存储一些元素长度和个数都较小的场景，特点：分配一块连续的内存，存储效率高，但修改、删除、新增都有可能导致大量数据的复制。</p><p>&emsp;除了上述的 ziplist 读取性能较差外，它还存在一个连锁更新的问题，这也是 Redis 后面使用 quicklist 替换它作为 list 的一种实现方式。上面已经说过 ziplist 存放了 preLen 和 curLen，ziplist 一个节点的结构形似 |entry1|preLen|curLen| -&gt; |entry2|preLen|curLen| -&gt; |entry3|preLen|curLen|，前置先声明一点节点中存放的 preLen 和 curLen 也是占空间长度的，并且 ziplist 在存储时使用的变长编码，比如原来的节点1的长度占用的长度为X，那节点2中的 preLen=X，此时在节点1和节点2之间插入一个长度为Y的新节点，并且Y占用的长度是刚好足够让X后移，那此时节点2中的 preLen 更新为 Y，那此时节点占用的长度就会变化，若刚好节点2的变化引发了3中的preLen从而导致节点3的长度发生移动，依次向后，这就会引发连锁更新，这会大大加大时间复杂度。</p><h3 id="3-2-quicklist快速链表"><a href="#3-2-quicklist快速链表" class="headerlink" title="3.2 quicklist快速链表"></a>3.2 quicklist快速链表</h3><p>&emsp;quicklist是 Redis 将 ziplist 和 linkedlist 相结合的结果（对存储和性能平衡的一种妥协），对外整体表现为一个 linkedlist，每个节点中存放的 ziplist，大致上的结构为 |node1| -&gt; |node2| -&gt; |node3|，每个 node 是对 ziplist 节点的封装，这样既保证了少使用内存，也保证了性能。</p><h2 id="4-Set"><a href="#4-Set" class="headerlink" title="4. Set"></a>4. Set</h2><p>&emsp; Redis 中 Set 底层实现主要有两种方式：intset(整数集合，第一眼居然没有反应过来) 和 hashtable，和大部分的数据存储结构差不多，这2中数据结构之间存在转换关系，也是优先 intset（当前前提是我们往里面放的是整数类型元素），达到一定条件后自动转化为 hashtable：</p><ol><li>集合元素超过 512 个（<code>set-max-intset-entries</code> 属性）；</li><li>往里面放了非整型元素；</li></ol><h2 id="5-ZSet"><a href="#5-ZSet" class="headerlink" title="5. ZSet"></a>5. ZSet</h2><p>&emsp;Redis 中 zset 底层实现方式有两种：ziplist 和 skiplist。也是优先使用 ziplist 进行存储，在一定条件下转换成 skiplist:</p><ol><li>存在元素长度都超过 64 字节（<code>zset-max-ziplist-value</code> 控制）；</li><li>集合元素超过 128 个（<code>zset-max-ziplist-entries</code> 控制）；</li></ol><p>&emsp;在基于 ziplist 实现 Zset 时，ziplist 中存储的核心元素包含了元素和得分，ziplist 链表中按照得分从小到大进行排列（表头是最小的元素，表尾是最大的元素）。</p><p>&emsp;基于 skiplist 实现 Zset 时，skiplist 每个节点中保留的是集合元素(object)和得分（score），每个节点从小到大排列，通过跳表可以实现对 Zset 的范围操作（如 <code>ZRANGE</code>、<code>ZRANK</code>）。Zset 基于 dict 为有序结合创建了从成员到得分的映射（Key 为成员元素，value 为得分），虽然zset结构同时使用跳跃表和字典来保存有序集合元素，但这两种数据结构都会通过指针来<strong>共享相同元素的成员和分值</strong>，所以同时使用跳跃表和字典来保存集合元素不会产生任何重复成员或者分值，也不会因此而浪费额外的内存。注意这里 Zset 同时保留了跳表和字典，这样可以保留跳表在范围查询上的优势，也可以保留元素成员根据字典快速查分的优势。</p><p>最后，简单的脑图记忆：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/redis数据结构.png" alt="redis数据结构底层实现"></p><blockquote><p>参考资源：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/102422311" rel="external nofollow noopener noreferrer" target="_blank">Redis列表list 底层原理</a></li><li><a href="https://www.cnblogs.com/ysocean/p/9080942.html" rel="external nofollow noopener noreferrer" target="_blank">Redis详解（四）—— redis的底层数据结构</a></li><li><a href="https://zhuanlan.zhihu.com/p/76026080" rel="external nofollow noopener noreferrer" target="_blank">浅谈Redis五种数据结构的底层原理</a></li><li><a href="https://lotabout.me/2018/skip-list/" rel="external nofollow noopener noreferrer" target="_blank">跳表──没听过但很犀利的数据结构</a></li><li>《Redis 设计与实现》</li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      Redis五种数据类型的底层实现
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Redis" scheme="https://jacksonary.github.io/tags/Redis/"/>
    
      <category term="数据结构" scheme="https://jacksonary.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="底层实现" scheme="https://jacksonary.github.io/tags/%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务解决思路</title>
    <link href="https://jacksonary.github.io/posts/11329911.html"/>
    <id>https://jacksonary.github.io/posts/11329911.html</id>
    <published>2021-11-11T01:34:27.000Z</published>
    <updated>2022-11-08T10:04:54.508Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;分布式系统中对于跨服务的事务处理相对比较复杂，不再像单一服务直接对单库的几张表进行事务操作。主要的几种解决方式有：2PC，TCC，本地消息表，可靠消息最终一致。刚好最近在整理这一块的内容，记录一下。<a id="more"></a></p><h2 id="1-XA（基于2PC）"><a href="#1-XA（基于2PC）" class="headerlink" title="1. XA（基于2PC）"></a>1. XA（基于2PC）</h2><p>&emsp;以前系统还没有做拆分的时候，数据库都是使用的同一个，所谓的事务就正常操作即可，但当服务拆分后，往往数据库也会随着被划走，这个时候事务就演变成了分布式事务。XA 是传统 2PC 的方式，主要表现为一阶段各个系统执行 SQL 但不提交，等到 TC 具体通知提交/回滚后，再进行二阶段操作。但这种方式和数据库强耦合，依赖数据库层面提供的事务提交/回滚行为，而且在一阶段和二阶段之间会一直持有资源。简单的流程描述为:</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/2021-11-23_10-18-18_XA1.png" alt="XA简单流程"></p><p>强依赖于数据层面的 undolog 和 redolog:</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/分布式事务-XA-2PC.png" alt="XA强依赖数据库"></p><p>&emsp; 注：上面描述主要是 2PC 的思想，还不是真实的实现。（基于数据XA协议实现的 2PC 称为 XA 方案）</p><ol><li>2PC 适用于对多个数据库而言的，而不是对多个系统而言;</li><li>现在大多是微服务系统，各个服务只能操作自己应用领域内的数据库，所以理论上也禁止一个服务同时调用多个库；<br>下面是真实的场景（2PC 从第一阶段开始到最后一阶段结束都是持有资源的锁定状态，中间 不会释放）</li></ol><h2 id="2-TCC"><a href="#2-TCC" class="headerlink" title="2. TCC"></a>2. TCC</h2><p>&emsp;TCC 有着强烈业务耦合，需要开发者自己去实现资源的锁定 + 业务操作 + 数据回滚补偿等逻辑，相对复杂，实现难度较高。大致上每个TCC 接口都会提供 3 个方法：try, commit, cancel 执行对应操作，通常3个方法对应的操作为：</p><ul><li>try: 资源检测 + 资源锁定；</li><li>commit: 提交操作，使数据生效；</li><li>cancel: 回滚操作，数据补偿（对应于 try 的反向操作）；</li></ul><p>流程可以描述为：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/2021-11-23_10-30-44-TCC流程.png" alt="SEATA中的流程"></p><p>&emsp;在上面的流程，主要存在的核心角色有 TC(transaction coordinator)、TM(transaction manager) 和 RM(resource manager)，TC 主要负责事务的管理，TM 主要负责全局事务的发起，RM 主要负责配合 TM 执行相应的操作。当然中间流程也会存在一些问题：</p><ol><li><p>空回滚：seata 在拦截 RM 后向 TC 注册分支事务，注册成功后，调用 RM 的 try，由于某些原因（网络波动、服务宕机、代码执行报错）导致资源没有锁定，超时后 TC 向 RM 发起 cancel 操作，此时如果正常 cancel 会导致数据错误（如正常 try 扣款30，cancel 补偿30，但若 try 扣款失败；此时还补偿30，账户会多出一笔意外之财，不和逻辑）;</p></li><li><p>幂等：在某些情况，若网络波动导致 commit 超时， TC 尝试再次调用 RM 的 commit，但中间上次的那个 commit 执行成功了，那 TC 发起的<br>第二次的 commit 再次执行也会导致数据错误（如 try 空，commit 加 30 快，此时重复执行 commit 会导致返回的加 30 块）；</p></li><li><p>悬挂：在某些情况下，如果 try 超时，TC 向 RM 发起 cancel，cancel 正常执行(不考虑空回滚),此时 Seata 认为事务已经完全执行了(成功/失败)。但这个时候上次超时的 try 到了 RM，一旦此时 try，那资源将会被锁定，并且没有后续的二阶段进行资源的提交或回滚，这时资源就会一直处理锁定的状态，并且没有人去释放这些资源；</p></li></ol><p>&emsp;为了解决上面的3个问题，可以通过额外引入一张事务表来解决，主要属性有事务 id 和事务状态，在 TCC 的各个阶段通过操作这张表来避免，详细流程如下：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/分布式事务-TCC问题解决.png" alt="分布式事务-TCC问题解决"></p><p>注：注意上述过程中对额外事务表操作的顺序！另外在 TCC 模式中，可以使用同库模式来做一些优化，它的主要思想是：将分支事务记录业务库中，可以减少 TC 和业务服务之间 RPC 的次数，但此时无法确定什么时候 TM 需要执行它的二阶段行为，可以通过定时器去扫本地事务还没变成 已提交/已回滚 状态的分支事务，向TC 询问对应的TM是否已经提交/回滚事务，然后 TM 再执行对应的 confirm/cancel 即可。</p><h2 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a>本地消息表</h2><p>&emsp;本地消息表主要思路是引入了 MQ 和本地消息表的方式来解决分布式事务，流程如下：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/分布式事务-本地消息表.png" alt="分布式事务-本地消息表"></p><p>当然上述过程中的 ZK Watcher 可以通过其他方式来（如 RPC 调用来取代），大致的思想就是这个样子，但存在的问题：严重依赖本地消息表，在高并发场景下吞吐量受限。这一套架构是最基础的模型，后面比如可靠消息最终一致性以及最大努力通知都是基于这套方案去优化的。</p><blockquote><p>参考文章：</p><ol><li><a href="https://seata.io/zh-cn/docs/dev/mode/tcc-mode.html" rel="external nofollow noopener noreferrer" target="_blank">https://seata.io/zh-cn/docs/dev/mode/tcc-mode.html</a></li><li><a href="https://www.infoq.cn/article/G33hCC-QoSJPlkt4e64E" rel="external nofollow noopener noreferrer" target="_blank">https://www.infoq.cn/article/G33hCC-QoSJPlkt4e64E</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      分布式系统中事务的解决方式
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="分布式事务" scheme="https://jacksonary.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo应用无异常日志问题排查</title>
    <link href="https://jacksonary.github.io/posts/af6e5a38.html"/>
    <id>https://jacksonary.github.io/posts/af6e5a38.html</id>
    <published>2021-06-12T05:28:20.000Z</published>
    <updated>2022-11-08T10:04:54.538Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>首先描述一下现象吧，前几天同事说我们服务应用好像错误日志被Dubbo吞掉了，就这么一听没放在心上。后来过了2天，测试反应测试反应某个接口挂了，去机器上看了下日志没啥异常或者try的信息，但接口一直报错，没得办法，只能把参数抓下来到自己本地Debug（走的是单测的流程），然后就查到NPE，此时本地控制台是有NPE异常日志的。</p></blockquote><p>&emsp;这个问题越想越奇怪，为啥走单测就可以打印异常信息，走 Dubbo Service 进来服务内部就没有异常信息。将测试环境的请求路由本地时发现，Dubbo 通过代理将本地的 Service 暴露出去，结果确实是做了封装，返回的对象是 <code>RpcResult</code> 类，这个可以查看 <code>com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker</code> 得知，代理方法为：<a id="more"></a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Result <span class="title">invoke</span><span class="params">(Invocation invocation)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RpcResult(e.getTargetException());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RpcException(<span class="string">"Failed to invoke remote proxy method "</span> + invocation.getMethodName() + <span class="string">" to "</span> + getUrl() + <span class="string">", cause: "</span> + e.getMessage(), e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际的调用链路为：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/2021-06-15_08-50-46_Dubbo%E8%B0%83%E7%94%A8%E9%93%BE.png" alt="Dubbo的调用链"></p><p>在实际返回结果前有个叫做 <code>ExceptionFilter</code> 的过滤器：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/2021-06-15_08-52-12_ExceptionFilter.png" alt="ExceptionFilter"></p><p>内部对异常做了一些处理：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Result <span class="title">invoke</span><span class="params">(Invoker&lt;?&gt; invoker, Invocation invocation)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Result result = invoker.invoke(invocation);</span><br><span class="line">        <span class="keyword">if</span> (result.hasException() &amp;&amp; GenericService.class != invoker.getInterface()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Throwable exception = result.getException();</span><br><span class="line"></span><br><span class="line">                <span class="comment">// directly throw if it's checked exception</span></span><br><span class="line">                <span class="keyword">if</span> (!(exception <span class="keyword">instanceof</span> RuntimeException) &amp;&amp; (exception <span class="keyword">instanceof</span> Exception)) &#123;</span><br><span class="line">                    <span class="keyword">return</span> result;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// directly throw if the exception appears in the signature</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Method method = invoker.getInterface().getMethod(invocation.getMethodName(), invocation.getParameterTypes());</span><br><span class="line">                    Class&lt;?&gt;[] exceptionClassses = method.getExceptionTypes();</span><br><span class="line">                    <span class="keyword">for</span> (Class&lt;?&gt; exceptionClass : exceptionClassses) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (exception.getClass().equals(exceptionClass)) &#123;</span><br><span class="line">                            <span class="keyword">return</span> result;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (NoSuchMethodException e) &#123;</span><br><span class="line">                    <span class="keyword">return</span> result;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// for the exception not found in method's signature, print ERROR message in server's log.</span></span><br><span class="line">                logger.error(<span class="string">"Got unchecked and undeclared exception which called by "</span> + RpcContext.getContext().getRemoteHost()</span><br><span class="line">                        + <span class="string">". service: "</span> + invoker.getInterface().getName() + <span class="string">", method: "</span> + invocation.getMethodName()</span><br><span class="line">                        + <span class="string">", exception: "</span> + exception.getClass().getName() + <span class="string">": "</span> + exception.getMessage(), exception);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// directly throw if exception class and interface class are in the same jar file.</span></span><br><span class="line">                String serviceFile = ReflectUtils.getCodeBase(invoker.getInterface());</span><br><span class="line">                String exceptionFile = ReflectUtils.getCodeBase(exception.getClass());</span><br><span class="line">                <span class="keyword">if</span> (serviceFile == <span class="keyword">null</span> || exceptionFile == <span class="keyword">null</span> || serviceFile.equals(exceptionFile)) &#123;</span><br><span class="line">                    <span class="keyword">return</span> result;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// directly throw if it's JDK exception</span></span><br><span class="line">                String className = exception.getClass().getName();</span><br><span class="line">                <span class="keyword">if</span> (className.startsWith(<span class="string">"java."</span>) || className.startsWith(<span class="string">"javax."</span>)) &#123;</span><br><span class="line">                    <span class="keyword">return</span> result;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// directly throw if it's dubbo exception</span></span><br><span class="line">                <span class="keyword">if</span> (exception <span class="keyword">instanceof</span> RpcException) &#123;</span><br><span class="line">                    <span class="keyword">return</span> result;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// otherwise, wrap with RuntimeException and throw back to the client</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> RpcResult(<span class="keyword">new</span> RuntimeException(StringUtils.toString(exception)));</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">                logger.warn(<span class="string">"Fail to ExceptionFilter when called by "</span> + RpcContext.getContext().getRemoteHost()</span><br><span class="line">                        + <span class="string">". service: "</span> + invoker.getInterface().getName() + <span class="string">", method: "</span> + invocation.getMethodName()</span><br><span class="line">                        + <span class="string">", exception: "</span> + e.getClass().getName() + <span class="string">": "</span> + e.getMessage(), e);</span><br><span class="line">                <span class="keyword">return</span> result;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RuntimeException e) &#123;</span><br><span class="line">        logger.error(<span class="string">"Got unchecked and undeclared exception which called by "</span> + RpcContext.getContext().getRemoteHost()</span><br><span class="line">                + <span class="string">". service: "</span> + invoker.getInterface().getName() + <span class="string">", method: "</span> + invocation.getMethodName()</span><br><span class="line">                + <span class="string">", exception: "</span> + e.getClass().getName() + <span class="string">": "</span> + e.getMessage(), e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际 Debug 时，断点走到了错误日志打印处（通过Dubbo调用）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// for the exception not found in method's signature, print ERROR message in server's log.</span></span><br><span class="line">logger.error(<span class="string">"Got unchecked and undeclared exception which called by "</span> + RpcContext.getContext().getRemoteHost()</span><br><span class="line">        + <span class="string">". service: "</span> + invoker.getInterface().getName() + <span class="string">", method: "</span> + invocation.getMethodName()</span><br><span class="line">        + <span class="string">", exception: "</span> + exception.getClass().getName() + <span class="string">": "</span> + exception.getMessage(), exception);</span><br></pre></td></tr></table></figure><p>但日志并没打印，和测试环境的现象一致，实际是出现了异常，应用服务和 Dubbo 都感知到了，那基本定位到日志本身的问题了。继续追到 Dubbo 的日志类 <code>LoggerFactory</code>，看到一个静态代码块：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    String logger = System.getProperty(<span class="string">"dubbo.application.logger"</span>, <span class="string">""</span>);</span><br><span class="line">    <span class="keyword">switch</span> (logger) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">"slf4j"</span>:</span><br><span class="line">            setLoggerAdapter(<span class="keyword">new</span> Slf4jLoggerAdapter());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">"jcl"</span>:</span><br><span class="line">            setLoggerAdapter(<span class="keyword">new</span> JclLoggerAdapter());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">"log4j"</span>:</span><br><span class="line">            setLoggerAdapter(<span class="keyword">new</span> Log4jLoggerAdapter());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">"jdk"</span>:</span><br><span class="line">            setLoggerAdapter(<span class="keyword">new</span> JdkLoggerAdapter());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">"log4j2"</span>:</span><br><span class="line">            setLoggerAdapter(<span class="keyword">new</span> Log4j2LoggerAdapter());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            List&lt;Class&lt;? extends LoggerAdapter&gt;&gt; candidates = Arrays.asList(</span><br><span class="line">                    Log4jLoggerAdapter.class,</span><br><span class="line">                    Slf4jLoggerAdapter.class,</span><br><span class="line">                    Log4j2LoggerAdapter.class,</span><br><span class="line">                    JclLoggerAdapter.class,</span><br><span class="line">                    JdkLoggerAdapter.class</span><br><span class="line">            );</span><br><span class="line">            <span class="keyword">for</span> (Class&lt;? extends LoggerAdapter&gt; clazz : candidates) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    setLoggerAdapter(clazz.newInstance());</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Throwable ignored) &#123;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动并没有配置啥 <code>dubbo.application.logger</code> 变量，所以是按照它默认的来：slf4j -&gt; jcl -&gt; log4j -&gt; jdk -&gt; log4j2，若都没有就依次尝试，发现服务选用的是 log4j，但项目又是使用的 logback 框架，所以日志无法打印。</p><p>&emsp;logback 框架是支持 slf4j 的，所以直接使用 slf4j 输出就可以了：</p><ol><li>手动配置 Dubbo 的日志；</li><li>将默认的 log4j 转成 slf4j 即可；</li></ol><p>第一种手动去配置 Dubbo 的日志，可以在启动服务时添加VM参数<code>-Ddubbo.application.logger=slf4j</code>，或者直接配置系统环境变量<code>dubbo.application.logger=slf4j</code>，也可以在应用的 Dubbo 配置文件中指定<code>&lt;dubbo:application name=&quot;${spring.application.name}&quot; logger=&quot;log4j&quot;&gt;</code>，更多方式参照dubbo官网。第二种方式不需要手动去配，但需要将默认的 log4j 转成 slf4j，可以将 log4j 通过 log4j-over-slf4j 路由到 slf4j，同时剔除项目中所有 log4j 的依赖即可，slf4j 和 logback 天然融合：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-over-slf4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Dubbo 应用无错误日志
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Dubbo" scheme="https://jacksonary.github.io/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>MySQL实用经验</title>
    <link href="https://jacksonary.github.io/posts/36236.html"/>
    <id>https://jacksonary.github.io/posts/36236.html</id>
    <published>2021-05-23T06:55:49.000Z</published>
    <updated>2022-11-08T09:07:57.362Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;在实际开发中，会有一些值得注意的点，下面简单记录一下。</p><h3 id="1-关于更新时间"><a href="#1-关于更新时间" class="headerlink" title="1. 关于更新时间"></a>1. 关于更新时间</h3><p>&emsp;在设计表时，通常会将创建时间和更新时间带上（即<code>create_time</code>和<code>update_time</code>），在更新记录时往往在代码层面不断的去手动设置<code>new Date()</code>，而且由于这个字段的存在感可能不是很强，所以有时候常常会忘了在更新时同时去更新这个字段，一旦后面需要用到的时候发现这个字段从来没有更新过，这就很尴尬，<a id="more"></a>其实mysql可能帮我们做这个事，不需要我们自己去做，只要在设计表时指定<code>update_time datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP</code>即可,下面是一个完整的表结构：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> school (</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">INT</span> ( <span class="number">16</span> ) <span class="keyword">NOT</span> <span class="literal">NULL</span> Auto_increment <span class="keyword">COMMENT</span> <span class="string">"id"</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="built_in">VARCHAR</span> ( <span class="number">32</span> ) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">"学校名"</span>,</span><br><span class="line"><span class="comment">-- 创建时间直接默认给当前时间</span></span><br><span class="line">create_time datetime <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">COMMENT</span> <span class="string">"创建时间"</span>,</span><br><span class="line"><span class="comment">-- 更新时间默认给当前时间，且在更新记录时自动更新为当前时间</span></span><br><span class="line">update_time datetime <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">COMMENT</span> <span class="string">"更新时间"</span>,</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> ( <span class="keyword">id</span> ) </span><br><span class="line">) <span class="keyword">ENGINE</span> = <span class="keyword">INNODB</span> <span class="keyword">DEFAULT</span> <span class="keyword">charset</span> = utf8;</span><br></pre></td></tr></table></figure><h3 id="2-关于IP"><a href="#2-关于IP" class="headerlink" title="2. 关于IP"></a>2. 关于IP</h3><p>&emsp;mysql中有专门处理ip的函数，不要直接用字符型存放IP地址，一是无法占用空间较大（满位是<code>255.255.255.255</code>占用16字节），而将其转成<code>int</code>型只需要4字节；二是无法对IP进行筛选；三对于字符类型检索也很慢。若将IP地址格式定义为<code>A.B.C.D</code>，那将其转成<code>INT</code>数值类型就为<code>A*2^24+B*2^16+C*2^8+D</code>，最大值为4294967295，所以int类型4位32字节足够了，主要涉及2个函数<code>INET_ATON([ipStr])</code>（将字符串IP转成整数型）和<code>INET_NTOA(ipInt)</code>（将整型数值转成字符型IP地址）。</p><h3 id="3-联合查询增加条件"><a href="#3-联合查询增加条件" class="headerlink" title="3. 联合查询增加条件"></a>3. 联合查询增加条件</h3><p>&emsp;联合查询条件是指在<code>join X on condition1</code>后面通过<code>and</code>关键字继续追加条件（如<code>and a.name like &quot;test%&quot;</code>或者<code>and b.category_id=20</code>等等），会造成什么结果，这个问题其实对于大部分的开发极少用到，一般而言就是<code>on A.b_id=b.id</code>，就拿<code>left join</code>为例，过程如下：将所有的结果都取出来，主表全显、次表只显示满足联合联合条件的，总体而言联合条件不会影响记录的总条数，只是影响次表是否展示。这里区别一下和<code>where</code>条件后面使用<code>and</code>追加条件就好了，<code>where</code>条件称之为全局条件，它是会影响最终的结果数目的，示例如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语句1，left join 在on后面又跟了条件 r.name like '%门%'</span></span><br><span class="line"><span class="keyword">SELECT</span> sc.id,sc.name,sc.shop_id,r.id r_id, r.name <span class="keyword">from</span> shop_component sc</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> rfa r <span class="keyword">ON</span> r.id = sc.component_id <span class="keyword">and</span> r.name <span class="keyword">like</span> <span class="string">'%门%'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 语句2，直接使用 where 进行过滤</span></span><br><span class="line"><span class="keyword">SELECT</span> sc.id,sc.name,sc.shop_id,r.id r_id, r.name <span class="keyword">from</span> shop_component sc</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> rfa r <span class="keyword">ON</span> r.id = sc.component_id </span><br><span class="line"><span class="keyword">WHERE</span> r.name <span class="keyword">like</span> <span class="string">'%门%'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 语句3，left join 在on后面又跟了条件 sc.name like '%门%'（主表）</span></span><br><span class="line"><span class="keyword">SELECT</span> sc.id,sc.name,sc.shop_id,r.id r_id, r.name <span class="keyword">from</span> shop_component sc</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> rfa r <span class="keyword">ON</span> r.id = sc.component_id <span class="keyword">and</span> sc.name <span class="keyword">like</span> <span class="string">'%门%'</span></span><br></pre></td></tr></table></figure><p>对照上面的结论：<br>语句1：在普通join的结果上加了限制，所以 shop_component 主表全显，关联表 rfa 只显示满足 <code>name like &#39;%门%&#39;</code> 条件的记录，其他记录的关联表都为空；<br>语句2：直接在最后加了<code>where</code>条件，它是对整个结果集进行了过滤，只在中间结果集中取满足 <code>name like &#39;%门%&#39;</code> 条件的记录，其他记录不限制，所以最终的结果记录要比语句1更少；<br>语句3：只是 <code>left join x and</code> 后面的条件有关联表rfa的<code>name like &#39;%门%&#39;</code>改成了主表 shop_compoment 的<code>name like &#39;%门%&#39;</code>，结果是类似于语句1的，这时主表也是全显，关联表只显示满足<code>sc.name like &#39;%门%&#39;</code>条件的记录；</p><p>综上所述，<code>left join on x and y</code>这种语句的on语句并不会影响结果记录数，主表是全显的，关联表只会显示满足<code>and</code>之后条件的记录，其他为null。</p><h3 id="4-小表驱动大表"><a href="#4-小表驱动大表" class="headerlink" title="4. 小表驱动大表"></a>4. 小表驱动大表</h3><p>&emsp;这算是sql优化的一种方式吧，它的使用场景主要有两种：存在于和join操作。</p><p>&emsp;存在于判断主要是<code>in</code>和<code>exists</code>操作：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 如果B表小、A表大，应优先使用 in 关键字，先循环的是  select id from B，这样利用这个小表来驱动A这个大表</span></span><br><span class="line"><span class="keyword">select</span> A.* <span class="keyword">from</span> A <span class="keyword">where</span> A.b_id <span class="keyword">in</span> (<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> B)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 如果A表小、B表大，应优先使用 exists 关键字，这样先循环的就是 select A.* from A（小表），然后在小表内再去验证是否满足 select 1 from B where B.id=A.b_id（大表）</span></span><br><span class="line"><span class="keyword">select</span> A.* <span class="keyword">from</span> A <span class="keyword">where</span> <span class="keyword">exists</span> (<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> B <span class="keyword">where</span> B.id=A.b_id)</span><br></pre></td></tr></table></figure><p>其实 <code>in</code> 和 <code>exists</code> 主要是看场景、看他们的驱动表，MySQL 表关联的算法是 Nest Loop Join，是通过驱动表的结果集作为循环基础数据，然后一条一条地通过该结果集中的数据作为过滤条件到下一个表中查询数据，然后合并结果。</p><p>&emsp;第二种就是联合查询了，左连接就尽量让左表尽量小，右连接就尽量让右表尽量小。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如左连接查询应该尽量保证左表尽可能的小</span></span><br><span class="line"><span class="keyword">select</span> A.* <span class="keyword">from</span> A <span class="keyword">left</span> <span class="keyword">join</span> B <span class="keyword">on</span> A.b_id = B.id</span><br></pre></td></tr></table></figure><h3 id="5-mysql中的锁"><a href="#5-mysql中的锁" class="headerlink" title="5. mysql中的锁"></a>5. mysql中的锁</h3><p>&emsp;现有主流mysql开发基本都是使用的INNODB引擎，INNODB引擎支持表锁和行锁（myISAM仅支持表锁），细分为 record lock、gap lock 和 next-key lock（即record lock + gap lock）。比如在同时修改同一条记录时就会出现其中一个线程（会话）在一直等待，或者<code>select * from A for update</code>（直接加写锁，仅允许一个线程加写锁）和<code>select * from A lock in share mode</code>（读锁，多个线程可以同时加读锁，和写锁互斥，一旦加了读锁就无法再加写锁），像<code>alter table</code>、<code>insert into A select * from B</code>（锁表A）这类操作表的行为会锁表。若需要验证上述的内容，需要在2个会话里面进行操作，并且将自动提交事务关闭（或者使用<code>begin ... commit</code>）。若出现慢SQL的话，排查的时候可能需要考虑到这种情况，主要可以这样排查：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 检查mysql的进程情况</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">processlist</span></span><br><span class="line"><span class="comment">-- 查看正在被锁定的表</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">OPEN</span> <span class="keyword">TABLES</span> <span class="keyword">where</span> In_use &gt; <span class="number">0</span>;</span><br><span class="line"><span class="comment">-- 查看事务锁的情况</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> INFORMATION_SCHEMA.INNODB_TRX;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 杀掉指定的进程，pid就是 processlist 中的id</span></span><br><span class="line"><span class="keyword">kill</span> [pid]</span><br></pre></td></tr></table></figure><p>&emsp;有些时候我们在mysql中会来做乐观锁和悲观锁的方法，具体方案如下：</p><ul><li>乐观锁：我们直接在表中新增一个<code>version</code>字段，每次更新前我们都比较一下当前记录的<code>version</code>，如果<code>version</code>字段和我们手中的<code>version</code>字段一致，那就进行更新同时将<code>version</code>字段进行更新（可以是自增或者时间戳），否则不更新；</li><li>悲观锁：在查询后添加<code>for update</code>即可人工加锁，即所谓的悲观锁的实现方案；</li></ul><h3 id="6-关于分布式锁"><a href="#6-关于分布式锁" class="headerlink" title="6. 关于分布式锁"></a>6. 关于分布式锁</h3><p>&emsp;现在分布式锁的主流实现方式是ZK（最小文件节点）和redis（setNX），其实mysql本身也可以用来做分布式锁的解决方案，mysql实现分布式锁主要是靠唯一键的约束，和redis的实现方式比较类似，直接以约定好的key（可以是指定好的字符串，可以是日期+方法名）插入DB中对应的列，该列做唯一约束，那么当多个线程同时操作时只可能有一个线程可以插入成功，其他的插入失败，其中插入成功的那个线程就表示成功获取了锁，其他插入失败的就表示没有抢到锁。</p><h3 id="7-数据库黑名单"><a href="#7-数据库黑名单" class="headerlink" title="7. 数据库黑名单"></a>7. 数据库黑名单</h3><p>&emsp;即某台主机或者ECS被mysql拉入黑名单，无法连接，通常发生的场景多发生在网络较差的情况，服务端和DB Server多次短时间的连接、断开，反复多次会出现这样的情况，在java服务端抛出的异常大概如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.sql.SQLException: null, message from server: &quot;Host &apos;129.60.199&apos; is blocked because of many connection errors; unblock with &apos;mysqladmin flush-hosts&apos;&quot;</span><br></pre></td></tr></table></figure><p>同一个ip在短时间内产生太多（超过mysql数据库max_connection_errors的最大值）中断的数据库连接而导致的阻塞；</p><p>解决方式：<code>mysqladmin flush-hosts</code>，可以直接在客户端运行<code>flush-hosts</code>。</p><h3 id="8-代码层面实现mysql的手动事务提交"><a href="#8-代码层面实现mysql的手动事务提交" class="headerlink" title="8. 代码层面实现mysql的手动事务提交"></a>8. 代码层面实现mysql的手动事务提交</h3><p>&emsp;在一些数据库双写的场景下可能需要手动提交事务，单独使用mybatis可以这样关闭事务的自动提交<br><code>SqlSession sqlSession = sqlSessionFactory.openSession(false)</code>，在与SpringBoot集成后，可以作如下实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> DataSourceTransactionManager transactionManager;</span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">TransactionDefinition transactionDefinition;</span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> UserMapper userMappper;</span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> UserSearchClient userSearchClient;</span><br><span class="line"></span><br><span class="line">TransactionStatus transaction = transactionManager.getTransaction(transactionDefinition);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(Long id)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// mysql的行为</span></span><br><span class="line">    userMapper.delete(id);</span><br><span class="line">    <span class="comment">// es的行为</span></span><br><span class="line">    userSearchClient.delete(id);</span><br><span class="line">    transactionManager.commit(transaction);</span><br><span class="line">  &#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">    logger.error(<span class="string">"user delete occur error."</span>, e);</span><br><span class="line">    transactionManager.rollback(transaction);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="【附】"><a href="#【附】" class="headerlink" title="【附】"></a>【附】</h3><p>&emsp;实际使用中注重性能的存在一些优化点(摘自PPT):</p><ul><li>查询频繁的列需要建立索引；</li><li>少用类似<code>select * from t where xx is null</code>;</li><li>尽量避免在<code>where</code>子句中使用<code>!=</code>或<code>&lt;&gt;</code>操作符;</li><li>尽量避免在<code>where</code>子句中使用<code>or</code>来连接条件；</li><li>尽量避免使用<code>in</code>和<code>not in</code>，否则会导致全表扫描；</li><li>连续的数值，能用<code>between</code>就不要用<code>in</code>；</li><li>尽量用<code>Exits</code>代替<code>In</code>，（<code>Exits</code>会使用索引，<code>In</code>不会使用索引）；</li><li><code>like ‘%abc%’</code>不使用索引；</li><li>尽量避免在<code>where</code>子句中对字段进行表达式操作，如<code>select id from t where num/2 = 100</code>、<code>select id from t where num = 100*2</code>；</li><li>避免在<code>where</code>子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描，比如<code>select id from t where datediff(day,createdate,’2005-11-30′) = 0</code>、<code>select id from t where name like &#39;abc%&#39; select id from t where createdate &gt;= &#39;2005-11-30&#39; and createdate &lt; &#39;2005-12-1‘</code>；</li><li>对于多张大数据量（这里几百条就算大了）的表<code>JOIN</code>，要先分页再<code>JOIN</code>，否则逻辑读会很高，性能很差；</li><li>尽量用<code>Count(1)</code>代替<code>Count(*)</code> 两个都是返回所有的；</li><li>索引列最好不要超过6个；</li><li>尽量使用数字类型代替字符类型（数字类型只比较一次，字符类型逐个字符对比）；</li><li>尽可能的使用<code>varchar/nvarchar</code> 代替 <code>char/nchar</code>，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些；</li><li>任何地方都不要使用<code>select * from t</code>，用具体的字段列表代替<code>*</code>，不要返回用不到的任何字段；</li><li>尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写；</li><li>尽量避免大事务操作，提高系统并发能力；</li><li>尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;在实际开发中，会有一些值得注意的点，下面简单记录一下。&lt;/p&gt;
&lt;h3 id=&quot;1-关于更新时间&quot;&gt;&lt;a href=&quot;#1-关于更新时间&quot; class=&quot;headerlink&quot; title=&quot;1. 关于更新时间&quot;&gt;&lt;/a&gt;1. 关于更新时间&lt;/h3&gt;&lt;p&gt;&amp;emsp;在设计表时，通常会将创建时间和更新时间带上（即&lt;code&gt;create_time&lt;/code&gt;和&lt;code&gt;update_time&lt;/code&gt;），在更新记录时往往在代码层面不断的去手动设置&lt;code&gt;new Date()&lt;/code&gt;，而且由于这个字段的存在感可能不是很强，所以有时候常常会忘了在更新时同时去更新这个字段，一旦后面需要用到的时候发现这个字段从来没有更新过，这就很尴尬，
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="MySQL" scheme="https://jacksonary.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>InnoDB存储引擎</title>
    <link href="https://jacksonary.github.io/posts/64693.html"/>
    <id>https://jacksonary.github.io/posts/64693.html</id>
    <published>2021-04-23T06:41:00.000Z</published>
    <updated>2022-11-08T09:07:57.353Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-MySQL-逻辑架构"><a href="#1-MySQL-逻辑架构" class="headerlink" title="1. MySQL 逻辑架构"></a>1. MySQL 逻辑架构</h2><p>&emsp;整体的逻辑架构分为 Server 层和引擎层两部分。其中 Server 层又细分为连接器和核心层，其中连接器那一层并非MySQL独有，大部分的C/S工具都有类似的架构（比如连接处理、授权认证、安全等），Server 层的第二层是 MySQL 独有的，MySQL 很多核心功能都在这一层，包括查询解析、分析、优化、缓存以及内置函数，还有所有跨存储引擎的功能也在这一层实现（包含存储过程、视图等等）。<a id="more"></a>服务器和存储引擎通过 API 进行通信，存储引擎不会去解析 SQL，它只负责数据的存储和读取。具体逻辑架构如下：</p><p><img src="https://img-blog.csdnimg.cn/20210423205944554.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70#pic_center" alt="MySQL的逻辑架构"></p><h2 id="2-物理存储"><a href="#2-物理存储" class="headerlink" title="2. 物理存储"></a>2. 物理存储</h2><p>&emsp;在 MySQL 的文件系统中，MySQL 的每个数据库（也称为schema）都会以<code>data</code>目录下的一个子目录的形式存在（库名即文件夹名），然后各个数据库里面的表定义会以<code>[table_name].frm</code>的文件形式存储在所属的数据库目录中（但现在的8.0+版本中已经取消了<code>*.frm</code>文件，只有表空间文件<code>.ibd</code>）。另外 schema 的定义和数据库的定义差不多，在 MySQL 中，对 <code>DATABASE</code> 的操作完全可以使用 <code>SCHEMA</code> 来替换操作（如<code>create database test</code>和<code>create schema test</code>效果一样，都是创建一个test库）。</p><h2 id="3-InnoDB-的结构"><a href="#3-InnoDB-的结构" class="headerlink" title="3. InnoDB 的结构"></a>3. InnoDB 的结构</h2><p>&emsp;Innodb是目前MySQL最常用也是最推荐的一种存储引擎，它的架构（8.0版本）如下：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/cf7d017565dee783807f5d7447b0fc9e.png" alt="Innodb的架构图"></p><p>&emsp;InnoDB 目前主要优势有：</p><ul><li>它的DML（data manipulation language，即数据操作，主要是增删改查，注意和DDL的区别；DDL-data definition language，即数据定义语言，主要是创库、建表）操作遵ACID模式，且支持事务提交、回滚以及crash恢复；</li><li>行级锁和一致性读的特性提高了其并发能力；</li><li>它将数据存储到磁盘上且基于主键来优化查询，每个 InnoDB 表都有一个叫做聚簇索引的主键索引，这个索引用来组织数据以便减少根据主键进行搜索的 I/O；</li><li>为了维持数据完整性，InnoDB 支持外键约束。外键的存在可以保证在增、删、改时不会导致相关表的不一致；</li></ul><h3 id="3-1-InnoDB的内存结构"><a href="#3-1-InnoDB的内存结构" class="headerlink" title="3.1 InnoDB的内存结构"></a>3.1 InnoDB的内存结构</h3><p>&emsp;Innodb的内存结构主要有 Buffer Pool、Change Buffer、Adaptive Hash Index 以及 Log Buffer 几部分组成。</p><h4 id="3-1-1-Buffer-Pool"><a href="#3-1-1-Buffer-Pool" class="headerlink" title="3.1.1 Buffer Pool"></a>3.1.1 Buffer Pool</h4><p>&emsp;Buffer Pool 是 InnoDB 缓表和索引数据的主要内存区域，它允许直接从内存中频繁操作数据（这样的操作很快），在专用服务器上通常会将高达80%的物理内存会分配给 Buffer Pool。为了大容量的读取行为的性能，Buffer Pool 被分割为一个个的页（Page，页可以承载多个 row），为了提高缓存管理的效率，页的实现是基于 linked list，使用 LRU（least recently used） 算法的变体将很少使用的数据从缓存中移除。很多时候 MySQL 的调整往往都是基于如何更大程度的使用 Buffer Pool 来操作数据考虑的。</p><p>&emsp;当需要空间去增加 page 到 buffer pool 中时，最近最少使用的 page 将会被驱逐（MySQL中将其称为老化，这些页也就是老年页），新的 page 将会被增加到列表的中间，这种中点插入法主要将列表分为2个子列表：</p><ul><li>在 head 处，子列表是最近最经常使用的，这里的子列表称之为 new sublist；</li><li>在 tail 处，子列表是最近最不经常使用的，这里的子列表称之为 old sublist；</li></ul><p><img src="https://img-blog.csdnimg.cn/img_convert/0e6028fb9f09b261555198f159e4f6e3.png" alt="Buffer Pool List"></p><p>&emsp;LRU 算法使得最近最常使用的保持在 new sublist 中，而 old sublist 中则是一些不被经常使用的 page，也是可能在不久后被驱逐那部分 page。如上图所示，默认 3/8 的 buffer pool 被划分为 old sublist，中点被定义在 new sublist 的尾部和 old sublist 的头部的相遇边界点，当 Innodb 读取 page 到 buffer pool 时，这些新 page 默认插入到被插入到中点处。</p><p>&emsp;默认情况下，查询所需要的 page 将立刻被放到 new sublist 中，这部分的page也会活得更久（短时间内不会被驱逐）。扫表行为（如 mysqldump 操作或无 where 条件的 select）会带入大量数据到 buffer pool 中，将原来 old list 中大量的老 page 驱逐出 Buffer Pool，即使这些新 page 后面不被使用。相似的，由预读后台（read-ahead）线程加载且仅访问一次的 page 将移至 new sublist 的开头，这些场景中可以将频繁使用的 page 推到 old sublist 中，最终被驱逐，实际来讲，这些场景都需要进行优化，我们最终的目的是将频繁使用的 page 对象保留在 Buffer Pool 中，而且尽可能保留在 new sublist 中，因为这样查询会更快。</p><p>&emsp;为了让Innodb更好、更快的工作，在配置 Buffer Pool 时可以做下面的一些优化：</p><ol><li>理想状态下，可以将 buffer pool 设置为实际的内存大小，保留足够的内存处理无需过多的page，buffer pool 设置的越大，Innodb 就越表现的像基于内存的数据库，从磁盘读取一次数据，然后在后续读取期间从内存访问、操作数据。buffer pool 的配置是基于一块一块的（即chunks），一个块（chunk）默认是128M，buffer pool 的大小必须是 <code>buffer_pool_chunk_six</code><em><code>buffer_pool_instances</code>的整数倍，<code>buffer_pool_chunk_six</code>默认是128M，如<code>mysqld --innodb-buffer-pool-size=8G --innodb-buffer-pool-instances=16</code>就是将 Buffer pool 配置为8G（128M </em> 16 * 4 = 8G），当配置的值不满足上述的整数倍时，Innodb会自动调整为向上取整，如<code>mysqld --innodb-buffer-pool-size=9G --innodb-buffer-pool-instances=16</code>，9G不是整数倍，会被自动调整为10G。</li><li>对于足够内存的64位系统，可以将 buffer pool 分割为多个部分，以最大程度地减少并发操作之间的内存结构争用。</li></ol><h4 id="3-1-2-Change-Buffer"><a href="#3-1-2-Change-Buffer" class="headerlink" title="3.1.2 Change Buffer"></a>3.1.2 Change Buffer</h4><p>&emsp;Change Buffer 是一种特殊的数据结构，它缓存了那些不在 buffer pool 中的第二索引（即辅助索引）的 page 对象的改动，当一些insert、update、delete操作让缓存变化后，当这些 page 被其他的读行为加载到 buffer pool 中时，可能导致上述的改变最后合并到一起，这就是 change buffer（和它的名字一样，记录变化的缓存），结构如下：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3bf0c7c861f168eeccba673e96f5802f.png" alt="innodb-change-buffer"></p><p>&emsp;和聚簇索引不一样，第二索引通常不是唯一的，且插入是相对随机的顺序，delete、update 可能会影响索引树种那些不相邻的第二索引的page。稍后，当其他操作将受影响的 page 读入 buffer pool 时，合并缓存的更改可以避免从磁盘将辅助索引页读入缓冲池所需的大量随机访问I/O。在系统基本处于空闲状态或在缓慢关机期间运行的清除操作会定期将更新的索引页写入磁盘，和立即写入磁盘相比，清除操作可以更高效的将一系列的索引值写入磁盘块。当有很多受影响的行和需要更新的辅助索引值时，change buffer 合并更改的行为可能会持续几个小时，并且在此期间，磁盘I/O会增加，与磁盘绑定的查询会变得十分缓慢。Change buffer 合并的行为可能会在事务提交后、甚至服务器重启后持续进行。</p><p>&emsp;在内存方面，其实 change buffer 占据了 buffer pool 的内存的一部分。在磁盘方面，change buffer 是系统 tableSpace 的一部分，当数据库服务器关闭时，索引的更改将会被缓存。在 change buffer 中的缓存数据类型主要是由变量<code>innodb change buffering</code>维护管理。注意的是：Change buffer 不支持包含降序索引的列或者主键中包含降序的列。</p><h4 id="3-1-3-adaptive-hash-index"><a href="#3-1-3-adaptive-hash-index" class="headerlink" title="3.1.3 adaptive hash index"></a>3.1.3 adaptive hash index</h4><p>&emsp;自适应hash索引可以让 Innodb 表现得更像是一个基于内存的数据库，前提将buffer pool 的工作负载和 buffer pool 具有合适充足内存合理结合，并且不丧失事务特性和可靠性。自适应 hash 索引可以通过变量<code>innodb adaptive hash index</code>开启或者通过启动参数<code>--skip-innodb-adaptive-hash-index</code>关闭。</p><p>&emsp;基于观察到的搜索模式，使用索引的前缀构建hash索引，前缀长度无限制，但可能只有 B 树的部分值会出现在 hash 索引中，它是由那些使用频繁的 page 对象按需进行构建的。如果一个表几乎完全在主存中，hash 索引可以将索引值转换指针，它允许直接搜索任何元素，这样可以加速查询速度。Innodb 有一种监控索引搜索的机制，如果Innodb发现某些查询可以受益于构建的hash 索引，那它就会自动这么做。</p><p>&emsp;在某些场景下，hash 索引的加速要大大胜过监控搜索和维护 hash 索引结构的额外工作。在繁重的负载下（比如多并发连接），hash 索引可能成为争抢的资源。像<code>like</code>和<code>%</code>匹配符往往不能受益于 hash 索引，对于不能受益于自适应 hash 索引的负载，可以将其关闭以避免不必要的性能开销，因为很难预先预测自适应哈希索引特性是否适合于特定的系统和工作负载，所以考虑在启用和禁用它的情况下运行基准测试。MySQL5.6中的体系结构更改使禁用自适应哈希索引功能比在早期版本中更合适。</p><p>&emsp;自适应hash索引是被切割开的，每个hash索引绑定了某个特定的区域，每个区域都有独立的锁保护，具体的划分行为是由<code>innodb_adaptive_hash_index_parts</code>变量控制，这个值默认是8，最大可设置为512。</p><p>【注】innodb 引擎是具备自适应hash索引特性的，默认自动开启，可以通过<code>SHOW VARIABLES LIKE &#39;%adaptive_hash_index%&#39;</code>查看，当InnoDB 注意到某些索引值被使用的非常频繁时，它会在内存中基于 B-Tree 索引上再建立一个 hash 索引，这样就可以让B-Tree 也具备 hash 索引的特性（如快速的hash查找）。这个建立自适应 hash 索引是自动的、内部行为，用户几乎无法控制，只能进行上述基础的开关和区域锁的控制。hash 索引可以创建在一些特别长的字段上（如url），这样可以使用直接使用 hash 值进行快速查找。</p><h4 id="3-1-4-log-buffer"><a href="#3-1-4-log-buffer" class="headerlink" title="3.1.4 log buffer"></a>3.1.4 log buffer</h4><p>&emsp;log buffer 是主要内存区域，它保存着待写入磁盘日志文件的数据。log buffer 的大小由变量 <code>innodb_log_buffer_size</code> 设定，默认为16MB，log buffer 中的内容会定期刷入磁盘中，一个大的 log buffer 可以使得一个大事务在提交前不需要往磁盘写 redo log，因此如果有更新、插入、删除多条记录的大事务，增大 log buffer 的大小可以节省磁盘I/O。</p><h3 id="3-2-InnoDB-的磁盘结构"><a href="#3-2-InnoDB-的磁盘结构" class="headerlink" title="3.2 InnoDB 的磁盘结构"></a>3.2 InnoDB 的磁盘结构</h3><p>&emsp;前面的内容基本都是InnoDB的内存结构，InnoDB的磁盘组成结构组要包含下面的几个部分：</p><ul><li>表 Table；</li><li>索引 Index；</li><li>表空间 Tablespace；</li><li>双写缓冲 Doublewrite Buffer：双写缓冲是一块 InnoDB 将数据从 Buffer pool 中刷入磁盘前的存储区，只有数据在刷入 DW Buffer 后，InnoDB 才会将将数据正式写入磁盘的数据文件中。如果由于某种原因 MySQL 线程在写 Page 退出，那它可以在故障恢复时使用 DW Buffer 中副本数据进行数据恢复。虽然这种机制数据需要写2份，但它不会消耗2倍I/O资源，而是以一份完整的数据块（可能很大）调用操作系统的<code>fsync()</code>写入。默认双写开启，可通过变量<code>innodb_doublewrite</code>控制（0-disable,1-able）。</li><li>Redo Log：重做日志是一种基于磁盘的数据结构，用于在崩溃恢复期间更正由不完整事务写入的数据，正常操作时，redo log 会将那些会更改数据的请求（即写请求）或底层的api调用进行编码。但若更改数据的请求可能由于某些原因没有完成完整的数据文件的修改，那此时在MySQL服务重启初始化时，在正式接受处理外部连接前将会重放 Redo log 日志。Redo log 在磁盘上主要体现在文件<code>ib_logfile0</code>和<code>ib_logfile1</code>上。MySQL 写 redo log 时是以循环写的方式进行，redo log 中的数据按照受影响的记录进行编码；这些数据统称为重做，redo log 的过程是由一个不断增长的 LSN 值表示。和其他ACID的数据库引擎一样，它会在事务提交前刷入 redo log，InnoDB 使用组合提交（group commit）的设计来将多个 flush 请求组合批量提交，这样可以避免每次commit都flush一下请求。使用组提交，InnoDB只需向日志文件发出一次写入操作，即可对大约同时提交的多个用户事务执行提交操作，从而显着提高了吞吐量。</li><li>Undo Log：undo log 中记录了一个独立的读写事务撤销日志的集合，一个 undo log 记录了怎样撤销最近的事务对聚簇索引的修改。若另一个事务需要查看原始数据作为一致性读的一部分操作，那此时未更改的数据将会从 undo log 中取出。Undo log 存在于 undo log segment 中，而 undo log segment 又存在于 rollback segment 中，rollback segment 存在于系统表空间中（system tablespace）和 undo tablespace 中以及 temporary tablespace中。rollback segment 支持的事务数量取决于 rollback segment 中 undo 插槽的数量以及每个事务所需的 undo log 的数量。其中 rollback segment 中undo 插槽的数量主要是由InnoDB page size 的大小决定的，通常就是 pageSize/16（如PageSize为4K，那undo 插槽为4*1024/16）。一个事务最多分配4种类型的 undo logs：用户自定义表的<code>INSERT</code>操作、用户自定义表的<code>UPDATE</code>和<code>DELETE</code>操作、用户自定义临时表的<code>INSERT</code>操作、用户自定义临时表的<code>UPDATE</code>和<code>DELETE</code>操作。</li></ul><h4 id="3-2-1-表Table"><a href="#3-2-1-表Table" class="headerlink" title="3.2.1 表Table"></a>3.2.1 表Table</h4><p>&emsp;InnoDB的表它的索引可以在系统表空间（system tablespace）、表文件（file-per-table，可能译为每个表作为一个文件更好理解一点）空间或者通用表空间（general tablespace）。当开启<code>innodb_file_per_table</code>时（默认开启），InnoDB的表将会隐式的创建每个表文件的独立表空间，相反的，当<code>innodb_file_per_table</code>关闭时，InnoDB的表将会隐式的创建系统表空间。可以在创建表时通过<code>CREATE TABLE ... TABLESPACE [tablespace_name]</code>指定，这时就是创建在通用表空间中。</p><p>&emsp;当在 file-pre-table 表空间中创建表时，MySQL 默认会在数据库的目录下创建一个<code>.ibd</code>（即idbdata）表空间文件；当在 system 表空间中创建表时，将会在已存在的 idbdata 文件中创建，这个文件驻留在 MySQL的data目中；当在通用表空间中创建表时，它将会在已存在的通用表空间中通用表空间中的<code>.idb</code>创建。通用表空间文件可以在MySQL的data目录内部或外部创建。</p><p>&emsp;<code>.frm</code>文件中存储了各个表的数据字典（表定义），InnoDB和其他存储引擎不一样，它仍然会在内部数据目录的系统表空间中编码这些信息，当MySQL drop 表或库时，它将会删除一个或多个<code>.frm</code>文件以及InnoDB中相应的条目，但注意不能简单的通过移动<code>.frm</code>文件来移动InnoDB的表。注：8.0中已经取消了该文件。</p><p>&emsp;InnoDB表的行格式决定了这些行记录怎样存储在物理磁盘上，InnoDB支持4种行格式（每种都有不同的存储特性）：<code>REDUNDANT</code>、<code>COMPACT</code>、<code>DYNAMIC</code>（默认格式）和<code>COMPRESSED</code></p><p>&emsp;内部，InnoDB会将每个表的条目添加到数据字典中，这个条目中包含了表空间的名字。比如在test数据库中创建表t1，那这个表在数据字典中的条目的名字就是’test/t1’，这就表示可以在不同的数据库中创建同名的表，表名不会在数据字典撞上。</p><p>&emsp;外部表可以在data目录外创建，在外部创建表主要原因有：空间管理，I/O优化，或者将表存储在某些特殊性能和能力的特性的设备上。在外部创建表主要有下面几种方式：</p><ol><li><code>CREATE TABLE ... DATA DIRECTORY=[external_directory]</code>，<code>DATA DIRECTORY</code>方式支持每个表一个文件的方式（file-per-table），当指定<code>DATA DIRECTORY</code>时，表的数据文件（即<code>table_name.idb</code>文件）就会在数据库目录下的指定目录创建；</li><li></li></ol><h2 id="关于锁"><a href="#关于锁" class="headerlink" title="关于锁"></a>关于锁</h2><p>&emsp;MySQL中大体主要分为表锁和行锁：</p><ul><li>表锁：会在用户对表进行写操作（即<code>ALTER TABLE</code>操作包括插入、删除、更新等）时触发，先获取写锁，写锁阻塞其他的读、写操作，是目前锁策略中开销最小，也是最简单粗暴的一种方式。</li><li>行锁：可以提高并发度，但也加锁的开销，需要加到行级别，行锁是存储引擎自己实现的。<ul><li>record lock：</li><li>gap lock：</li><li>next-key lock：</li></ul></li></ul><p>其中MyIASM只支持表锁。显式锁可以通过<code>SELECT ... FOR UPDATE</code>或<code>SELECT ... LOCK IN SHARE MODE</code>来锁定，或者使用<code>LOCK TABLE</code>和<code>UNLOCK TABLE</code>来控制表锁，但这个行为和存储引擎无关，是在Server层实现的。</p><h3 id="共享锁和排他锁"><a href="#共享锁和排他锁" class="headerlink" title="共享锁和排他锁"></a>共享锁和排他锁</h3><p>&emsp;InnoDB 实现了2种标准的行级锁：shared lock 和 exclusive lock。共享锁（s锁）：允许持共享锁的事务读取行记录；排他锁（x锁）：允许持有排他锁的事务更新或删除行记录。当事务T1持有记录行r的共享锁，另一个事务T2再来请求行记录r的锁时，若请求的为共享锁那将会即刻获取，若请求的是排他锁则无法即刻获取。当事务T1持有记录行r的排他锁，那其他事务无法即刻获取r上的任意类型锁（共享锁和排他锁），必须等到T1的排他锁释放。</p><h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>&emsp;InnoDB 支持多重颗粒度的锁：允许行级锁和表级锁共存。当给某个表加一个排他锁时（如：<code>LOCK TABLES heartbeat WRITE</code>，释放锁是<code>UNLOCK TABLES</code>），为了实现多颗粒度级别的锁，InnoDB 引入了意向锁（intention lock）。首先<font color="red">意向锁是表级锁</font>，它标示着一个事务即将对于表中的某个行记录所要加的锁，同样的 intention lock 也分为意向共享锁（IS）和意向排他锁（IX），意向共享锁标识着某个事务将要对表中的每个行记录加共享锁（<code>SELECT ... FOR SHARE</code>），意向排他锁则标识将要对表中的每个记录加排他锁（<code>SELECT ... FOR UPDATE</code>）。意向锁的协议如下：</p><ul><li>在一个事务获取一个表中某行记录的共享锁之前，它必须先要获取表级别的 intention share lock 或者是更强的锁；</li><li>在一个事务获取一个表中某行记录的排他锁之前，它必须先要获取表级别的 intention exclusive lock 或者是更强的锁；</li></ul><p>S、X、IS、IX之间并不是都可以相互兼容，它们之间的兼容关系如下：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">X</th><th style="text-align:center">IX</th><th style="text-align:center">S</th><th style="text-align:center">IS</th></tr></thead><tbody><tr><td style="text-align:center">X</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td></tr><tr><td style="text-align:center">IX</td><td style="text-align:center">×</td><td style="text-align:center">√</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">S</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">IS</td><td style="text-align:center">×</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr></tbody></table><p>当前即将加的锁和已有的锁只有兼容的时候才能加上，否则必须等到已有冲突锁释放，如果没有这个机制很可能导致死锁。</p><p>&emsp;intention lock 不会阻止除完整表请求以外的任何请求（例如<code>LOCK TABLES ... WRITE</code>）。意向锁的主要目的是显示有人正在锁定一行，或者将要锁定表中的一行。</p><h3 id="record-lock"><a href="#record-lock" class="headerlink" title="record lock"></a>record lock</h3><p>&emsp;记录锁是索引记录上的锁，比如<code>SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE</code>，它将阻止其他事务读对 c1=10 的记录进行删、改、插入行为。记录锁始终锁定索引记录，即使定义的表没有索引，因为InnoDB会自动为没有聚簇索引的表创建隐式聚簇索引。</p><h3 id="gap-lock"><a href="#gap-lock" class="headerlink" title="gap lock"></a>gap lock</h3><p>&emsp;间隙锁是一种锁住索引记录之间间隙的锁（如<code>SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE</code>），或者锁住在第一个索引记录之前的锁、亦或者是锁住最后一个索引记录之后锁。间隙锁可以防止其他事务将一些中间值插入到所在区间，无论该列中是否已有这样的值，都无法插入，如上述是锁住了10~20，即使不存在15的记录，15记录仍然无法插入。间隙锁将会作用于0个或1个也或是多个索引值。间隙锁是性能和并发性之间权衡的一部分，并且在某些事务隔离级别中使用，而在其他级别中则不使用。</p><p>&emsp;那些是使用唯一索引检索某个唯一行记录时是不需要间隙锁的（注：但不包含搜索条件中只有那些联合唯一索引），如：<code>SELECT * FROM child WHERE id = 100</code>这个SQL，若 id 上具有唯一索引，那对 id=100 记录加的锁就是 index-record lock；但如果 id 上没有索或者没有唯一索引，那这个SQL就会锁住 id=100 前面的间隙，此时就是间隙锁，<font color="red">这里检索的字段上一定是无索引的，否则就成了index-record lock</font>。示例如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 初始数据准备</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`test`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT <span class="keyword">COMMENT</span> <span class="string">'id'</span>,</span><br><span class="line">  <span class="string">`name`</span> <span class="built_in">varchar</span>(<span class="number">32</span>) <span class="keyword">DEFAULT</span> <span class="string">'default'</span> <span class="keyword">COMMENT</span> <span class="string">'名字'</span>,</span><br><span class="line">  <span class="string">`create_time`</span> <span class="built_in">timestamp</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">COMMENT</span> <span class="string">'创建时间'</span>,</span><br><span class="line">  <span class="string">`update_time`</span> <span class="built_in">timestamp</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">COMMENT</span> <span class="string">'更新时间'</span>,</span><br><span class="line">  <span class="string">`property`</span> <span class="built_in">varchar</span>(<span class="number">32</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`second_index`</span> <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'普通第2索引'</span>,</span><br><span class="line">  <span class="string">`no_index`</span> <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'无索引字段'</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="string">`si`</span> (<span class="string">`second_index`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">15</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb3 <span class="keyword">COMMENT</span>=<span class="string">'测试表'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span>(property, second_index,no_index) <span class="keyword">VALUES</span>(<span class="string">"prop1"</span>, <span class="number">9</span>,<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 会话1</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> heartbeat <span class="keyword">WHERE</span> server_id=<span class="number">1</span> <span class="keyword">LOCK</span> <span class="keyword">IN</span> <span class="keyword">SHARE</span> <span class="keyword">MODE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 会话2，发现在等待间隙锁</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span>(property, second_index,no_index) <span class="keyword">VALUES</span>(<span class="string">"prop1"</span>, <span class="number">6</span>,<span class="number">6</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 杀掉等待的进程</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">PROCESSLIST</span></span><br><span class="line"><span class="keyword">KILL</span> xx</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看未提交的事务</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="string">`information_schema`</span>.<span class="string">`INNODB_TRX`</span></span><br></pre></td></tr></table></figure><p>&emsp;间隙锁可以通过将事务隔离级别设置为 RC 来主动关闭。</p><h3 id="next-key-lock"><a href="#next-key-lock" class="headerlink" title="next-key lock"></a>next-key lock</h3><p>&emsp;next-key lock 就是 record lock 和 gap lock 的组合，它会给当前索引记录加 record lock，同时在该索引记录之前的间隙上加间隙锁。</p><p>&emsp;InnoDB 行级锁是加锁方式是当它搜索或扫描一个表索引时，它将会在遇到的索引记录上加共享或排他锁（可能表述为扫描到一行就对这行加锁）。因此，MySQL的行级锁实际就是 index-record lock。当对一个索引记录上加上 next-key lock 时，实际也会影响这个索引记录之前的间隙，索引上的 next-key lock 是一个 index-record lock 加上这个索引记录之前间的间隙锁。一旦对某个索引记录加了共享锁或者排他锁，那就不能对这个记录以及它之前的记录进行操作。</p><p>&emsp;默认情况下，InnoDB使用的是 RR 隔离级别，这种情况下，InnoDB 使用 next-key lock 搜索或扫描索引，这样做可以避免幻影读（又学了一个单词 phantom - /ˈfæntəm/）。</p><h3 id="Auto-Inc-lock"><a href="#Auto-Inc-lock" class="headerlink" title="Auto-Inc lock"></a>Auto-Inc lock</h3><p>&emsp;AUTO-INC 锁是一种特殊的表级锁，发生在插入存在自增列（AUTO_INCREMENT）记录的时候。如果一个事务正在向表中插入值，其他事务必须等到这个事务插入完成，以便第一个事务收到那个连续的主键值。8.0 默认是交错模式（即<code>innodb_autoinc_lock_mode</code>为2，5.X的版本默认是连续模式1会加锁，但具体是从哪个版本开始就忘了）。Auto-Inc Lock 可以的模式可以是期望可预测的自增值、还是更期望插入行为的更高并发。在交错模式下是不会加 AUTO-INC 锁，需要设置为连续模式1。</p><p>&emsp;对于自增锁的3种模式有如下的说明（通过变量<code>innodb_autoinc_lock_mode</code>设置，需要在配置文件中设置）：</p><ul><li><p>0：传统锁模式（traditional lock mode），它在变量<code>innodb_autoinc_lock_mode</code>引入之前就存在了，它在传统的锁模式选项用于向后兼容性、性能测试以及解决“混合模式插入”问题，因为语义上可能存在差异。在传统锁模式下，所有的 <code>insert</code> like 语句将获取一个特殊级别的表级别的 AUTO-INC 锁，这个锁将持有到语句的最后（而不是事务的最后），为的是确保自增值可预知的、可重复的顺序按照<code>insert</code>语句的顺序分配出去，并确保自增值是按<code>insert</code>循序连续不断的；在主从架构上的 statement-base 复制（是否就是binlog的格式），当SQL语句被复制到从节点上时，从节点上的自增列将会使用和主节点上一样的值。但若多条<code>insert</code>语句插入的结果是未知的，在 statement-based 级别的传播出去的自增值是不可靠。上面描述的场景可以用下面2个事务的示例来描述：Tx1（插入1000条） - <code>INSERT INTO t1 (c2) SELECT 1000 rows from another table ...</code>，Tx2（插入1条） - <code>INSERT INTO t1 (c2) VALUES (&#39;xxx&#39;)</code>，对于事务1在执行时，Innodb是不能提前获知<code>insert into t1 select ...</code>这个语句会取出多少行记录，当它执行时一次分配一个自增值。它会持有表级锁直到在该语句的末尾，一次只能执行一个引用表t1的<code>INSERT</code>语句，并且不会交错使用不同的语句生成自动递增编号。但是事务1生成的自增值是连续的，事务2中生成的自增值要么比事务1中所有自增值大，要么比它所有自增值要小，这取决哪个语句先执行。若从节点通statement-base格式的binlog重放SQL，只要他们的执行顺序和主节点上一致就没有问题，因此，在语句结束之前保持的表级锁使使用自动增量的<code>INSERT</code>语句可以保证安全地用于基于语句的主从复制，但也因此限制Innodb多事务的并发。若上述行为没有表级锁，事务2中的自增键的值去取决于该语句的执行时机，比如事务2中的行为在事务1插入行为正在进行时执行（既不是在事务1执行之前，也不是在事务1执行之后），分配给2个插入语句的特定自增值是不确定的，因运行时机而定；</p></li><li><p>1：连续锁模式（consecutive lock mode），<font color="red">这是默认的锁模式</font>。在连续锁模式下，”bulk insert” 使用特殊的 AUTO-INC 表级锁，且持有到语句的最后，包含了<code>insert ... select</code>、<code>replace ...select</code>和<code>load data</code>，每次有且只有那一个持有 AUTO-INC 表级锁的语句可以执行，若原始表的批量插入行为和目标表不一样，那目标表上的AUTO-INC锁加上的时机为：在原始表第一行满足条件的记录被选中且加上共享锁时加上。若目标表和原始表的批量插入行为一致，那AUTO-INC锁会在所有行的共享锁被获取时加上。对于简单插入行为（即可以事先知道插入的行数），可以通过在互斥量（一种轻量级锁）的控制下获取所需数量的自增值，这个锁仅仅在分配自增值期间持有，而不持有到语句完成，这样可以避免表级别的 AUTO-INC 锁，除非另一个事务持有AUTO-INC锁，此时简单插入将会等待AUTO-INC锁，就像是批量插入的行为一样。在这种锁模式下，出现不能预知行数的插入语句时(且当在语句执行过程中分配自增值时)，所有的自增值都将会被连续分配，这样可以保证基于语句的主从复制(statement-based)的数据安全；连续锁模式可以可显着提高可伸缩性，同时可安全地用于基于语句的复制，此外，与“传统”锁模式一样，任何给定语句分配的自动增量编号都是连续的。但有种例外情况，对于使用自增的SQL语句，和传统锁模式相比在语义上没有区别。</p></li><li><p>2：交叉锁模式（interleaved lock mode），这种锁模式下，插入语句不会使用AUTO-INC锁，且多条语句可以同时执行，交叉锁模式时最快、可扩展性最高的锁模式，但在基于语句主从复制的情况下，从节点从binlog重放SQL语句时它并不安全。交叉锁模式下，在所有插入语句并发执行时，自增值可以保证唯一且单调增，但由于是多个语句同时生成数值（数字分配在语句之间交错），所以任何给定的插入语句生成的自增值并不是连续的（和它的名字一样，是交错的）。若执行的语句仅仅是简单插入，且他们插入的行数是可预知的，那对于单个语句中生成的数值则是没间隙的，除非是混合模式的插入场景，当执行批量插入时，分配出来的自增值可能会出现间隙。</p></li></ul><p>我们需要更改<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-auto-increment-handling.html" rel="external nofollow noopener noreferrer" target="_blank"><code>innodb_autoinc_lock_mode</code>的配置</a>（0-标识传统锁模式，1-标识，2-标识），这是一种特殊的锁机制，他不是在一个事务完成后才释放，而是在完成对自增键的增长后就立刻释放，从而提升并发效率。</p><p>&emsp;InnoDB推荐主键顺序插入（即定义为<code>AUTO_INCREMENT</code>），这样可以减少频繁的页分裂和碎片的产生，特别是I/O密集型应用，最好避免随机（不连续且值分布范围很大）的聚簇索引（比如使用UUID来作主键性能会很差且索引占用空间大）。自增主键的情况下，每条记录都存储在上一条记录的后面，在一个页被插满（达到页的最大填充因子，默认15/16，留出部分空间以便后面修改）后继续插入会插入到下一个新页，数据加载是顺序加载，主键页就会近似于被顺序的记录填满，而若主键是随机的，InnoDB无法简单的总是把新行记录插入到索引的最后（因为B-Tree叶子节点是顺序的），这样就需要为新行寻找合适的位置并分配空间，通常是已有数据的中间，这种为新行分配空间的行为会导致频繁的页分裂，页分裂会导致数据的大量移动，页会变得稀疏且填充不规则，最终产生碎片，关于页分裂和页合并可以参考<a href="https://zhuanlan.zhihu.com/p/98818611" rel="external nofollow noopener noreferrer" target="_blank">这篇文章</a>。当然，顺序主键也并非是绝对的友好，对于高并发应用，InnoDB按主键顺序插入可能会造成明显的竞争，所有的插入都发生在主键的上界，并发插入可能导致间隙锁的竞争；另一个是<code>AUTO_INCREMENT</code>锁机制，它是一种描述用于生成自增值的锁机制。</p><p>【注】在描述AUTO-INC LOCK时的一些概念：</p><ul><li>insert-like 语句：插入型语句，指所有可以在表中生成新行的语句，包含<code>insert</code>、<code>insert...select</code>、<code>replace</code>、<code>replace ... select</code>以及<code>load data</code>，也包含下面的简单插入（simple inserts）、批量插入(bulk inserts)和混合模式插入(mixed-mode inserts)。</li><li>simple inserts：可预测的简单插入，这种插入可以提前预测到将要插入的行数，包含了没有嵌套子查询的单个和批量的<code>insert</code>、<code>replace</code>语句，但不包含了<code>insert ... on duplicate key update</code>；</li><li>bulk inserts：不可预测的批量插入，一些需要生成自增键值的批量插入语句，但具体的数量又是不可预测的，这种场景包含了<code>insert ... select</code>、<code>replace ... select</code>和<code>load data</code>语句，不包含可预知数量的<code>insert</code>行为，Innodb会在处理该行数据时为<code>AUTO_INCREMENT</code>的列生成新值；</li><li>mixed-mode inserts：混合插入，就是一些简单的插入语句，在这个语句中指定了一些自增值，但没有为所有新纪录行指定，比如：<code>INSERT INTO t1 (c1,c2) VALUES (1,&#39;a&#39;), (NULL,&#39;b&#39;), (5,&#39;c&#39;), (NULL,&#39;d&#39;);</code>，其中 c1 是自增列。另一种情况就是<code>insert ... on duplicate key update</code>，这个就是最糟的场景（<code>insert</code>后面跟<code>update</code>，因为给自增列分配的值在 update 语句中可能会被使用，但也可能不被使用）。</li></ul><p>【注】<code>insert into t1 select * from t2 where index_field&gt;xx</code>加锁规则：t1是锁表（前提是表必须存在），t2是逐步锁，扫描一个锁一个，随着扫描的行数越来越多锁的行也会越来越多，直到后面t2整表被锁，完成数据复制，这种逐行锁还是有主键或索引作为条件的情况下，若后面跟的条件是非主键，那会导致t2在一开始就直接被整表锁（区别重要）。为了避免t2被锁走全表扫描，最好在后面追加<code>FORCE INDEX (index_filed) where index_filed=xxx</code>，这样就会强制走索引检索，从而避免现用业务表t2被全表锁住，影响业务服务。若数据量巨大，慎用<code>insert into ... select ...</code>，它只是插入数据，且目标表必须事先建好，其次它是DML语句（数据操作语言-database manipulation language，SQL中处理数据等操作统称为数据操纵语言），完成后需要提交才能生效。<code>CREATE TABLE AS SELECT</code> 是DDL语句（数据定义语言-database definition language，用于定义和管理 SQL 数据库中的所有对象的语言 ），执行完直接生效，不提供回滚，效率比较高，执行过程中全程锁表，可以在深更半夜停服的情况下使用。</p><h2 id="关于-MySQL-中指定属性宽度"><a href="#关于-MySQL-中指定属性宽度" class="headerlink" title="关于 MySQL 中指定属性宽度"></a>关于 MySQL 中指定属性宽度</h2><p>&emsp;</p><h2 id="关于索引"><a href="#关于索引" class="headerlink" title="关于索引"></a>关于索引</h2><p>&emsp;索引可以帮助快速定位数据。最常见的索引就是 B-Tree，它的叶子节点是按照顺序存储数据的，所以 MySQL 可以做 <code>ORDER BY</code> 和 <code>GROUP BY</code> 之类的操作，因为数据是有序的，所以B-Tree 会将相关的列值都存储在一起，因为索引中存储了实际的列值，所以某些查询只使用索引就可以完成全部查询。索引的优点：</p><ol><li>索引可以减少服务器需要扫描的数据量；</li><li>索引可以避免排序和临时表；</li><li>索引可以将随机I/O变为顺序I/O；</li></ol><p>&emsp;几个索引的使用建议：</p><ol><li>独立的列：尽量不要在<code>where</code>后面的条件中对列属性作函数操作，如<code>age -1 = 4</code>，这种情况 MySQL 中的 age 索引将会失效，它无法自动解析这种行为，所谓独立的列就是让列单独在一侧，运算的逻辑不要放在列所在一侧，而应该放在另一侧，这样索引才可以正常使用，所以上述的sql应该优化为 <code>age = 4+1</code>；</li><li>索引简短：尽量不要对一些很长的列属性进行索引创建，比如爬虫时持久化的网站url，对这个字段创建索引只会让索引变得巨大且缓慢。有几种方式来避免这种大型字段索引的创建：<ul><li>2.1 使用 hash 索引：如果刚好选用的存储引擎不支持 hash 索引，则手动模拟 hash 索引（如<code>CRC32</code>函数10位），但表中需要额外维护一个该字段的 hash 值并对该字段建立索引，每次查询该属性的条件值时，则可以变相使用那个额外的 hash 值字段来进行替换检索，这是一种非常高效的索引方式，因为索引将变得很小且快，至于维护可以使用触发器来帮助在插入或更新时 hash 值的自动更新。【注】这种方式不要使用<code>SHA1()</code>(40位)或<code>MD5()</code>(32位)，这2个 hash 函数计算结果相对耗时且结果很长，且这个2个 hash 函数目的是为了最大限度的消除冲突，如果数据非常多（大于9W），使用<code>CRC32</code>冲突可能会很多，这时在<code>where</code> 追加对应业务属性字段条件（如<code>where url_hash_value=CRC32(&#39;https://pan.aliyun.com&#39;) and url=&#39;https://pan.aliyun.com&#39;</code>），而不再是<code>where url_hash_value=CRC32(&#39;https://pan.aliyun.com&#39;)</code>（数据量小时可以直接使用），或者可以使用<code>FNV64</code>(它比<code>CRC32()</code>冲突要少得多)、自定义简单的函数来做 hash 函数；</li><li>2.2 前缀索引：只对索引开始的部分字符，这样索引就会变小提升效率，但由于是只对前缀部分的内容做的索引，所以就会降低索引的选择性。如果对<code>BLOB</code>、<code>TEXT</code>类型字段建立索引时必须使用前缀索引，但前缀的选择性也需要足够高，又不能太长，通常是将频繁搜索的值列出来，然后不断增加前缀索引的长度，直到整个前缀索引的选择性接近完整列的选择性即可，在实际比较时可以直接使用<code>count(DISTINCT(LEFT(索引字段), 前缀长度)))/Count(*)</code> SQL 来调整前缀长度观察该长度的索引的选择性。【注】创建前缀索引<code>KEY (索引字段(前缀长度))</code>，前缀索引无使用<code>ORDER BY</code>和<code>GROUP BY</code>操作，也无法做覆盖扫描。</li></ul></li><li>多列索引：即联合索引，对多个字段建立索引，遵循最左匹配原则。常规的2种建立联合索引的法则：将使用越频繁的列放在联合索引的越左侧、将选择性越高的列放在联合索引的越左侧。</li><li>聚簇索引：一个表只允许有一个聚簇索引（覆盖索引可以模拟多个聚簇索引的情况），通常是主键，若未定义主键，InnoDB会隐式定义一个主键来作聚簇索引。聚簇索引的的结构是-叶子节点包含了行的全部数据，但节点只包含索引列，所以通常非聚簇索引（二级索引）的查找往往都涉及到回表的操作，它只保存了主键的值。聚簇索引的有点：<ul><li>4.1 可以将相关数据保存在一起，根据主键聚集数据时，只需要从磁盘读取少量数据；</li><li>4.2 速度快，索引和数据保存在同一个B-Tree中，获取数据快；</li><li>4.3 覆盖索引的扫描可以直接使用叶节点中的主键值；</li></ul></li><li>覆盖索引：当一个索引包含（覆盖）所有所需字段，那此时就不需要二次回表（我们知道，通常除了主键索引外，其他索引的查询一般都是先找到主键，然后在根据主键定位叶节点的数据，需要二次回表），这样的索引就是覆盖索引。Innodb的二级索引在叶节点保存了主键值，若二级索引可以覆盖查询，可以避免对主键索引的二次查询。但并不是所有类型索引都可以成为覆盖索引，覆盖索引必须存储索引列的值，而 hash 索引、空间索引以及全文索引都不会存储索引列的值，所以只能使用 B-Tree 做覆盖索引。索引覆盖查询时，SQL执行计划Extra可以看“Using index”信息（不要和type搞混，type是标识查询访问数据的方式或者是MySQL查找行的方式，即连接方式join type）。其实个人理解下来覆盖索引会出现在2个场景中：一种是主键查询，另一种就是联合索引查询联合列。覆盖索引的优化场景需要合理利用二级索引叶子节点都包含了主键。</li></ol><p>【注】索引的选择性=不重复的索引值（基数）/总记录数=<code>COUNT(DISTINCT(索引字段))/COUNT(*)</code>，选择性越高查询效率就越高，它可以在查找时过滤更多无用行。唯一索引的选择性是1，它也是最好的索引选择，因为每条记录的唯一索引都不一样=N/N，再如<code>gender</code>只会有男、女2个值，那么gender索引的选择性=2/N，随着记录的增加，这个索引的选择性多越来越低，所以通常这种字段就也没有建立索引的必要。</p><p>【注】InnoDB推荐主键顺序插入（即定义为<code>AUTO_INCREMENT</code>），这样可以减少频繁的页分裂和碎片的产生，特别是I/O密集型应用，最好避免随机（不连续且值分布范围很大）的聚簇索引（比如使用UUID来作主键性能会很差且索引占用空间大）。自增主键的情况下，每条记录都存储在上一条记录的后面，在一个页被插满（达到页的最大填充因子，默认15/16，留出部分空间以便后面修改）后继续插入会插入到下一个新页，数据加载是顺序加载，主键页就会近似于被顺序的记录填满，而若主键是随机的，InnoDB无法简单的总是把新行记录插入到索引的最后（因为B-Tree叶子节点是顺序的），这样就需要为新行寻找合适的位置并分配空间，通常是已有数据的中间，这种为新行分配空间的行为会导致频繁的页分裂，页分裂会导致数据的大量移动，页会变得稀疏且填充不规则，最终产生碎片，关于页分裂和页合并可以参考<a href="https://zhuanlan.zhihu.com/p/98818611" rel="external nofollow noopener noreferrer" target="_blank">这篇文章</a>。当然，顺序主键也并非是绝对的友好，对于高并发应用，InnoDB按主键顺序插入可能会造成明显的竞争，所有的插入都发生在主键的上界，并发插入可能导致间隙锁的竞争；另一个是<code>AUTO_INCREMENT</code>锁机制，它是一种描述用于生成自增值的锁机制，可用值有：</p><ul><li><p>0：传统锁模式（traditional lock mode），传统的锁模式选项用于向后兼容性、性能测试以及解决“混合模式插入”问题，因为语义上可能存在差异。在传统锁模式下，所有的 <code>insert</code> like 语句将获取一个特殊级别的表级别的 AUTO-INC 锁，这个锁将持有到语句的最后（而不是事务的最后），为的是确保自增值可以以可预知的、可重复的顺序按照<code>insert</code>语句的顺序分配出去，并确保自增值是按<code>insert</code>循序连续不断的；在主从架构上的 statement-base 复制（是否就是binlog的格式），当SQL语句被复制到从节点上时，从节点上的自增列将会使用和主节点上一样的值。但若多条<code>insert</code>语句插入的结果是未知的，在 statement-based 级别的传播出去的自增值是不可靠。上面描述的场景可以用下面2个事务的示例来描述：Tx1（插入1000条） - <code>INSERT INTO t1 (c2) SELECT 1000 rows from another table ...</code>，Tx2（插入1条） - <code>INSERT INTO t1 (c2) VALUES (&#39;xxx&#39;)</code>，对于事务1在执行时，Innodb是不能提前获知<code>insert into t1 select ...</code>这个语句会取出多少行记录，当它执行时一次分配一个自增值。它会持有表级锁直到在该语句的末尾，一次只能执行一个引用表t1的<code>INSERT</code>语句，并且不会交错使用不同的语句生成自动递增编号。但是事务1生成的自增值是连续的，事务2中生成的自增值要么比事务1中所有自增值大，要么比它所有自增值要小，这取决哪个语句先执行。若从节点通statement-base格式的binlog重放SQL，只要他们的执行顺序和主节点上一致就没有问题，因此，在语句结束之前保持的表级锁使使用自动增量的<code>INSERT</code>语句可以保证安全地用于基于语句的主从复制，但也因此限制Innodb多事务的并发。若上述行为没有表级锁，事务2中的自增键的值去取决于该语句的执行时机，比如事务2中的行为在事务1插入行为正在进行时执行（既不是在事务1执行之前，也不是在事务1执行之后），分配给2个插入语句的特定自增值是不确定的，因运行时机而定；</p></li><li><p>1：连续锁模式（consecutive lock mode），<font color="red">这是默认的锁模式</font>。在连续锁模式下，”bulk insert” 使用特殊的 AUTO-INC 表级锁，且持有到语句的最后，包含了<code>insert ... select</code>、<code>replace ...select</code>和<code>load data</code>，每次有且只有那一个持有 AUTO-INC 表级锁的语句可以执行，若原始表的批量插入行为和目标表不一样，那目标表上的AUTO-INC锁加上的时机为：在原始表第一行满足条件的记录被选中且加上共享锁时加上。若目标表和原始表的批量插入行为一致，那AUTO-INC锁会在所有行的共享锁被获取时加上。对于简单插入行为（即可以事先知道插入的行数），可以通过在互斥量（一种轻量级锁）的控制下获取所需数量的自增值，这个锁仅仅在分配自增值期间持有，而不持有到语句完成，这样可以避免表级别的 AUTO-INC 锁，除非另一个事务持有AUTO-INC锁，此时简单插入将会等待AUTO-INC锁，就像是批量插入的行为一样。在这种锁模式下，出现不能预知行数的插入语句时(且当在语句执行过程中分配自增值时)，所有的自增值都将会被连续分配，这样可以保证基于语句的主从复制(statement-based)的数据安全；连续锁模式可以可显着提高可伸缩性，同时可安全地用于基于语句的复制，此外，与“传统”锁模式一样，任何给定语句分配的自动增量编号都是连续的。但有种例外情况，对于使用自增的SQL语句，和传统锁模式相比在语义上没有区别。</p></li><li><p>2：交叉锁模式（interleaved lock mode），这种锁模式下，插入语句不会使用AUTO-INC锁，且多条语句可以同时执行，交叉锁模式时最快、可扩展性最高的锁模式，但在基于语句主从复制的情况下，从节点从binlog重放SQL语句时它并不安全。交叉锁模式下，在所有插入语句并发执行时，自增值可以保证唯一且单调增，但由于是多个语句同时生成数值（数字分配在语句之间交错），所以任何给定的插入语句生成的自增值并不是连续的（和它的名字一样，是交错的）。若执行的语句仅仅是简单插入，且他们插入的行数是可预知的，那对于单个语句中生成的数值则是没间隙的，除非是混合模式的插入场景，当执行批量插入时，分配出来的自增值可能会出现间隙。</p></li></ul><p>我们需要更改<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-auto-increment-handling.html" rel="external nofollow noopener noreferrer" target="_blank"><code>innodb_autoinc_lock_mode</code>的配置</a>（0-标识传统锁模式，1-标识，2-标识），这是一种特殊的锁机制，他不是在一个事务完成后才释放，而是在完成对自增键的增长后就立刻释放，从而提升并发效率。</p><p>【注】一些专有概念：</p><ul><li><code>insert</code>-like statements：插入型语句，所有可以在表中生成一个新行的语句，包含<code>insert</code>、<code>insert...select</code>、<code>replace</code>、<code>replace ... select</code>以及<code>load data</code>，也包含简单插入、批量插入和混合模式插入。</li><li>simple inserts：简单插入，这种插入可以提前决定一些待插入的行，包含了没有嵌套子查询的单个和批量的<code>insert</code>、<code>replace</code>语句，但不包含了<code>insert ... on duplicate key update</code>；</li><li>bulk inserts：批量插入，一些需要生成自增键值的批量插入语句，但具体的数量又不知道，这种场景包含了<code>insert ... select</code>、<code>replace ... select</code>和<code>load data</code>语句，不包含清楚数量的<code>insert</code>行为，Innodb会在处理该行数据时为<code>AUTO_INCREMENT</code>的列生成新值；</li><li>mixed-mode inserts：混合插入，就是一些简单的插入语句，在这个语句中指定了一些自增值，但没有为所有新纪录行指定，比如：<code>INSERT INTO t1 (c1,c2) VALUES (1,&#39;a&#39;), (NULL,&#39;b&#39;), (5,&#39;c&#39;), (NULL,&#39;d&#39;);</code>，其中 c1 是自增列。另一种情况就是<code>insert ... on duplicate key update</code>，最糟的场景就是<code>insert</code>后面跟着<code>update</code>，但分配的自增列值不确定是否会被使用。</li></ul><p>【注】<code>insert into t1 select * from t2 where index_field&gt;xx</code>加锁规则：t1是锁表（前提是表必须存在），t2是逐步锁，扫描一个锁一个，随着扫描的行数越来越多锁的行也会越来越多，直到后面t2整表被锁，完成数据复制，这种逐行锁还是有主键或索引作为条件的情况下，若后面跟的条件是非主键，那会导致t2在一开始就直接被整表锁（区别重要）。为了避免t2被锁走全表扫描，最好在后面追加<code>FORCE INDEX (index_filed) where index_filed=xxx</code>，这样就会强制走索引检索，从而避免现用业务表t2被全表锁住，影响业务服务。若数据量巨大，慎用<code>insert into ... select ...</code>，它只是插入数据，且目标表必须事先建好，其次它是DML语句（数据操作语言-database manipulation language，SQL中处理数据等操作统称为数据操纵语言），完成后需要提交才能生效。<code>CREATE TABLE AS SELECT</code> 是DDL语句（数据定义语言-database definition language，用于定义和管理 SQL 数据库中的所有对象的语言 ），执行完直接生效，不提供回滚，效率比较高，执行过程中全程锁表，可以在深更半夜停服的情况下使用。</p><h2 id="3-InnoDB-的排序"><a href="#3-InnoDB-的排序" class="headerlink" title="3. InnoDB 的排序"></a>3. InnoDB 的排序</h2><p>&emsp;使用索引来满足<code>ORDER BY</code>进行排序，可以避免执行<code>filesort</code>排序（文件排序）时涉及的额外排序操作。只要那些没有使用索引的区域和所有<code>ORDER BY</code>列都是在<code>WHERE</code>语句中的常量时，那么甚至可以在非精确匹配索引时使用索引。若索引没有包含查询所需的所有列，那只有在使用索引比其他方式代价更小的场景下才会使用索引。</p><p>&emsp;若有索引建立在k1、k2上，那<code>select * from [table_name] order by k1,k2</code>语句可能会使用上面的索引进行排序，当然只是可能会使用上述索引，优化器如何做，具体是否使用需要取决于读取索引是否比全表扫描更加高效（若不在索引中的列必须读取，那就会进行全表扫）。当然上述的<code>select *</code>表明了获取所有的列（而不是只有索引k1和k2的列），这时如果扫描整个索引，然后再查找那些不在索引列的列，这样干的代价可能相比全表扫然后对结果进行排序更大，因此，优化器在上述语中可能不太会使用索引k1、k2，而直接全表扫。另外，需要注意的是，对于二级索引叶子节点存放的是主键，所以某种意义上，所有的二级索引都是隐含了主键，所以若将上述SQL改为<code>select pk,k1,k2 from [table_name] order by k1,k2</code>，那和<code>select k1,k2 from [table_name] order by k1,k2</code>一样都会使用索引k1、k2来进行排序。</p><p>&emsp;在某些场景下，MySQL是无法使用索引进行<code>ORDER BY</code>操作，即使可以对<code>WHERE</code>中的条件可以命中索引且使用索引查找到记录。有下面几个场景：</p><ul><li>查询对不同的索引使用<code>ORDER BY</code>：如<code>select * from [table_name] Order by k1,k2</code>；</li><li>查询对一个索引的不连续部分使用<code>ORDER BY</code>：如<code>select * from [table_name] where k2=constant order by k1_part1,k1_part2</code>；</li><li>混合使用升序和降序：如<code>select * from [table_name] order by k1_part1 desc, k2_part2 asc</code>；</li><li>查询使用的索引和排序使用的索引不一样：如<code>select * from [table_name] where k2=constant order by k1</code>；</li><li>排序的字段非原始列名，可能做了一些运算：如<code>SELECT * FROM t1 ORDER BY ABS(key);</code>，再如<br><code>SELECT * FROM t1 ORDER BY -key;</code>；</li><li>查询中<code>join</code>多表，<code>order by</code>中的列并不是来自于首个获取数据的固定表（<code>explain</code>输出的第一个非<code>const</code>类型的表）；</li><li>查询中<code>order by</code>和<code>group by</code>的表达式不一样；</li><li><code>order by</code>中的列是建立了索引，但仅仅是前缀索引，这种前缀索引是不能完全用于解决排序问题的，因为前缀索引位置之后的内容是无法区分的，此时是需要进行文件排序的；</li><li>索引没有按序存储行记录，比如 memory 表中的 hash 索引；</li></ul><p>&emsp;索引是否可以用于排序可能会被列的别名所影响，若<code>t1.a</code>已经建立了索引，<code>select a from t1 order by a</code>在这个语句中，查询语句中的列名为<code>a</code>，它指向的是<code>t1.a</code>，在<code>order by</code>中也就指向了a，所以在排序过程中索引<code>t1.a</code>可以被使用；又如<code>select abs(a) as a from t1 order by a</code>，这里面<code>order by</code>后面的<code>a</code>是指的<code>abs(a)</code>，而非原始<code>a</code>列；再如<code>select abs(a) as b from t1 order by a</code>就可以使用<code>t1.a</code>的索引进行排序。</p><p>&emsp;默认情况下，若</p><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>&emsp;通常一个查询的流程如下：客户端发送查询SQL到服务端 -&gt; 服务端查缓存，若命中，直接返回缓存结果 -&gt; 服务端进行SQL解析、预处理，由优化器生成对应的执行计划 -&gt; 根据执行计划，调用存储引擎的API执行查询 -&gt; 返回结果给客户端。对于一个MySQL连接（线程），某一时刻有且仅有一个状态，可以通过命令 <code>SHOW FULL PROCESSLIST</code> 指令来查看，对应接结果中的Command列，主要有下面几种状态：</p><ul><li><code>Sleep</code>：线程正在等待客户端发送新的请求；</li><li><code>Query</code>：线程正在执行查询或正在将查询的结果发送给客户端；</li><li><code>Locked</code>：MySQL服务层，表示线程正在等待锁，须是引擎级别的锁（如行锁），并不会体现线程状态中；</li><li><code>Analyzing and statistics</code>：线程正在收集存储引擎的统计信息，并生成查询的执行计划；</li><li><code>Copying to tmp table [on disk]</code>：线程正在查询，并将结果复制到一个临时表，这种状态要么再做 GROUP BY 操作，要么在作文件排序或者 UNION 操作，若后面还有 on disk 标记，则表示 MySQL 正在将一个内存临时表放在磁盘上；</li><li><code>Sorting result</code>：线程正在对结果集进行排序；</li><li><code>Sending data</code>：线程可能在多个状态之间传输数据、或者在征程结果集，或者向客户端返回数据；</li><li><code>Daemon</code>：守护线程，通常是事件调度器；</li></ul><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>&emsp;MySQL如果不能通过索引进行排序时，那它就需要自己排序，数据量小则在内存进行排序，数据量大就需要借助磁盘，这2种方式统称为文件排序(filesort)，核心在于<font color="red">不能使用索引进行排序</font>。若需要排序的数据量小于“排序缓冲区”，MySQL将会使用内存进行快排；若数据量大于内存，那它将会将数据分块，对每个块进行快排，然后将各个块的快排结果放置磁盘上，最后再合并结果集返回。</p><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>&emsp;分区表，示例为：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> partiation_test ( create_time datetime <span class="keyword">DEFAULT</span> <span class="keyword">now</span>() ) <span class="keyword">ENGINE</span> = <span class="keyword">INNODB</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> (</span><br><span class="line"><span class="keyword">MINUTE</span> ( create_time )) (</span><br><span class="line"><span class="keyword">PARTITION</span> p_1</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line"><span class="keyword">LESS</span> <span class="keyword">THAN</span> ( <span class="number">10</span> ),</span><br><span class="line"><span class="keyword">PARTITION</span> p_2</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line"><span class="keyword">LESS</span> <span class="keyword">THAN</span> ( <span class="number">30</span> ),</span><br><span class="line"><span class="keyword">PARTITION</span> p_other</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line"><span class="keyword">LESS</span> <span class="keyword">THAN</span> ( <span class="number">60</span> ) </span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>最终在对应schema目录下会生成3个物理子表 p_1、p_2、p_3 ，分别对应的 .idb 物理文件的表空间文件为 partiation_test#p#p_1.ibd、partiation_test#p#p_2.ibd 以及 partiation_test#p#p_other.ibd，同时不再生成 partiation_test.ibd 主表空间文件，注：分区字段不能为<code>timestamp</code>类型，故上述将 create_time 定义为<code>datetime</code>类型。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-MySQL-逻辑架构&quot;&gt;&lt;a href=&quot;#1-MySQL-逻辑架构&quot; class=&quot;headerlink&quot; title=&quot;1. MySQL 逻辑架构&quot;&gt;&lt;/a&gt;1. MySQL 逻辑架构&lt;/h2&gt;&lt;p&gt;&amp;emsp;整体的逻辑架构分为 Server 层和引擎层两部分。其中 Server 层又细分为连接器和核心层，其中连接器那一层并非MySQL独有，大部分的C/S工具都有类似的架构（比如连接处理、授权认证、安全等），Server 层的第二层是 MySQL 独有的，MySQL 很多核心功能都在这一层，包括查询解析、分析、优化、缓存以及内置函数，还有所有跨存储引擎的功能也在这一层实现（包含存储过程、视图等等）。
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="MySQL" scheme="https://jacksonary.github.io/tags/MySQL/"/>
    
      <category term="InnoDB" scheme="https://jacksonary.github.io/tags/InnoDB/"/>
    
  </entry>
  
  <entry>
    <title>主备延迟监控</title>
    <link href="https://jacksonary.github.io/posts/52a5a976.html"/>
    <id>https://jacksonary.github.io/posts/52a5a976.html</id>
    <published>2021-04-21T02:51:00.000Z</published>
    <updated>2022-11-08T09:07:57.376Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-基本工具的安装"><a href="#1-基本工具的安装" class="headerlink" title="1. 基本工具的安装"></a>1. 基本工具的安装</h2><h3 id="1-1-安装-percona-toolkit"><a href="#1-1-安装-percona-toolkit" class="headerlink" title="1.1 安装 percona-toolkit"></a>1.1 安装 percona-toolkit</h3><p>&emsp;这玩意儿工具挺全，有时间可以深入了解一下，我的系统是 debian，流程如下：<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载软件包</span></span><br><span class="line">wget https://downloads.percona.com/downloads/percona-toolkit/3.3.0/binary/debian/buster/x86_64/percona-toolkit_3.3.0-1.buster_amd64.deb</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装，注意路径</span></span><br><span class="line">apt install ./percona-toolkit_3.3.0-1.buster_amd64.deb</span><br><span class="line"><span class="meta">#</span><span class="bash"> 校验，随便一个模块 --version，这里选用 pt-find 模块</span></span><br><span class="line">pt-find --version</span><br></pre></td></tr></table></figure><p>如果你的系统不是，到<a href="https://www.percona.com/downloads/percona-toolkit/LATEST/" rel="external nofollow noopener noreferrer" target="_blank">官网</a>获取对应的资源包再安装。</p><h3 id="1-2-安装-sysbench"><a href="#1-2-安装-sysbench" class="headerlink" title="1.2 安装 sysbench"></a>1.2 安装 sysbench</h3><p>&emsp;这个也很方便就可以安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 关联仓库</span></span><br><span class="line">curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.deb.sh | bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装</span></span><br><span class="line">apt -y install sysbench</span><br></pre></td></tr></table></figure><p>一些基本参数（来源于网络）说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">--threads=4500  表示发起4500个并发连接</span><br><span class="line">--oltp-read-only=off 表示不要进行只读测试，也就是会采用读写混合模式测试</span><br><span class="line">--report-interval=10 表示每10秒输出一次测试进度报告</span><br><span class="line">--rand-type=uniform 表示随机类型为固定模式，其他几个可选随机模式：uniform,gaussian,special,pareto</span><br><span class="line">--time=120 表示最大执行时长为 120 秒</span><br><span class="line">--max-requests=0 表示总请求数为 0，因为上面已经定义了总执行时长，所以总请求数可以设定为 0；也可以只设定总请求数，不设定最大执行时长</span><br><span class="line">--tables=10  表示10个表</span><br><span class="line">--table-size=100000  单表100000条记录</span><br><span class="line">--percentile=99 表示设定采样比例，默认是 95%，即丢弃1%的长请求，在剩余的99%里取最大值</span><br><span class="line"></span><br><span class="line">SQL statistics:</span><br><span class="line">    queries performed:</span><br><span class="line">        read:                            0         读操作</span><br><span class="line">        write:                           233015     --写总数</span><br><span class="line">        other:                           197026  --其他操作总数(SELECT、INSERT、UPDATE、DELETE之外的操作，例如COMMIT等)</span><br><span class="line">        total:                           430041  --全部总数</span><br><span class="line">    transactions:                        62617  (486.84 per sec.)  --总事务数(每秒事务数)</span><br><span class="line">    queries:                             430041 (3343.55 per sec.) --查询数(每秒查询数)</span><br><span class="line">    ignored errors:                      27087  (210.60 per sec.)  --忽略错误数</span><br><span class="line">    reconnects:                          0      (0.00 per sec.)  --重新连接次数</span><br><span class="line"></span><br><span class="line">General statistics:</span><br><span class="line">    total time:                          128.6147s  --运行总时间</span><br><span class="line">    total number of events:              62617  --事件总数</span><br><span class="line"></span><br><span class="line">Latency (ms):</span><br><span class="line">         min:                                    2.09</span><br><span class="line">         avg:                                 8957.64</span><br><span class="line">         max:                                99069.80</span><br><span class="line">         95th percentile:                    27846.48</span><br><span class="line">         sum:                            560900840.54</span><br><span class="line"></span><br><span class="line">Threads fairness:    #线程平均数</span><br><span class="line">    events (avg/stddev):           13.9149/3.92</span><br><span class="line">    execution time (avg/stddev):   124.6446/2.39</span><br></pre></td></tr></table></figure><p>详细说明看<code>sysbench --help</code>输出即可。</p><p><strong>【注】</strong>sysbench 自带一些测试的 lua 脚本，脚本所在目录 <code>/usr/share/sysbench</code>（后面会用到）。sysbench对数据库进行压力测试的过程分为3个阶段：prepare 阶段，做准备的、比较说建立好测试用的表、并向表中填充数据；run 阶段，去跑压力测试的SQL；cleanup 阶段，清除数据的，即drop掉prepare阶段初始化好的表，下面是一个完整阶段的示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 建表，初始化数据</span></span><br><span class="line">sysbench --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=root --mysql-db=ms_rep oltp_insert prepare</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 跑SQL，输出报告</span></span><br><span class="line">sysbench --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=root --mysql-db=ms_rep oltp_read_write run</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 清除测试数据</span></span><br><span class="line">sysbench --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=root --mysql-db=ms_rep oltp_read_write cleanup</span><br></pre></td></tr></table></figure><p>上述过程如果执行报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</span><br><span class="line"></span><br><span class="line">FATAL: unable to connect to MySQL server on host &apos;127.0.0.1&apos;, port 3306, aborting...</span><br><span class="line">FATAL: error 1045: Plugin caching_sha2_password could not be loaded: /usr/lib/x86_64-linux-gnu/mariadb19/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory</span><br><span class="line">FATAL: `sysbench.cmdline.call_command&apos; function failed: ./oltp_common.lua:83: connection creation failed</span><br></pre></td></tr></table></figure><p>解决方式，更改加密方式：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新用户的密码</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">USER</span> <span class="string">'root'</span>@<span class="string">'localhost'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">WITH</span> mysql_native_password <span class="keyword">BY</span> <span class="string">'root'</span>; </span><br><span class="line"><span class="comment"># 更新用户的密码</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">USER</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">WITH</span> mysql_native_password <span class="keyword">BY</span> <span class="string">'root'</span>; </span><br><span class="line"><span class="comment"># 刷新权限</span></span><br><span class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</span><br></pre></td></tr></table></figure><p>上述已经打包好了镜像，可以直接使用<code>docker pull registry.cn-shanghai.aliyuncs.com/hhu/mysql:wgl_8.0.24</code>。</p><h2 id="2-搭建延迟监控"><a href="#2-搭建延迟监控" class="headerlink" title="2. 搭建延迟监控"></a>2. 搭建延迟监控</h2><p>&emsp;先创建好一个测试的数据库 ms_rep，然后</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 主库：创建后台不断更改心跳表的线程</span></span><br><span class="line">pt-heartbeat --user=root --ask-pass --host=127.0.0.1 --create-table -D ms_rep --interval=1 --update --replace --daemonize</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证后台线程正常在跑，必须验证</span></span><br><span class="line">pgrep -fla pt-heartbeat</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭后台线程（结束时执行）</span></span><br><span class="line">pt-heartbeat --stop</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 从库：监控延迟，-h 后指定的是从库的地址，建议在各个从库执行，这样观察更直观</span></span><br><span class="line">pt-heartbeat --user=root --ask-pass --host=127.0.0.1 --table=heartbeat --monitor -D ms_rep</span><br></pre></td></tr></table></figure><p>&emsp;通常刚建立的延迟监控输出都为<code>0.00s [  0.00s,  0.00s, 0.00s ]</code>，这时通过 sysbench 在 master 上生成不同的数据观察延迟即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在 master 上生成数据以便观察 binlog 重放的延迟</span></span><br><span class="line">sysbench --mysql-host=localhost --mysql-port=3306 --mysql-user=root --mysql-password=root --mysql-db=ms_rep --table-size=1000000 oltp_insert prepare</span><br></pre></td></tr></table></figure><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">插入的记录数     延迟时间</span><br><span class="line">   1000            0</span><br><span class="line">   2000            0</span><br><span class="line">   2W              0</span><br><span class="line">   3W              0</span><br><span class="line">   4W             0.99</span><br><span class="line">   5W             0.9,1.0</span><br><span class="line">   6W             1</span><br><span class="line">   7W             1, 0.99</span><br><span class="line">   8W             1,1</span><br><span class="line">   9W             0.99, 1, 1</span><br><span class="line">   10W            1,1</span><br><span class="line">   11W            1,1,1</span><br></pre></td></tr></table></figure><p><strong>【注】</strong>在执行完<code>pt-heartbeat --stop</code>后会提示创建文件<code>/tmp/pt-heartbeat-sentinel</code>，下次再建立监控时必须删除此文件，否则会跑一下就挂了。在从节点建立监控后会出现类似于 <code>5s [  0.25s,  0.05s,  0.02s ]</code> 标识延迟时间，默认是1m内、5m内、15m内的时间段，通过参数<code>--frames</code>指定。</p><p>心跳表无须手动创建，指定参数<code>--create-table</code>即可，心跳表的定义如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> heartbeat (</span><br><span class="line">  ts                    <span class="built_in">varchar</span>(<span class="number">26</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  server_id             <span class="built_in">int</span> <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">  <span class="keyword">file</span>                  <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,    <span class="comment">-- SHOW MASTER STATUS</span></span><br><span class="line">  <span class="keyword">position</span>              <span class="built_in">bigint</span> <span class="keyword">unsigned</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>, <span class="comment">-- SHOW MASTER STATUS</span></span><br><span class="line">  relay_master_log_file <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,    <span class="comment">-- SHOW SLAVE STATUS</span></span><br><span class="line">  exec_master_log_pos   <span class="built_in">bigint</span> <span class="keyword">unsigned</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>  <span class="comment">-- SHOW SLAVE STATUS</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-基本工具的安装&quot;&gt;&lt;a href=&quot;#1-基本工具的安装&quot; class=&quot;headerlink&quot; title=&quot;1. 基本工具的安装&quot;&gt;&lt;/a&gt;1. 基本工具的安装&lt;/h2&gt;&lt;h3 id=&quot;1-1-安装-percona-toolkit&quot;&gt;&lt;a href=&quot;#1-1-安装-percona-toolkit&quot; class=&quot;headerlink&quot; title=&quot;1.1 安装 percona-toolkit&quot;&gt;&lt;/a&gt;1.1 安装 percona-toolkit&lt;/h3&gt;&lt;p&gt;&amp;emsp;这玩意儿工具挺全，有时间可以深入了解一下，我的系统是 debian，流程如下：&lt;br&gt;
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="docker" scheme="https://jacksonary.github.io/tags/docker/"/>
    
      <category term="mysql" scheme="https://jacksonary.github.io/tags/mysql/"/>
    
      <category term="主备" scheme="https://jacksonary.github.io/tags/%E4%B8%BB%E5%A4%87/"/>
    
  </entry>
  
  <entry>
    <title>docker 部署 MySQL 主备架构</title>
    <link href="https://jacksonary.github.io/posts/ffbed5ba.html"/>
    <id>https://jacksonary.github.io/posts/ffbed5ba.html</id>
    <published>2021-04-20T11:27:00.000Z</published>
    <updated>2022-11-08T09:07:57.374Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>docker 镜像为 <code>8.0.24</code>，MySQL 版本为 8.0.24，若无法拉取可以用我这个 <code>docker pull registry.cn-shanghai.aliyuncs.com/hhu/mysql:wgl_8.0.24</code></p></blockquote><p>&emsp;部署 master 和 slave，可以顺次扩展 slave，流程如下：<a id="more"></a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 部署 master</span></span><br><span class="line">docker run --name mysql-master --privileged=<span class="literal">true</span> -v D:\tmp\docker\mysql\master\data:/var/lib/mysql -v D:\tmp\docker\mysql\master\conf\my.cnf:/etc/mysql/my.cnf -v D:\tmp\docker\mysql\master\mysql-files:/var/lib/mysql-files -p 3307:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署 slave</span></span><br><span class="line">docker run --name mysql-slave1 --privileged=<span class="literal">true</span> -v D:\tmp\docker\mysql\slave1\data:/var/lib/mysql -v D:\tmp\docker\mysql\slave1\conf\my.cnf:/etc/mysql/my.cnf -v D:\tmp\docker\mysql\master\mysql-files:/var/lib/mysql-files -p 3308:3306 --link mysql-master:master -e MYSQL_ROOT_PASSWORD=root -d mysql</span><br></pre></td></tr></table></figure><p>上述参数做如下说明：</p><ul><li><code>--name</code>：指定运行之后的容器的名称为mysql-master；</li><li><code>--privileged</code>：指定了当前容器是否真正的具有root权限，所谓的root权限是指具有宿主机的root权限，而不仅仅只是在容器内部有root权限；</li><li><code>-v</code>：指定了容器中指定目录挂载到宿主机上的某个目录，这样做的目的在于防止容器中配置的数据丢失，因为docker容器在重启之后是不会保留前一次在其内部运行的相关数据的；<ul><li><code>-v D:\tmp\docker\mysql\master\data:/var/lib/mysql</code>：挂载mysql的data目录，作外部持久化；</li><li><code>-v D:\tmp\docker\mysql\master\conf\my.cnf:/etc/mysql/my.cnf</code>：挂载mysql的配置文件，当然如果是我们自己打的包就不用了，因为像这种配置文件完全调好后直接打包到镜像中；</li><li><code>-v D:\tmp\docker\mysql\master\mysql-files:/var/lib/mysql-files</code>：正常不需要挂载，在启动出现异常<code>Failed to access directory for --secure-file-priv. Please make sure that directory exists and is accessible by MySQL Server. Supplied value : /var/lib/mysql-files</code>，此时需要额外挂载<code>mysql-files</code>目录；</li></ul></li><li><code>-p</code>：表示宿主机上的某个端口映射到docker容器内的某个端口，这里也就是将宿主机的3307、3308端口映射到容器内部的3306端口；</li><li><code>-e</code>：表示指定当前容器运行的环境变量，该变量一般在容器内部程序的配置文件中使用，而在外部运行容器指定该参数。这里的MYSQL_ROOT_PASSWORD表示容器内部的MySQL的启动密码；</li><li><code>-d</code>：参数指定了当前容器是在后台运行；</li><li><code>--link</code>：用来链接2个容器，使得源容器（被链接的容器）和接收容器（主动去链接的容器）之间可以互相通信，并且接收容器可以获取源容器的一些数据，如源容器的环境变量；</li></ul><p>&emsp;正常启动后，进入 master 和 slave 各个容器，登录 MySQL，发现提示异常：<code>[Warning] World-writable config file &#39;/etc/mysql/my.cnf&#39; is ignored</code>，这是因为我们挂载的配置文件是全局可写的，MySQL Server 不认可，此时我们改一下挂载的配置文件读写权限即可，我这里是win10，直接右击文件<code>D:\tmp\docker\mysql\master\conf\my.cnf</code>修改 属性 -&gt; 属性 -&gt; 只读 即可，重启上述容器<code>docker restart mysql-master</code>、<code>docker restart mysql-slave</code>即可。</p><p>&emsp;配置主备同步：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录 mysql</span></span><br><span class="line">mysql -uroot -p</span><br><span class="line"><span class="comment"># 查询master的binlog日志信息</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">master</span> <span class="keyword">status</span>;</span><br><span class="line"><span class="comment"># 在各个slave上配置master的连接信息，master_file和master_Position就是上面插叙的结果</span></span><br><span class="line"><span class="keyword">change</span> <span class="keyword">master</span> <span class="keyword">to</span> master_host=<span class="string">'master'</span>, master_user=<span class="string">'root'</span>, master_password=<span class="string">'root'</span>, master_port=<span class="number">3306</span>, master_log_file=<span class="string">'[master_file]'</span>, master_log_pos=[master_Position], master_connect_retry=<span class="number">30</span>;</span><br><span class="line"><span class="comment"># 在各个备库上开启主备复制</span></span><br><span class="line"><span class="keyword">start</span> <span class="keyword">slave</span>;</span><br><span class="line"><span class="comment"># 查看开启状态，只要看到两个参数Slave_IO_Running和Slave_SQL_Running都为YES，则表示复制是正常进行的</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">slave</span> <span class="keyword">status</span>;</span><br></pre></td></tr></table></figure><p>若<code>start slave</code>执行失败出现<code>ERROR 1872 (HY000): Slave failed to initialize relay log info structure from the repository</code>，重置一下该slave即可<code>reset slave</code>，然后再执行<code>start slave</code>。</p><p><strong>附</strong>：</p><p>主备的配置文件如下（备库自己修改server-id）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">#设置3306端口</span><br><span class="line">port = 3306</span><br><span class="line"># 设置mysql的安装目录</span><br><span class="line">#basedir=D:\Program Files\MySQL\mysql-8.0.20</span><br><span class="line"># 设置mysql数据库的数据的存放目录</span><br><span class="line">#datadir=D:\Program Files\MySQL\mysql-8.0.20\data</span><br><span class="line"># 允许最大连接数</span><br><span class="line">max_connections=200</span><br><span class="line"># 服务端使用的字符集默认为8比特编码的latin1字符集</span><br><span class="line">character-set-server=utf8</span><br><span class="line"># 创建新表时将使用的默认存储引擎</span><br><span class="line">default-storage-engine=INNODB</span><br><span class="line"># binlog配置</span><br><span class="line"># 开启binlog，指定basefileName</span><br><span class="line"># mysql会在baseName后面追加数值来生成新的binlog日志，在服务启动或重启、flush日志、当前日志文件达到max_binlog_size的值都会生成新的日志文件</span><br><span class="line">log-bin=mysql-binlog</span><br><span class="line"># 和log-bin类似，但可以指定路径，实测未生效</span><br><span class="line">#log_bin_basename=D:\Program Files\MySQL\mysql-8.0.20\data\logs\binlog\</span><br><span class="line"># 默认为 log-bin 后面追加 .index，可以不设</span><br><span class="line">log-bin-index=mysql-binlog.index</span><br><span class="line"># binlog模式设置为row</span><br><span class="line">binlog-format=ROW</span><br><span class="line"># 单个binlog文件的大小，单位字节，默认1073741824（即1G），但不是绝对的，binlog在记录事务时，是不会将一个事务进行分割的，总是以一个整体的形式来记录</span><br><span class="line">max_binlog_size=1073741824</span><br><span class="line"># 8.0以下版本必须在开启binlog时必设，8.0及以上默认为1，但不显式设置，虽可以启动但会出现提示信息</span><br><span class="line">server_id=1</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;docker 镜像为 &lt;code&gt;8.0.24&lt;/code&gt;，MySQL 版本为 8.0.24，若无法拉取可以用我这个 &lt;code&gt;docker pull registry.cn-shanghai.aliyuncs.com/hhu/mysql:wgl_8.0.24&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;emsp;部署 master 和 slave，可以顺次扩展 slave，流程如下：
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="docker" scheme="https://jacksonary.github.io/tags/docker/"/>
    
      <category term="mysql" scheme="https://jacksonary.github.io/tags/mysql/"/>
    
      <category term="主备" scheme="https://jacksonary.github.io/tags/%E4%B8%BB%E5%A4%87/"/>
    
  </entry>
  
  <entry>
    <title>主备复制</title>
    <link href="https://jacksonary.github.io/posts/47049.html"/>
    <id>https://jacksonary.github.io/posts/47049.html</id>
    <published>2021-04-19T07:07:00.000Z</published>
    <updated>2022-11-08T09:07:57.376Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-主备复制的基础-二进制日志"><a href="#1-主备复制的基础-二进制日志" class="headerlink" title="1. 主备复制的基础-二进制日志"></a>1. 主备复制的基础-二进制日志</h2><p>&emsp;用于就描述 MySQL 事件，包含表创建、数据修改以及可能修改数据的语句（比如没有匹配到记录的<code>DELETE</code>操作），除非是使用 row-based 日志形式，二进制日志包含了每条语句更新数据时所花费的时间信息，在 mysql 中，二进制日志存在的主要目的有2个：<a id="more"></a></p><ol><li>主从同步。在master上产生的二进制日志副本，记录着数据的变化，这个二进制日志副本将被读取到各个 slave 上，slave 可以通过这个二进制日志副本来重放在 master 上操作，将自己的数据进行同样的修改；</li><li>数据恢复。某些数据恢复的场景需要使用二进制日志。在备份还原后，将重新执行备份后在二进制日志中记录的事件，这些事件会使数据库从备份时起是最新的。</li></ol><p>&emsp;二进制日志只用于修改行为，不会记录<code>SELECT</code>或<code>SHOW</code>语句。如果要记录所有语句（例如，标识问题查询），直接使用常规查询日志即可。开启二进制日志会使性能稍微变慢，但用较小的性能下降换取主备复制和数据还原的能力还是可以接受的。二进制日志的存在可以很好的弹性处理一些意外情况，它仅记录或读取完整的事件或事务，主要有3种模式。</p><h3 id="1-1-row-based-日志（基于行的日志）"><a href="#1-1-row-based-日志（基于行的日志）" class="headerlink" title="1.1 row-based 日志（基于行的日志）"></a>1.1 row-based 日志（基于行的日志）</h3><p>&emsp;row-based 日志是仅限于某个具体的数据库（物理层面），但对于初始化生成的 default 数据库没有此限制，若在启动时指定 <code>--binlog-do-db=sales</code>，那此时不论在sales库中的哪个表中进行写行为都将会记录到 binlog 中，即使在写行为中之前显式的去指定数据库名<code>use db_a</code>，但只要在写行为语句的表声明时加上了指定记录日志的db名即可<code>sales.table_a</code>。</p><p>&emsp;master 将一些改变各个表中的各行记录（具体到 row 级别）的事件记录到二进制日志种，可以通过 <code>binlog-format=ROW</code> 参数指定， row-based 日志是默认日志形式。当使用 ROW 格式的日志时，<code>binlog-row-event-max-size</code>系统参数（默认8192字节）将会生效（限制 row event 的最大值，如果某个事件不可分割，也有可能超出此限制，和 binlog 文件大小<code>max_binlog_size</code>的限制一样都是软限制），这个系统参数只在服务启动时设置生效，它表明的是 Row 将会以块的形式存储在二进制文件中，这个块的大小不会超过<code>binlog-row-event-max-size</code>参数，该参数必须是256的倍数。</p><p>【<strong>注</strong>】在使用 ROW 格式时，很多写行为的操作都会以 ROW 格式记录到二进制日志中，但有一些行为仍然会以 statement 的格式记录（比如所有的 <code>CREATE TABLE</code>、<code>ALTER TABLE</code>、<code>DROP TABLE</code>）。</p><h3 id="1-2-statement-based-日志（基于语句的日志）"><a href="#1-2-statement-based-日志（基于语句的日志）" class="headerlink" title="1.2 statement-based 日志（基于语句的日志）"></a>1.2 statement-based 日志（基于语句的日志）</h3><p>&emsp;mysql 最初的复制功能是基于 master 上面的 SQL 语句传播到 slave 上实现的，这种方式就是 statement-based log，可以通过 <code>binlog-format=STATEMENT</code> 参数指定。但使用 statement-based 格式日志复制非确定性语句可能存在问题，对于 statement-based 副本使用所给的 statement 是否安全时，mysql 通过是否可以保证可以使用基于语句的日志记录来复制该语句来决定，如果 mysql 不能保证，那就会提示不可靠的提示“statement may not be safe to log in statement format”。对于有临时表的场景，只有 statement 日志才会记录，row 和 mixed 并不会记录。</p><h3 id="1-3-mixed-日志"><a href="#1-3-mixed-日志" class="headerlink" title="1.3 mixed 日志"></a>1.3 mixed 日志</h3><p>&emsp;将 row-based 和 statement-based 2种形式的日志混合使用，可以通过 <code>binlog-format=MIXED</code> 参数指定。混合格式的日志默认使用 statement-based 日志，但在下面的特定场景下会自动切换到 row-based 形式日志（重要）：</p><ol><li>包含了<code>UUID()</code>、<code>FOUND_ROWS()</code>、<code>ROW_COUNT()</code>、<code>USER()</code>、 <code>CURRENT_USER()</code>、 <code>CURRENT_USER</code>、<code>LOAD FILE()</code>；</li><li>当表中包含了<code>AUTO_INCREMENT</code>列被更新，或者包含类似形式的比如触发器；</li><li>当涉及的表中有 mysql 的日志表时；</li><li>当语句中引用了系统参数（当然也有一些特殊的系统参数不会引起切换到 row）；</li></ol><p>日志记录格式还可以通过所使用的存储引擎来设置或限制，这有助于消除在源和副本之间使用不同存储引擎复制某些语句时的问题。</p><p><strong>注：</strong></p><p>&emsp;每个独立的客户端可以控制自己语句的 binlog 格式，可以运行时改变，通过设置 session 级别的参数，如：<code>SET SESSION binlog_format = &#39;STATEMENT&#39;</code>，前后对照一下<code>SHOW VARIABLES LIKE &#39;%binlog%&#39;</code>即可发现格式变了，原先在配置文件 my.ini 中关于 binlog 配置都被改变了。但不是每个 session 都推荐自己去更改 binlog 的格式，只是在某些特殊的场景下，客户端可能去做更改，比如：</p><ul><li>某个 session 中对数据库做了很多细微的写操作，那客户端可能想将日志格式改为 ROW 格式；</li><li>某个 session 中使用 <code>update ... where ...</code>对好多匹配命中的记录做了更改，那这时候可能他会将格式调整为 STATEMENT，因为这样比记录很多行的变化更高效；</li><li>有一些语句执行执行很耗时，但实际结果影响的行记录很少，那这时使用 ROW 格式会更高效；</li></ul><p>此外，有临时表存在时，不要随便更改日志的格式，而且对于有临时表的场景，只有 statement 日志才会记录，row 和 mixed 并不会记录。各种存储引擎对 ROW 和 STATEMENT 日志的支持情况，对于 INNODB 引擎，支持 ROW 格式日志，STATEMENT 格式仅事务隔离级别设置为可重复读或者序列化才支持，其他事务级别不支持 STATEMENT 格式。</p><p><strong>附</strong><br></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查看 binlog 文件的内容，若不加 in 'xx' 指定 binlog 文件，默认查看第一个 binlog 文件</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">binlog</span> <span class="keyword">events</span> <span class="keyword">in</span> <span class="string">'mysql-binlog.0000xx'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看当前正在写入 binlog 文件</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">MASTER</span> <span class="keyword">STATUS</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看 binlog 列表</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">MASTER</span> <span class="keyword">LOGS</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 将 binlog 刷入磁盘重新生成一个 binlog 编号开始写入</span></span><br><span class="line"><span class="keyword">FLUSH</span> <span class="keyword">LOGS</span>;</span><br></pre></td></tr></table></figure><h2 id="2-主备同步"><a href="#2-主备同步" class="headerlink" title="2. 主备同步"></a>2. 主备同步</h2><h3 id="2-1-同步过程"><a href="#2-1-同步过程" class="headerlink" title="2.1 同步过程"></a>2.1 同步过程</h3><p>&emsp;MySQL的主从同步主要是通过将 binlog 在备库（从库）重放实现数据异步同步，一般是主库负责写，从库负责读（读写分离），主要架构和过程如下：</p><p><img src="https://img-blog.csdnimg.cn/20210420091614801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70#pic_center" alt="主从同步"></p><ol><li>主库将数据的更改写入 binlog 中：在每次提交事务完成数据更新前，二进制日志的记录行为会按事务的提交顺序而不是每条SQL语句的执行顺序，在记录日志后，主库会通知存储引擎进行事务的提交；</li><li>备库将将主库上的 binlog 复制到自己的中继日志（relay log）上：从库启动一个工作线程（I/O线程），这个线程和主库建立一个客户端连接，然后在主库上启动一个二进制转储线程（即binlog dump thread），这个转储线程会读取主库的 binlog 日志，注意这个线程不会轮询主库的 binlog，如果转储线程读取二进制日志中的行为追上了主库，那转储线程进入睡眠，直到主库通知它有新的事件行为发生才会重新唤醒转储线程，将日志转储（flush）到中继日志中；</li><li>备库读取中继日志中的事件进行重放：从库的SQL线程从中继日志中读取二进制日志在自己上执行。</li></ol><p>这个过程可能出现在某一时刻主从不一致的情况，尤其是一些大语句可能导致几秒甚至几分钟的延迟。从上面的流程不难看出主库的主要开销主要集中在binlog的写和传播，写binlog是写一份，但传播随着从库的增加而增加（即 binlog dump thread 会随着从库的增加而增加），从库的主要创建2个线程：读取主库 binlog 到中继日志的 I/O 线程，从中继日志读取行为事件执行SQL重放的 SQL 线程。在主从同步时，如果主、备的延迟很大，备库的I/O线程可能会写很多relay log，这个过程中如果延迟很高，I/O线程可能会把磁盘撑爆，所以尽量配置合适的relay_log_space_limit，若中继日志大小超过这个值，那I/O线程就会停止等待SQL线程执行完来释放空间。SQL线程在重放完中继日志中的事件后会尽快将其删除（relay_log_purge）。</p><p>&emsp;MySQL的主从同步主要是依托binlog，binlog的格式也会影响同步行为，主要分为基于语句和基于行的复制：</p><ul><li>statement-based：基于语句的复制（即逻辑复制）。主库会记录那些造成数据更新的语句，当备库读取这些事件之后就是简单的将这些SQL再执行一遍。这种方式相对白痴，理论上可以实现主从数据一致。但在某些场景下也会存在问题，比如当语句中存在诸如<code>CURRENT_USER()</code>、<code>NOW()</code>等函数时，另外基于语句的复制必须是串行，这个要求占用更多锁资源；</li><li>row-based：基于行的复制。这种复制方式最大的好处就是可以正确复制每一行数据，但在一些场景下又是非常低效的，比如将一些聚合数据插入另一张表中，通常这里面的聚合行为是很慢的，但产生的数据相对比较有限，这种情况使用基于行的复制方式开销就会很小，因为日志中描述的只是进行行数据的插入，而不会去重放SQL再做一下聚合操作。再如<code>update [table_name] set [column]=x</code>基于语句的复制代价就更小，因为这种SQL是几乎就是批量更改数据，若基于行复制的话，批量更新就会被分解为一个个零散的更新，一方面会使二进制日志变得巨大，也会给日志所在机器增加负载。</li></ul><h3 id="2-2-主备拓扑结构"><a href="#2-2-主备拓扑结构" class="headerlink" title="2.2 主备拓扑结构"></a>2.2 主备拓扑结构</h3><p>&emsp;主、备的拓扑结构（即主、备的组合方式）可能会很多，只要遵守下面的4个基本原则即可：</p><ul><li>主备的对应关系是1:N；</li><li>每个备库必须有一个唯一的服务器ID；</li><li>若开启<code>log_slave_update</code>相关，备库可以将主库的变化传播到其他备库上；</li></ul><p>&emsp;可拓展的拓扑结构有多种方式：</p><h4 id="2-2-1-一主多备"><a href="#2-2-1-一主多备" class="headerlink" title="2.2.1 一主多备"></a>2.2.1 一主多备</h4><p>&emsp;这是最简单的结构，应对写少读多的场景尤为管用。它可以将读分散到多个备库上，可以加到直至备库多到给主库造成压力。结构如下：<br><img src="https://img-blog.csdnimg.cn/20210420092215479.png#pic_center" alt="主从同步-一主多备"></p><p>&emsp;这种拓扑结构有一些常用的场景：</p><ul><li>为不同的角色使用不同的备库（如添加不同的索引和存储引擎）；</li><li>直接将备库作为待用主库，只做复制；</li><li>远程备库，容灾恢复；</li></ul><h4 id="2-2-2-主主复制（双主-双向复制）"><a href="#2-2-2-主主复制（双主-双向复制）" class="headerlink" title="2.2.2 主主复制（双主/双向复制）"></a>2.2.2 主主复制（双主/双向复制）</h4><h3 id="主动双主"><a href="#主动双主" class="headerlink" title="主动双主"></a>主动双主</h3><p>&emsp;2台服务互为对方的主库和备库，任何一方的改动都会复制到另一方中，拓扑结构主要如下：<br><img src="https://img-blog.csdnimg.cn/2021042009180082.png#pic_center" alt="主从同步-双主复制"></p><p>&emsp;双主复制通常用于一些特殊目的，如2个不同地理位置但都需要一份可写的数据拷贝。但这种拓扑结构存在一个很难解决的问题：当同时修改同一条数据时，或同时向表中插入一个包含<code>AUTO_INCREMENT</code>列的记录。在5.0可以设置系统变量<code>auto_increment_increment</code>和<code>auto_increment_offset</code>来改变自增行为中的步长和初始值，这种支持使得双主稍微变得安全一些（因为2个主库之间的冲突减少了），但允许同时对2个主库进行写行为还是很不安全，如 col = 1，SQL <code>update table set col=col+1</code> 和 <code>update table set col=col*2</code> 同时在2个主库上执行，那2台主库上可能出现一个为4、一个为3的情况，并不会出现复制错误，但此时主备数据已经不一致了。</p><h3 id="被动双主"><a href="#被动双主" class="headerlink" title="被动双主"></a>被动双主</h3><p>&emsp;这种拓扑结构主要和主动双主的区别是其中一台服务器只是被动的读取，这样的方式使得反复切换主动和被动服务器非常方便，因为服务器的配置是对称的。当我们执行 <code>ALTER TABLE</code> 时会锁表，阻塞表的读写。这种场景下可以切断主库中 binlog dump 线程，然后在从库中执行 <code>ALTER TABLE</code> 操作，执行完后交换角色，让执行完修改操作的只读主库变成主库，并开启 binlog dump 线程，最后将原先的主库将会读取现在主库的 binlog 执行修改操作，这样就可以在不影响服务的同时去作阻塞式操作。</p><h3 id="带备双主"><a href="#带备双主" class="headerlink" title="带备双主"></a>带备双主</h3><p>&emsp;即在双主的基础上给他们各自加上一个备库，形式如下：<br><img src="https://img-blog.csdnimg.cn/20210420091840496.png#pic_center" alt="主从同步-带备双主"></p><p>这种形式增加了冗余，对于不同地理位置的复制，可以消除单点失效的问题。双主可以一定程度解决单点故障，但也要考虑其复杂性。</p><h4 id="2-2-3-环形复制"><a href="#2-2-3-环形复制" class="headerlink" title="2.2.3 环形复制"></a>2.2.3 环形复制</h4><p>&emsp;环形复制的拓扑结构中，可以有3个及3个已上的主库，结构如下：<br><img src="https://img-blog.csdnimg.cn/20210420091913185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70#pic_center" alt="主从同步-环形复制"></p><p>环形复制没有双主的对称配置和故障转移的有点，它完全依赖于环形上没有可用节点，总的来说环形结构非常脆弱（尽量避免）。虽然在后续衍生出带备环形，可以一定程度上减少环形复制的风险，但仍不能解决在断电或者断网情况下对与各个主节点的强依赖。拓扑结构如下：<br><img src="https://img-blog.csdnimg.cn/20210420091947645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70#pic_center" alt="主从同步-带备环形"></p><h4 id="2-2-4-多主一备"><a href="#2-2-4-多主一备" class="headerlink" title="2.2.4 多主一备"></a>2.2.4 多主一备</h4><p>&emsp;多主复制在 MySQL 5.7 版本中开始支持多主复制，如下：<br><img src="https://img-blog.csdnimg.cn/20210420092017367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70#pic_center" alt="主从同步-多主一备"></p><p>多主一备主要是将用于将数据存储到另一台性能较高的服务器上。</p><h4 id="2-2-5-树形（金字塔型）"><a href="#2-2-5-树形（金字塔型）" class="headerlink" title="2.2.5 树形（金字塔型）"></a>2.2.5 树形（金字塔型）</h4><p>&emsp;这种拓扑结构可以大大减轻主库在传播 binlog 时的负载，但因为不是每个备库都从主库中拉取原始内容，所以一旦中间某些节点出现问题都会影响它的子孙节点，层次越多越容易出现问题：<br><img src="https://img-blog.csdnimg.cn/20210420092045202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70#pic_center" alt="主从同步-树形"></p><h3 id="2-3-主备复制方式"><a href="#2-3-主备复制方式" class="headerlink" title="2.3 主备复制方式"></a>2.3 主备复制方式</h3><p>&emsp;MySQL 传播 binlog 的方式分为异步复制（默认方式）、半同步复制和全同步复制三种方式。详细如下：</p><h4 id="2-3-1-异步复制"><a href="#2-3-1-异步复制" class="headerlink" title="2.3.1 异步复制"></a>2.3.1 异步复制</h4><p>&emsp;异步复制是 MySQL 默认的复制方式，master 自己执行完对应操作并记录 binlog，这个操作就成功了，它不关心 slave 的复制结果（是否转存 relay log 成功，有几个 slave 成功等）；</p><h4 id="2-3-2-半同步复制"><a href="#2-3-2-半同步复制" class="headerlink" title="2.3.2 半同步复制"></a>2.3.2 半同步复制</h4><p>&emsp;异步复制中由于 master 并不关心备库读取 binlog 或重放的情况，所以存在主库执行成功但备库执行失败的情况（如 master 执行成功后，在 slave 读取 binlog 到 relay log 完成之前 master 挂了）。为了解决这个问题，半同步复制可以保证 master 自己执行成功，且至少1个 slave 已经读取 binlog 并 flush 到 relay log 文件中（无需等 SQL 线程重放），这样才算成功。半同步复制需要开启 <code>semisync</code>；</p><h4 id="2-3-3-全同步复制"><a href="#2-3-3-全同步复制" class="headerlink" title="2.3.3 全同步复制"></a>2.3.3 全同步复制</h4><p>&emsp;全同步复制是效率最低的复制方式，因为 master 正常执行成功后，还需要等待所有备库执行成功后才算成功，这么干会严重拖慢并发写。</p><h3 id="2-4-主备架构中存在的问题"><a href="#2-4-主备架构中存在的问题" class="headerlink" title="2.4 主备架构中存在的问题"></a>2.4 主备架构中存在的问题</h3><p>&emsp;主备的场景有很多，诸如容灾备份、读写分离，当然也会存在如复制延迟、过多 slave 在master创建的 binlog 读取线程拖垮 master 等问题。</p><p>若master写并发较高，此时 slave 的数据可能存在几毫秒到几秒的延迟（并发很小，几百并发写，延迟可能就几毫秒；中等并发写，1k~2K可能会出现几十毫秒的延迟；&gt;2K并发可能会出现几秒甚至几十秒的延迟）。</p><h4 id="2-4-1-不能确保-slave-成功复制"><a href="#2-4-1-不能确保-slave-成功复制" class="headerlink" title="2.4.1 不能确保 slave 成功复制"></a>2.4.1 不能确保 slave 成功复制</h4><p>&emsp;开启半同步复制（即 smisync），解决 I/O 线程还未读取 master 到 relay log ，master 就挂数据丢失的问题，半同步机制可以作如下保证：master 操作成功并且至少1个 slave 执行半成功，这里“半成功”的概念是至少1个 slave 的 I/O 线程读取 master binlog 到 relay log 中给 master 反馈，master 才会认为当前操作成功；</p><h4 id="2-4-2-主备延迟"><a href="#2-4-2-主备延迟" class="headerlink" title="2.4.2 主备延迟"></a>2.4.2 主备延迟</h4><p>&emsp;这个问题会在并发写时遇见，主要有下面2种方式来缓解：</p><ol><li>开启并行复制，让 slave 中读取 relay log 执行 SQL 的线程可以并行执行不同库的 SQL，但这种方式解决问题很有限，因为大部分延迟是聚集在某个或某几个热点表，并行复制解决的是异库并行重放 binlog 缓慢的问题；</li><li>主库拆分，对于并发写导致的延迟可以拆分主库的方式来分摊负载，将原来对一个库的并发写分摊为对多个库的并发写，然后再挂几个 slave，可以大大提高并发能力；<br><img src="https://img-blog.csdnimg.cn/20210420092108931.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70#pic_center" alt="主从同步-主备延迟_拆库"></li></ol><h4 id="2-4-3-主备延迟导致更细数据失败"><a href="#2-4-3-主备延迟导致更细数据失败" class="headerlink" title="2.4.3 主备延迟导致更细数据失败"></a>2.4.3 主备延迟导致更细数据失败</h4><p>&emsp;读写分离的场景下，延迟可能导致服务异步逻辑异常，大致的场景如下：服务对主库 insert，然后在备库进行 select，若巨记录存在则进行 update，但因为主备延迟，第二步的 select 没有查到数据，导致流程中断。这个问题知道读写分离架构的前提下，可以在代码处理的逻辑层面来规避问题，即略过对备库进行 select 操作，直接进行 update 操作，此时操作的便是主库，不会出现记录不存在的情况。</p><h2 id="附：主备架构中一些概念"><a href="#附：主备架构中一些概念" class="headerlink" title="附：主备架构中一些概念"></a>附：主备架构中一些概念</h2><p>&emsp;主备架构在进行binlog传播时，是由各个备库在主库上创建一个线程执行 binlog dump 指令读取主库的 binlog 发送到备库的 relay log，各个备库在主库进行这个工作时不会共享 binlog dump 资源，随着备库的增加主库的负载也会不断增大，如果数据不在内存还会导致大量的磁盘检索，这种行为会影响主库的性能。在多备场景下主库有明显负载压力时，就需要使用分发主库了，分发主库实际是一个备库，但分发主库唯一的目的为了提取主库的binlog并对其他备库提供，这样就让主库摆脱了负载，分发主库几乎都是使用 blackhole 引擎（黑洞引擎，用于验证 dump file 语法的正确性、检测 binlog 功能所需的负载，经常用作日志服务器、dummy master、增量备份服务器，没有高级的功能：no transaction,no XA,no save point），使用blackhole引擎可以避免在分发主库上的查询行为（应为这回使得它对binlog的分发性能有所损耗），对于blackhole的使用场景网上有段较为详细的说明：</p><ol><li>充当dummy master。当master后面挂载过多的slave，利用 blackhole 来充当一个 “dummy master” 来减轻master的负载（延迟是需要考虑的）；这里需要提一下的是: 对于 master来说“dummy master” 还是一个slave的角色， 由于binlog 设计中是不记录 <code>engine=xxxx</code> 关键字的，采用默认的存储引擎（除非在 <code>create</code> 语句中 显式声明 <code>engine=innodb</code>）,所以对于dummy master 来说 只要设置 default_storage_engine=blackhole 就能实现主从 使用不一致的存储引擎；</li><li>充当日志服务器。对于blackhole的slave启用 <code>log_slave_updates</code> 这个参数，通过解析相关语句来做审计或者观测服务器负载的情况；需要考虑的问题，如果binlog format 为 row 模式，解析 binlog 查看SQL语句将是一个小问题，<code>mysqlbinlog -vv</code>这个不单纯显示的SQL，还有部分“前后镜像”；</li><li>充当增量备份服务器。免去拷贝binlog的问题，如果机器数据量多，也需要多个 blackhole 的slave实例，这是一个成本问题；其次是 master  binlog，pos 位置和 blackhole 重新产生的pos 是不一致的，在恢复数据的时候需要手动来恢复，不知道有没有工具之类的来做对比；如果 MySQL 版本达到 5.6+ 那启用 GTID 这个选项可以很容易的实现 增量的恢复；</li></ol><p>最终的拓扑结构应该如下：<br><img src="https://img-blog.csdnimg.cn/2021042009213319.png#pic_center" alt="主从同步-分发主库"></p><p>&emsp;主备架构上，若主库接近满负载，根据经验来说，那它的备库应该在10个以内，当然如果引入了分发主库可以适当增加备库来提高读操作的并发性能。</p><p><strong>注</strong>：</p><p>&emsp;master千万不要有blackhole的存储引擎来复制到其他slave，会造成的影响如下：</p><ol><li>如果binlog format 格式为 row或者 mixed 模式，那 delete 和update 是不会记录在binlog里面，并产生warning；</li><li>对于具有<code>auto_incrment</code>属性的column，由于blackhole 是 no op模式，没有任何记录，所以每次插入的记录，主键ID列都是相同的，造成复制失败；</li><li>对于 trigger 由于 for each row关键字，trigger不会被执行，因为没有一条row；</li></ol><p>又翻了下官网，解释到位：blackhole 引擎和名字一样，如同黑洞，吸收数据，但输出的结果集为空。可以如下测试：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 确保支持 blackhole 引擎</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">ENGINES</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建 blackhole 引擎的测试表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> blackhole_test (</span><br><span class="line">    <span class="string">`id`</span> <span class="built_in">INT</span> ( <span class="number">11</span> ) <span class="keyword">NOT</span> <span class="literal">NULL</span> auto_increment <span class="keyword">COMMENT</span> <span class="string">'primary key'</span>,</span><br><span class="line">    <span class="string">`prop`</span> <span class="built_in">VARCHAR</span> ( <span class="number">32</span> ) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">'default prop'</span> <span class="keyword">COMMENT</span> <span class="string">'blackholes pop'</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> ( <span class="string">`id`</span> ) </span><br><span class="line">) <span class="keyword">ENGINE</span> = blackhole <span class="keyword">charset</span> = utf8 <span class="keyword">COMMENT</span> <span class="string">'黑洞引擎测试'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 插入测试数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> blackhole_test <span class="keyword">VALUES</span>(<span class="number">1</span>, <span class="string">'prop'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询数据为空</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> blackhole_test;</span><br></pre></td></tr></table></figure><p>&emsp;BlackHole引擎的表空间是定义在全局数据字典中的，没有其他文件与之关联。blackhole 引擎是支持所有类型的索引，但不支持分区和自增属性（<code>auto_increment</code>）。最大的特点就是它不记录数据但会记录binlog，这个特性天生就是专门为缓解master中的读取binlog线程的压力。当然还有其他的一些场景：</p><ol><li>验证dump文件的语法；</li><li>衡量 binlog 的负载，通过在使用 blackhole 引擎的情况下，开启和禁用 binlog 功能比较两者性能差异即可得出各个slave对master读取 binlog 的造成的负载情况；</li><li>blackhole 引擎本质上是一种无操作（“no-op”）引擎，所以它可以用来排查和存储引擎无关的瓶颈因素，同时“no-op”的原因，blackhole引擎不会保存自增键的状态，所以自增属性<code>auto_increment</code>在blackhole中不生效；</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-主备复制的基础-二进制日志&quot;&gt;&lt;a href=&quot;#1-主备复制的基础-二进制日志&quot; class=&quot;headerlink&quot; title=&quot;1. 主备复制的基础-二进制日志&quot;&gt;&lt;/a&gt;1. 主备复制的基础-二进制日志&lt;/h2&gt;&lt;p&gt;&amp;emsp;用于就描述 MySQL 事件，包含表创建、数据修改以及可能修改数据的语句（比如没有匹配到记录的&lt;code&gt;DELETE&lt;/code&gt;操作），除非是使用 row-based 日志形式，二进制日志包含了每条语句更新数据时所花费的时间信息，在 mysql 中，二进制日志存在的主要目的有2个：
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="MySQL" scheme="https://jacksonary.github.io/tags/MySQL/"/>
    
      <category term="主备" scheme="https://jacksonary.github.io/tags/%E4%B8%BB%E5%A4%87/"/>
    
  </entry>
  
  <entry>
    <title>Spring 中的模块装配</title>
    <link href="https://jacksonary.github.io/posts/42478593.html"/>
    <id>https://jacksonary.github.io/posts/42478593.html</id>
    <published>2021-02-26T00:36:00.000Z</published>
    <updated>2022-11-08T09:07:57.371Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;Spring 中一直有类似于 <code>@EnbaleXxx</code> 这样注解一键开启 xxx 功能的支持，甚至连配置都不需要就可以使用，对于接入方来说实在是太爽了。最近在写内部中间件就接触到模块装配的知识点，因为对写过中间件的同学都明白，<a id="more"></a>中间件有2点很重要：1.对于业务领域的高度抽象；2. 让接入方爽！重点来了，怎么让对方爽？说白一点，你把业务方的公用的、但又不属于中间件抽象出来的领域行为通过SDK封装好，让业务方几乎不用配置啥就可以用你的功能，这样他就爽了。下面就展示一下一般的流程：</p><h3 id="1-自定义装配模块的注解-EnableXxx"><a href="#1-自定义装配模块的注解-EnableXxx" class="headerlink" title="1. 自定义装配模块的注解 @EnableXxx"></a>1. 自定义装配模块的注解 @EnableXxx</h3><p>&emsp;这个自定义注解很简单，唯一要注意的它比一般的注解多一个<code>@Import({ExcelExportSelector.class})</code>，这个很关键，后面会有用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> weiguo.liu</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2020/11/17</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> excel导出支持的开启配置注解，开启后直接使用 &#123;<span class="doctag">@link</span> ExcelOptTemplate&#125; 提供的方法即可更为简单的操作 推荐使用</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Target</span>(ElementType.TYPE)</span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Import</span>(&#123;ExcelExportSelector.class&#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> EnableExcelExportSupport &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 导出的场景类型，全局，可多个</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    ExcelExportTaskBizType[] types();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">`</span><br></pre></td></tr></table></figure><h3 id="2-指明需要装配哪些配置"><a href="#2-指明需要装配哪些配置" class="headerlink" title="2. 指明需要装配哪些配置"></a>2. 指明需要装配哪些配置</h3><p>&emsp;<code>XxxSelector</code>中说明需要加载哪些配置，这个类必须实现 <code>ImportSelector</code> 接口，在 <code>selectImports</code> 方法中指明所需要加载配置的全类名，返回对象是一个全类名数组。</p><p>下面就是加载2个配置：<code>NewExcelExportDubboConfig</code>和<code>ExcelExportTemplateConfig</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> weiguo.liu</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2020/11/17</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> 这里建议直接实现 DeferredImportSelector 接口，他会在所有的 <span class="doctag">@Bean</span> 生效后再执行</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExcelExportSelector</span> <span class="keyword">implements</span> <span class="title">DeferredImportSelector</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String[] selectImports(AnnotationMetadata importingClassMetadata) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> String[] &#123;NewExcelExportDubboConfig.class.getName(), ExcelExportTemplateConfig.class.getName()&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-提供2中需要导入的配置类"><a href="#3-提供2中需要导入的配置类" class="headerlink" title="3. 提供2中需要导入的配置类"></a>3. 提供2中需要导入的配置类</h3><p>&emsp;<code>NewExcelExportDubboConfig</code>主要是用来注册一个dubboService：newExcelExportService，这样有个好处，接入方不需要在<code>application-consumer.xml</code>去配置消费者就可以使用我们rpc，非常方便。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> weiguo.liu</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2020/11/17</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> template使用的基础dubbo配置</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NewExcelExportDubboConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;dubbo.reference.version&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> String dubboVersion;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ApplicationConfig applicationConfig;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RegistryConfig registry;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span>(name = <span class="string">"newExcelExportService"</span>)</span><br><span class="line">    <span class="meta">@ConditionalOnBean</span>(value = &#123;ApplicationConfig.class, RegistryConfig.class&#125;)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> NewExcelExportService <span class="title">getNewExcelExportService</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ReferenceConfig&lt;NewExcelExportService&gt; reference = <span class="keyword">new</span> ReferenceConfig&lt;&gt;();</span><br><span class="line">        reference.setApplication(applicationConfig);</span><br><span class="line">        <span class="comment">// 多个注册中心可以用setRegistries()</span></span><br><span class="line">        reference.setRegistry(registry);</span><br><span class="line">        reference.setInterface(NewExcelExportService.class);</span><br><span class="line">        reference.setVersion(dubboVersion);</span><br><span class="line">        reference.setCheck(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> reference.get();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再看一下<code>ExcelExportTemplateConfig</code>，这个配置类中主要是注册<code>excelExportTemplate</code> Bean 对象，这个对象中主要是封装了多个像<code>newExcelExportService</code>之类的dubboService，让一些复杂、组合的操作变成一个简单的方式来让接入放调用，所以在注入的时候创建是用的<code>new ExcelExportTemplate(newExcelExportService)</code>。甚至在SDK中我都帮客户端都写好了MQ的监听行为<code>excelExportConsumer</code>，接入想不爽都不行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> weiguo.liu</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/2/23</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExcelExportTemplateConfig</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> NewExcelExportService newExcelExportService;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * excel操作模板</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span>(name = <span class="string">"excelExportTemplate"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ExcelExportTemplate <span class="title">excelOptTemplate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ExcelExportTemplate(newExcelExportService);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span>(name = <span class="string">"excelExportConsumer"</span>)</span><br><span class="line">    <span class="meta">@ConditionalOnBean</span>(value = &#123;ExcelExportTemplate.class, ExcelExportHandler.class&#125;)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ExcelExportConsumer <span class="title">excelExportConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ExcelExportConsumer();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>稍微瞄一下MQ的监听类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> weiguo.liu</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2020/11/24</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> excel业务校验的基础消息消费类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExcelExportConsumer</span> <span class="keyword">extends</span> <span class="title">BaseConsumer</span> <span class="keyword">implements</span> <span class="title">ApplicationContextAware</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(ExcelExportConsumer.class);</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 业务方需要监听的mq</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> TraceTopic EXCEL_EXPORT_TOPIC = TraceTopic.EXCEL_EXPORT_TASK_CREATE;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ApplicationContext springApplicationContext;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer, ExcelExportHandler&gt; bizTypeContainer = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> ExcelExportTemplate excelExportTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;public.rocketmq.nameserver.name&#125;"</span>)</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNameServer</span><span class="params">(String nameServer)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.nameServer = nameServer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 特殊场景需要，重新定义</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;rocketmq.consumer.group&#125;"</span>)</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setGroup</span><span class="params">(String group)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.group = group;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initMethod</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.init();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (CollectionUtils.isEmpty(bizTypeContainer)) &#123;</span><br><span class="line">            fillBizTypeContainer();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PreDestroy</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroyMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.destroy();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getTopic</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> EXCEL_EXPORT_TOPIC.getTopic();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getTags</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> EXCEL_EXPORT_TOPIC.getTags();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">doConsumeMessage</span><span class="params">(String msgId, <span class="keyword">int</span> reconsumeTimes, Serializable message)</span> </span>&#123;</span><br><span class="line">        LOGGER.info(<span class="string">"ExcelExportConsumer receive topic:&#123;&#125; tag:&#123;&#125; message:&#123;&#125;"</span>, EXCEL_EXPORT_TOPIC.getTopic(),</span><br><span class="line">            EXCEL_EXPORT_TOPIC.getTags(), JSON.toJSONString(message));</span><br><span class="line">        <span class="keyword">if</span> (!(message <span class="keyword">instanceof</span> ExcelExportAddNotifyDTO)) &#123;</span><br><span class="line">            LOGGER.warn(<span class="string">"&gt;&gt; useless message,msgId=&#123;&#125;, message=&#123;&#125;"</span>, msgId, JSON.toJSONString(message));</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ExcelExportAddNotifyDTO excelTaskNotifyDTO = (ExcelExportAddNotifyDTO)message;</span><br><span class="line">        <span class="keyword">if</span> (!acceptable(msgId, excelTaskNotifyDTO)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果需要自定义检查消息体内容，需要覆盖此方法</span></span><br><span class="line">        <span class="comment">// true 数据合法，业务后端会接着处理业务 | false 数据非法，请求终止，业务方逻辑不会继续处理，直接失败，任务超时</span></span><br><span class="line">        <span class="keyword">if</span> (!customCheck()) &#123;</span><br><span class="line">            LOGGER.warn(<span class="string">"&gt;&gt; customCheck failed."</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ExcelExportHandler processHandler = bizTypeContainer.get(excelTaskNotifyDTO.getBizType());</span><br><span class="line">        <span class="keyword">if</span> (processHandler == <span class="keyword">null</span>) &#123;</span><br><span class="line">            LOGGER.warn(<span class="string">"&gt;&gt; found no handler -&gt; can not found excel export handler, type:&#123;&#125;"</span>,</span><br><span class="line">                excelTaskNotifyDTO.getBizType());</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> processHandler.process(excelTaskNotifyDTO);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 如果需要自定义检查消息体内容，需要覆盖此方法</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> true 数据合法，业务后端会接着处理业务 | false 数据非法，请求终止，业务方逻辑不会继续处理，直接失败</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">customCheck</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 简单的数据预处理</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> excelTaskNotifyDTO</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">acceptable</span><span class="params">(String msgId, ExcelExportAddNotifyDTO excelTaskNotifyDTO)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (excelTaskNotifyDTO == <span class="keyword">null</span>) &#123;</span><br><span class="line">            LOGGER.warn(<span class="string">"&gt;&gt; excelTaskNotifyDTO is null, msgId:&#123;&#125;"</span>, msgId);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> bizType = excelTaskNotifyDTO.getBizType();</span><br><span class="line">        <span class="keyword">if</span> (!CollectionUtils.isEmpty(bizTypeContainer) &amp;&amp; !bizTypeContainer.containsKey(bizType)) &#123;</span><br><span class="line">            LOGGER.warn(<span class="string">"&gt;&gt; not your msg -&gt; your type is &#123;&#125;, msgId:&#123;&#125;, msg's bizType is &#123;&#125;."</span>,</span><br><span class="line">                JSON.toJSONString(bizTypeContainer), msgId, excelTaskNotifyDTO.getBizCondition());</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ExcelExportTaskDO task = excelExportTemplate.getTask(excelTaskNotifyDTO.getId());</span><br><span class="line">        <span class="keyword">if</span> (task == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (ExcelExportTaskStatus.isTerminalStatus(task.getStatus())) &#123;</span><br><span class="line">            LOGGER.warn(<span class="string">"&gt;&gt; unexpect result -&gt; task's status arrive terminal status, task:&#123;&#125;"</span>, JSON.toJSONString(task));</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setApplicationContext</span><span class="params">(ApplicationContext applicationContext)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        springApplicationContext = applicationContext;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">fillBizTypeContainer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; excelExportSupportAnnotation =</span><br><span class="line">            springApplicationContext.getBeansWithAnnotation(EnableExcelExportSupport.class);</span><br><span class="line">        <span class="keyword">if</span> (CollectionUtils.isEmpty(excelExportSupportAnnotation)) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Map&lt;String, Object&gt; excelExportHandlerAnnotation =</span><br><span class="line">            springApplicationContext.getBeansWithAnnotation(CustomExcelExportHandler.class);</span><br><span class="line">        Map&lt;Integer, ExcelExportHandler&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">8</span>);</span><br><span class="line">        excelExportHandlerAnnotation.forEach((k, v) -&gt; &#123;</span><br><span class="line">            Class&lt;?&gt; clazz = v.getClass();</span><br><span class="line">            CustomExcelExportHandler annotation =</span><br><span class="line">                AnnotationUtils.findAnnotation(clazz, CustomExcelExportHandler.class);</span><br><span class="line">            <span class="keyword">if</span> (annotation != <span class="keyword">null</span>) &#123;</span><br><span class="line">                ExcelExportTaskBizType type = annotation.type();</span><br><span class="line">                map.put(type.getCode(), (ExcelExportHandler)v);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        excelExportSupportAnnotation.forEach((key, value) -&gt; &#123;</span><br><span class="line">            Class&lt;?&gt; aClass = value.getClass();</span><br><span class="line">            EnableExcelExportSupport annotation =</span><br><span class="line">                AnnotationUtils.findAnnotation(aClass, EnableExcelExportSupport.class);</span><br><span class="line">            <span class="keyword">if</span> (annotation != <span class="keyword">null</span> &amp;&amp; annotation.types().length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                Arrays.asList(annotation.types()).forEach(o -&gt; bizTypeContainer.put(o.getCode(), map.get(o.getCode())));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的操作完成后，一旦业务方在启动类上添加了注解 <code>@EnableExcelExportSupport</code> 注解后，业务方就会自动注入我们中间件的 dubboSrvice <code>newExcelExportService</code>、封装好的dubboService的操作模板<code>excelExportTemplate</code>以及MQ的消费者。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;Spring 中一直有类似于 &lt;code&gt;@EnbaleXxx&lt;/code&gt; 这样注解一键开启 xxx 功能的支持，甚至连配置都不需要就可以使用，对于接入方来说实在是太爽了。最近在写内部中间件就接触到模块装配的知识点，因为对写过中间件的同学都明白，
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Spring" scheme="https://jacksonary.github.io/tags/Spring/"/>
    
      <category term="模块装配" scheme="https://jacksonary.github.io/tags/%E6%A8%A1%E5%9D%97%E8%A3%85%E9%85%8D/"/>
    
  </entry>
  
  <entry>
    <title>RESTful架构</title>
    <link href="https://jacksonary.github.io/posts/2654e413.html"/>
    <id>https://jacksonary.github.io/posts/2654e413.html</id>
    <published>2020-10-04T01:38:21.000Z</published>
    <updated>2022-11-08T10:04:54.513Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;REST(Representational State Transfer)中文含义是表述性状态转移，它指的是一组架构约束条件和原则(它是一种设计风格而不是标准)，如果一个架构符合REST的约束条件和原则，我们就称它为RESTful架构。理论上REST架构风格并不是绑定在HTTP上，只不过目前HTTP是唯一与REST相关的实例，但不要形成固定思维。目前在三种主流的Web服务实现方案中，因为REST模式的Web服务与复杂的SOAP和XML-RPC对比来讲明显的更加简洁，越来越多的web服务开始采用REST风格设计和实现。REST的设计标准有下面的一些：<a id="more"></a></p><ul><li>网络上的所有事物都被抽象为资源（resource），在REST的世界中，资源即状态，而互联网就是一个巨大的状态机，每个网页是其一个状态；URI是状态的表述；REST风格的应用则是从一个状态迁移到下一个状态的状态转移过程。早期互联网只有静态页面的时候，通过超链接在静态网页间浏览跳转的page-&gt;link-&gt;page-&gt;link…模式就是一种典型的状态转移过程。也就是说早期的互联网就是天然的REST；</li><li>每个资源对应一个唯一的资源标识符（resource identifier），系统中的每一个对象或是资源都可以通过一个唯一的 URI 来进行寻址，URI 的结构应该简单、可预测且易于理解，比如定义目录结构式的URI；</li><li>通过通用的连接器接口（generic connector interface）对资源进行操作，建立创建、检索、更新和删除（CRUD：Create, Retrieve, Update and Delete）操作与HTTP方法之间的一对一映射，主要如下：<ul><li>若要在服务器上创建资源，应该使用POST方法；</li><li>若要检索某个资源，应该使用GET方法；</li><li>若要更新或者添加资源，应该使用PUT方法；</li><li>若要删除某个资源，应该使用DELETE方法。</li></ul></li><li>对资源的各种操作不会改变资源标识符；</li><li>所有的操作都是无状态的（stateless），对服务器端的请求应该是无状态的，完整、独立的请求不要求服务器在处理请求时检索任何类型的应用程序上下文或状态，无状态约束使服务器的变化对客户端是不可见的，因为在两次连续的请求中，客户端并不依赖于同一台服务器。一个客户端从某台服务器上收到一份包含链接的文档，当它要做一些处理时，这台服务器宕掉了，可能是硬盘坏掉而被拿去修理，可能是软件需要升级重启——如果这个客户端访问了从这台服务器接收的链接，它不会察觉到后台的服务器已经改变了。通过超链接实现有状态交互，即请求消息是自包含的（每次交互都包含完整的信息），有多种技术实现了不同请求间状态信息的传输，例如 URI 重新，cookies 和隐藏表单字段等，状态可以嵌入到应答消息里，这样一来状态在接下来的交互中仍然有效。REST 风格应用可以实现交互，但它却天然地具有服务器无状态的特征。在状态迁移的过程中，服务器不需要记录任何 Session，所有的状态都通过 URI 的形式记录在了客户端。更准确地说，这里的无状态服务器，是指服务器不保存会话状态(Session)；而资源本身则是天然的状态，通常是需要被保存的；这里所指无状态服务器均指无会话状态服务器。</li></ul><p>【总结】</p><p>什么是RESTful架构—</p><p>　　（1）每一个URI代表一种资源；</p><p>　　（2）客户端和服务器之间，传递这种资源的某种表现层；</p><p>　　（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。</p><h2 id="1-基础"><a href="#1-基础" class="headerlink" title="1. 基础"></a>1. 基础</h2><ul><li>API与用户的通信协议总是用<code>https</code>协议；</li><li>API尽量部署到专用域名下，如<code>https://api.example.com</code>；</li><li>将API的版本号放入URL中，如<code>https://api.example.com/v1/</code>，此外，还可以将其放在HTTP头信息中，但不如放入URL方便和直观；</li><li>路径又称”终点”（endpoint），表示API的具体网址，在RESTful架构中，每个网址代表一种资源（resource），所以<font color="red">网址中不能有动词(具体动词表现在像<code>get</code>、<code>post</code>这些方法上)</font>，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数，如一个提供动物园信息的API可以像下面的这样：<code>https://api.example.com/v1/zoos</code>、<code>https://api.example.com/v1/animals</code>等；</li><li>对资源进行具体操作时，主要表现在方法层面，比如：<ul><li><code>GET /zoos</code>：列出所有动物园；</li><li><code>POST /zoos</code>：新建一个动物园；</li><li><code>GET /zoos/ID</code>：获取某个指定动物园的信息；</li><li><code>PUT /zoos/ID</code>：更新某个指定动物园的信息（提供该动物园的全部信息）；</li><li><code>PATCH /zoos/ID</code>：更新某个指定动物园的信息（提供该动物园的部分信息）；</li><li><code>DELETE /zoos/ID</code>：删除某个动物园；</li><li><code>GET /zoos/ID/animals</code>：列出某个指定动物园的所有动物；</li><li><code>DELETE /zoos/ID/animals/ID</code>：删除某个指定动物园的指定动物；</li><li><font color="red">【注意】</font><code>PUT</code>和<code>PATCH</code>都是更新资源，但前者需要客户端提供改变后的完整资源，而后者只需要客户端提供改变的属性即可；</li></ul></li><li>过滤信息，API提供参数可以过滤返回结果，常见的参数有：<ul><li><code>?limit=10</code>：指定返回记录的数量，这里是10；</li><li><code>?offset=10</code>：指定返回记录的开始位置；</li><li><code>?page=2&amp;per_page=100</code>：指定第几页，以及每页的记录数；</li><li><code>?sortby=name&amp;order=asc</code>：指定返回结果按照哪个属性排序，以及排序顺序；</li><li><code>?animal_type_id=1</code>：指定筛选条件；</li><li><font color="red">【注意】</font>参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复；</li></ul></li><li>错误的信息的处理：如果状态码是<code>4xx</code>，就应该向用户返回出错信息。一般来说，返回的信息中将<code>error</code>作为键名，出错信息作为键值即可，如<code>error: &quot;Invalid API key&quot;</code>;</li><li>不同接口调用返回的结果应该符合如下的规范：<ul><li><code>GET /collection</code>：返回资源对象的列表（数组）；</li><li><code>GET /collection/resource</code>：返回单个资源对象；</li><li><code>POST /collection</code>：返回新生成的资源对象；</li><li><code>PUT /collection/resource</code>：返回完整的资源对象；</li><li><code>PATCH /collection/resource</code>：返回完整的资源对象；</li><li><code>DELETE /collection/resource</code>：返回一个空文档；</li></ul></li><li>API的身份认证应该使用<code>OAuth 2.0</code>框架；</li><li>服务器返回的数据格式，应该尽量使用JSON，避免使用XML；</li><li>Hypermedia API，即超媒体API，Hypermedia API的设计被称为HATEOAS。返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么，如：向<code>api.example.com</code>请求得到：</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"link"</span>: &#123;</span><br><span class="line">        <span class="attr">"rel"</span>: <span class="string">"collection https://www.example.com/zoos"</span>,</span><br><span class="line">        <span class="attr">"href"</span>: <span class="string">"https://api.example.com/zoos"</span>,</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"List of zoos"</span>,</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"application/vnd.yourformat+json"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>rel</code>表示这个<code>API</code>与当前网址的关系（collection关系，并给出该collection的网址），<code>href</code>表示API的路径，<code>title</code>表示API的标题，<code>type</code>表示返回类型；</p><p>REST API案例(用户和订单)：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/API%E6%A1%88%E5%88%97.png" alt="API案列"></p><p>【总结】</p><p>&emsp;REST是面向资源的(非常重要)，而资源是通过URI进行暴露，URI的设计只要负责把资源通过合理方式暴露出来就可以了，对资源的操作与它无关，操作是通过HTTP动词来体现，所以REST通过URI暴露资源时，会强调不要在URI中出现动词。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;REST(Representational State Transfer)中文含义是表述性状态转移，它指的是一组架构约束条件和原则(它是一种设计风格而不是标准)，如果一个架构符合REST的约束条件和原则，我们就称它为RESTful架构。理论上REST架构风格并不是绑定在HTTP上，只不过目前HTTP是唯一与REST相关的实例，但不要形成固定思维。目前在三种主流的Web服务实现方案中，因为REST模式的Web服务与复杂的SOAP和XML-RPC对比来讲明显的更加简洁，越来越多的web服务开始采用REST风格设计和实现。REST的设计标准有下面的一些：
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="RESTful" scheme="https://jacksonary.github.io/tags/RESTful/"/>
    
      <category term="API" scheme="https://jacksonary.github.io/tags/API/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot集成Prometheus</title>
    <link href="https://jacksonary.github.io/posts/8d957094.html"/>
    <id>https://jacksonary.github.io/posts/8d957094.html</id>
    <published>2020-05-08T03:56:12.000Z</published>
    <updated>2022-11-08T09:07:57.372Z</updated>
    
    <content type="html"><![CDATA[<p>SpringBoot集成prometheus:</p><ol><li>添加依赖：</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.micrometer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>micrometer-registry-prometheus<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.prometheus<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>simpleclient_spring_boot<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><a id="more"></a><ol start="2"><li>添加配置：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">management.metrics.tags.application=account-server</span><br><span class="line">management.metrics.export.prometheus.enabled=true</span><br><span class="line">management.metrics.export.jmx.enabled=true</span><br><span class="line">management.endpoints.web.exposure.include=*</span><br><span class="line">management.endpoints.web.base-path=/metrics</span><br><span class="line"></span><br><span class="line"># 添加 http_server_requests_seconds_bucket 直方图配置</span><br><span class="line">management.metrics.distribution.percentiles-histogram.http.server.requests=true</span><br><span class="line"></span><br><span class="line"># 其他可选配置</span><br><span class="line">  metrics:</span><br><span class="line">    distribution:</span><br><span class="line">      percentiles-histogram:</span><br><span class="line">        http.server.requests: true</span><br><span class="line">      sla:</span><br><span class="line">        http.server.requests: 50ms</span><br></pre></td></tr></table></figure><ol start="3"><li>启动类添加(可省)</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function">MeterRegistryCustomizer <span class="title">meterRegistryCustomizer</span><span class="params">(MeterRegistry meterRegistry)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> meterRegistry1 -&gt; meterRegistry.config()</span><br><span class="line">            .commonTags(<span class="string">"application"</span>, <span class="string">"account-server"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>验证：<br><a href="http://localhost:8081/metrics" rel="external nofollow noopener noreferrer" target="_blank">http://localhost:8081/metrics</a><br><a href="http://localhost:8081/metrics/prometheus" rel="external nofollow noopener noreferrer" target="_blank">http://localhost:8081/metrics/prometheus</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SpringBoot集成prometheus:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;添加依赖：&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;io.micrometer&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;micrometer-registry-prometheus&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.3.2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;spring-boot-starter-actuator&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;io.prometheus&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;simpleclient_spring_boot&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;0.8.1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Prometheus" scheme="https://jacksonary.github.io/tags/Prometheus/"/>
    
      <category term="SpringBoot" scheme="https://jacksonary.github.io/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>Docker的存储驱动</title>
    <link href="https://jacksonary.github.io/posts/4bf33dda.html"/>
    <id>https://jacksonary.github.io/posts/4bf33dda.html</id>
    <published>2020-04-02T10:06:59.000Z</published>
    <updated>2022-11-08T10:04:54.538Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;存储驱动允许用户在容器的可写层创建数据，但这些数据并不会持久化，随着容器的消亡而消亡，而且存储驱动的赋予这些文件读、写速度都比本地文件系统的性能要慢。</p><h2 id="1-关于-image-和-layer"><a href="#1-关于-image-和-layer" class="headerlink" title="1. 关于 image 和 layer"></a>1. 关于 image 和 layer</h2><p>&emsp;Docker镜像是以一系列的layers为基础构建出来的，镜像中的每个layer都代表着一条指令，除最后一层其他每层都是只读的，所以镜像可以理解为是一个个的只读层堆积起来的。像下面的 Dokcerfile :</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">18.04</span></span><br><span class="line"><span class="keyword">COPY</span> . /app</span><br><span class="line"><span class="keyword">RUN</span> make /app</span><br><span class="line"><span class="keyword">CMD</span> python /app/app.py</span><br></pre></td></tr></table></figure><a id="more"></a><p>上述的 Dockerfile 就会创建4层 layer，<code>FROM</code>指令从 ubuntu:18.04 镜像创建一个 layer，<code>COPY</code>指令从Docker客户端的当前目录添加文件，<code>RUN</code>指令使用<code>make</code>命令来编译应用，最后一个layer指定了容器中运行的命令。</p><p>&emsp;每一个layer都是一系列和前一个layer不同的东西组成，然后这些layer相互堆积。当创建一个新的容器时，其实这个行为的实质就是在底层的 layer 上添加了一个可写层，这个可写层就是常说的“容器层”，接下来容器内所有的增、改行为（创建、修改文件）都是写入到这个可写层上。存储驱动解决了这些layers之间的通信，不同的存储驱动在不同情况下各有利弊，应该根据业务场景选型。</p><h2 id="2-容器和-layer"><a href="#2-容器和-layer" class="headerlink" title="2. 容器和 layer"></a>2. 容器和 layer</h2><p>&emsp;其实了解了镜像和层的关系后，容器和镜像的最大区别是容器的顶层是可写的，但镜像是只读的，所有写入容器的内容都是存储到可写层的，不会影响镜像的内容，所以当容器消亡时，可写层也随之消亡，那么之前写入的内容会丢失。每个容器都有自己的可写容器层，一个镜像可以创建多个容器，但每个容器都有他们各自的可写层，并不会相互影响（除非指定挂载同一个目录），之间的关系如下：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="容器和镜像的关系"></p><p>可以简单的理解为<code>容器 = 镜像 + 可写层</code>，而Docker的存储驱动就是Docker用来管理镜像层和可写容器层的，每个存储驱动实现方式都不太一样，但所有的存储驱动都是使用可堆积的镜像层和“写时复制”策略（Cow - copy-on-write）。</p><h2 id="3-容器的size"><a href="#3-容器的size" class="headerlink" title="3. 容器的size"></a>3. 容器的size</h2><p>&emsp;使用 <code>docker ps -s</code>中的<code>-s</code>参数可以看到一列名为 SIZE 的列，该列包含的内容大概形式为“0B (virtual 64.2MB)”，0表示容器可写层中的数据量（一般不会为0，除非容器已经停止），括号中的<code>virtual 64.2MB</code>表示镜像+容器可写层的总数据量。因为多个容器可以共享只读的镜像层，如果镜像层是同一个，那它们的只读数据肯定都是共享的，但如果由两个不同的镜像创建的两个容器，但如果这2个镜像中有相同的layer也会共享，因此很难推断总虚拟化的大小（只是简单的进行加和的话），一般都是比加和的总共要小。下面是我简单看了下官方一直叨叨的 the thin writable layer ：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker ps -s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> alpine-base:1.0 是一个包含openjdk8和nodejs12的最小化Linux</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES               SIZE</span><br><span class="line">fa689846c376        alpine-base:1.0     "/bin/sh"           2 hours ago         Up 2 hours                              focused_rubin       193B (virtual 153MB)</span><br></pre></td></tr></table></figure><p>可以看到可写容器层的数据量只占用了193B，确实很小很苗条，但个人理解可写层厚薄与否实际取决于应用在可写层操作行为，比如我在容器内生成一个体积较大的块<code>dd if=/dev/zero of=test bs=1M count=1000</code>，然后再看一下可写层的数据量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker ps -s</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES               SIZE</span><br><span class="line">418eb1cbcea5        22de903425e2        "/bin/sh"           About a minute ago   Up About a minute                       angry_newton        1.05GB (virtual 1.2GB)</span><br></pre></td></tr></table></figure><p>瞬间就达到了1.05G，但Docker本身倡导 thin writable container layer，如果你的应用在容器有很大的数据量写入，建议使用数据卷 volume 挂载，这样可以提高I/O效率，而且和应用本身隔离，容器可写层不会占用太多空间，这也是被提倡的。</p><h2 id="4-写时复制-Copy-on-Write"><a href="#4-写时复制-Copy-on-Write" class="headerlink" title="4. 写时复制 Copy-on-Write"></a>4. 写时复制 Copy-on-Write</h2><p>&emsp;写时复制是一种共享和复制文件的策略，能最大程度地提高效率，如果某个文件或目录已经存在于镜像中的底层 layer 中，然后另外一个layer（可以是镜像中的某个layer或直接是容器可写层）需要读取这个文件或目录，那这个文件或目录就会被复制到需要读取该文件的layer中进行相应的读取或修改，这样可以将I/O和每个后续层的大小最小化。</p><h3 id="4-1-最小化镜像大小"><a href="#4-1-最小化镜像大小" class="headerlink" title="4.1 最小化镜像大小"></a>4.1 最小化镜像大小</h3><p>&emsp;当使用<code>docker pull</code>拉取镜像时，或者使用一个不存在的镜像创建容器时，docker 会进行镜像的拉取，可以看到它是一个layer一个layer独立拉取的，存储到Docker本地存储区中（通常是<code>/var/lib/docker</code>目录），每个layer存储到Docker宿主机器的目录中，可以查看<code>/var/lib/docker/&lt;storage-driver&gt;</code>目录，比如 overlay 或者 overlay2，但里面的目录并不是和layer的id一一对应的。注意Docker中的镜像是以layer为基础的，就算2个镜像不同，但如果它们之间有相同的layer时还是会进行共享的，通常可以使用<code>docker history &lt;image-name/image-id&gt;</code>查看镜像中的layer信息，比如下面是 alpine-base:1.0 （一个包含openjdk8和nodejs12的最小化Linux）镜像的Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine:latest</span><br><span class="line"><span class="keyword">MAINTAINER</span> WeiguoLiu &lt;jacksonary@<span class="number">163</span>.com&gt;</span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span> apk update</span><br><span class="line"><span class="keyword">RUN</span> apk fetch openjdk8</span><br><span class="line"><span class="keyword">RUN</span> apk add openjdk8</span><br><span class="line"><span class="keyword">RUN</span> apk add nodejs</span><br></pre></td></tr></table></figure><p>build完再看一下该镜像的layer：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 查看 alpine-base:1.0 的层信息</span><br><span class="line">docker history bec86562d726</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 结果</span><br><span class="line">IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class="line">bec86562d726        2 days ago          /bin/sh -c apk add nodejs                       29.6MB              </span><br><span class="line">60359c5a2fda        2 days ago          /bin/sh -c apk add openjdk8                     100MB               </span><br><span class="line">cb259c1d667d        2 days ago          /bin/sh -c apk fetch openjdk8                   15.8MB              </span><br><span class="line">ef35bbeb82c2        2 days ago          /bin/sh -c apk update                           1.57MB              </span><br><span class="line">0e8ab980a0c8        2 days ago          /bin/sh -c #(nop)  USER root                    0B                  </span><br><span class="line">2dda369aac80        2 days ago          /bin/sh -c #(nop)  MAINTAINER WeiguoLiu &lt;liu…   0B                  </span><br><span class="line">cc0abc535e36        2 weeks ago         /bin/sh -c #(nop)  CMD ["/bin/sh"]              0B                  </span><br><span class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop) ADD file:36fdc8cb08228a870…   5.59MB</span><br></pre></td></tr></table></figure><p>和之前说的一样，Dockerfile中的每个命令都是一个新的layer，上面展现出来的layer信息几乎和Dockerfile中是一样的，而且可以发现除了在使用<code>apk add</code>安装软件外，其他指令几乎不会占用空间（因为大部分的指令仅仅是一个“指令”），此外很多底层镜像都会在<code>FROM XXX</code>引入基础镜像，但这个镜像是在本地所没有的或者是使用另一个系统构建的，那在显式层信息时就会显式上面的<code>&lt;missing&gt;</code>的样式。</p><h3 id="4-2-提高容器效率"><a href="#4-2-提高容器效率" class="headerlink" title="4.2 提高容器效率"></a>4.2 提高容器效率</h3><p>&emsp;当创建容器时，一个薄薄的可写层（感觉docker每次提及 the thin writable layer 时都是可骄傲可骄傲的，哈哈o(<em>￣▽￣</em>)o）将加到镜像的顶层，然后容器内<font color="red">所有文件系统的改变</font>都会存储到这个可写层，而容器中其他任何没有发生改动的文件都不会复制到可写层，所以说这点可以在一定程度上减小了容器可写层的数据量。</p><p>&emsp;在容器内对一个文件进行修改时，那存储驱动就会进行“写时复制”（CoW）的操作，具体操作流程会根据不同的存储驱动而有所不同（而且是强依赖、强相关），比如<code>aufs</code>、<code>overlay</code>和<code>overlay2</code>这3种存储驱动，但写时复制遵循下面大致的顺序：</p><ol><li>从镜像底层查找需要更新的文件，这个过程从镜像的最顶层开始，一直到基础层，当查找完毕后，它们将查找得到的文件添加到缓存以便于后面的操作；</li><li>对第一个查找到的文件副本执行<code>copy_up</code>操作，将这个文件复制到容器的可写层；</li><li>所有的改动都执行到这个副本，容器并不能看到镜像底层只读的文件（因为镜像中的layer都是只读的）；</li></ol><p>&emsp;Btrfs、ZFS和其他的驱动在处理写时复制都有所不同，<code>copy_up</code>操作行为会引发明显的性能开销（开销大小依赖于不同的存储驱动），尤其是在文件量比较大或层次、目录树比较深时，这种消耗可以这样减轻：仅在第一次修改某个文件时进行<code>copy_up</code>。下面是一个计数器镜像的示例（创建4个容器并查看它们所占用的空间）：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/%E5%AE%B9%E5%99%A8%E5%9C%A8%E5%AE%BF%E4%B8%BB%E6%9C%BA%E4%B8%8A%E5%AD%98%E5%82%A8.png" alt="容器在宿主机上存储"></p><h2 id="5-存储驱动"><a href="#5-存储驱动" class="headerlink" title="5. 存储驱动"></a>5. 存储驱动</h2><p>&emsp;一般情况下，推荐在容器可写层写入少量数据，如果数据量较大，建议切换成 volume 挂载的方式，但有些情况又必须写入容器层，此时就涉及到了存储驱动。Docker支持多种存储驱动，且以热拔插的方式运行，它控制着宿主机如何存储以及管理镜像和容器。</p><h3 id="5-1-存储驱动的选择"><a href="#5-1-存储驱动的选择" class="headerlink" title="5.1 存储驱动的选择"></a>5.1 存储驱动的选择</h3><p>&emsp;如果内核支持多个存储驱动，如果没有显式配置存储驱动，Docker将使用内置的存储驱动优先级别列表来决定使用哪个。Docker支持的存储驱动有（首选 <font color="red">overlay2</font>）：</p><ul><li><code>overlay2</code>：是首选的存储驱动，适用于所有Linux发行版，不需要额外的配置；</li><li><code>aufs</code>：对于 Ubuntu 14.04 的 3.13 内核，Docker 18.06 及之前的版本，aufs 是首选的存储驱动，但仅支持Ubuntu 和 Debian，可能还需要安装额外的包；</li><li><code>devicemapper</code>：Docker支持该存储驱动，但对于生产环境需要<code>direct-lvm</code>，因为<code>loopback-lvm</code>虽然也是零配置，但性能非常差。对于 centOS 和 RHEL 是推荐使用的存储驱动，因为这两种操作系统的内核不支持<code>overlay2</code>，但它们的版本已经支持<code>overlay2</code>，所以最终还是推荐使用<code>overlay2</code>驱动；</li><li><code>btrfs</code>和<code>zfs</code>：如果 <code>btrfs</code> 和 <code>zfs</code> 存储驱动程序是后备文件系统（安装了Docker的主机的文件系统），则使用它们。这些文件系统有更高级的选项（比如创建快照，但需要更多的维护和配置），这些都依赖于正确配置的支持文件系统，仅支持SLES，而且只有Docker企业版才支持；</li><li><code>vfs</code>：专门为了测试设计的存储驱动，以及无法使用写时复制文件系统的情况才会使用，性能差，不推荐使用；</li></ul><p>&emsp;<strong>根据负载选择合适的驱动</strong>：每个存储驱动程序都有其自己的性能特征，这或多或少地会让不同的存储驱动适合于不同的工作负载。但也有一些共性：</p><ul><li><code>overlay2</code>、<code>aufs</code>、<code>overlay</code>所有的操作都是在文件级别上操作的而不是块上进行，这种方式对于空间的利用率很高，但对于写操作频繁的应用而言，容器可写层占用的空间会增长的比较大；</li><li>类似于<code>devicemapper</code>、<code>btrfs</code>、<code>zfs</code>这种块级别的存储驱动，更适用于写操作频繁的应用，虽然性能没有volume挂载好；</li><li>对于很多少写或容器层级比较多或者文件系统目录树比较深的情况，<code>overlay</code>通常会比<code>overlay2</code>要好，但会消耗更多的inode（类似于用于索引的存储块-索引节点，记录了文件的metadata），可能导致inode耗尽；</li><li><code>btrfs</code>和<code>zfs</code>需要很多内存；</li><li><code>zfs</code>对于高密度的负载是个好选择，比如 PaaS；</li></ul><h3 id="5-2-AUFS存储驱动"><a href="#5-2-AUFS存储驱动" class="headerlink" title="5.2 AUFS存储驱动"></a>5.2 AUFS存储驱动</h3><p>&emsp;aufs 是联合文件系统（advanced multi-layered unification filesystem）的简称，它之前是Ubuntu以及Stretch之前的Debian版本中Docker管理镜像和层的默认存储驱动。如果Linux的内核版本4.0+，那就可以使用 Docker Engine - Community，建议使用更新的 overlay2 驱动（比aufs更具优势），Docker的某些版本是不支持aufs驱动的。如果使用aufs驱动，必须具备一些条件：</p><ul><li>对于Docker Engine - Community，aufs驱动支持Ubuntu以及Stretch之前的Dibian；</li><li>对于Docker EE，aufs驱动支持Ubuntu；</li><li>对于Ubuntu，需要安装额外的包以便将aufs模块加入到内核。注意：如果不安装这些额外的包，就需要使用<code>devicemapper</code>驱动（对于Ubuntu 14.04版本而言，当然这是不被推荐的）或者<code>overlay2</code>（对于Ubuntu 16.04版本而言，可以接受）；</li><li>aufs驱动不能使用下面的备份文件系统：aufs、btrfs以及ecryptfs，换而言之，在<code>/var/lib/docker/aufs</code>中不会出现上面的这些文件系统类型；</li></ul><p>&emsp;aufs的配置也很方便，步骤如下：</p><ol><li>检测是否宿主机器的内核是否支持aufs，直接查看<code>proc/filesystem</code>文件（这个文件中罗列了当前内核支持的所有文件系统，总共两列信息，其中第二列表示支持的文件系统，第一列如果是“nodev”表示对应的文件系统尚未被mount某块设备上，如果第一列为空白，则表示该文件系统已经被挂载到某块设备上了）中是否有<code>aufs</code>关键字：<code>grep aufs /proc/filesystems</code>，如果可以查找到<code>nodev aufs</code>就表示支持aufs，且没有挂载到其他设备上；</li><li>查看当前Docker使用的存储驱动：<code>docker info</code>，可以看到<code>Storage Driver: overlay</code>；</li><li>查看<code>/etc/docker/daemon.json</code>文件是否配置驱动，查看docker启动时是否使用<code>--storage-driver</code>参数指定存储驱动：<code>ps auxw | grep dockerd</code>；</li></ol><p>&emsp;aufs是联合文件系统，可以把多个文件夹的内容合并到一起并提供统一的视图，然后这些目录在aufs专业术语中叫做分支，对应于Docker中就是layer。工作原理如下：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/aufs_layers.jpg" alt="aufs_layers"></p><p>一般这些信息就是存在<code>/var/lib/docker/&lt;store-driver&gt;</code>目录中（store-driver取决于Docker使用的驱动），然后这个目录里面所有目录和文件都是由Docker自己管理。所有的镜像和容器可写层的信息都是存储在<code>/var/lib/docker/&lt;store-driver&gt;</code>目录中（对应于aufs就是<code>/var/lib/docker/aufs</code>目录），通常该目录中会有如下的子目录：</p><ul><li><code>diff</code>：该目录包含了容器可写层的差异，比如新增或修改的文件；</li><li><code>layers</code>：该目录中存储了容器可写层的父级layer；</li><li><code>mnt</code>：表示每一个运行容器的文件系统的挂载点，它和容器一起出现；</li></ul><p>对应于上图，每个镜像层以及容器可写层在Docker宿主机上都是以<code>/var/lib/docker</code>下面的子目录形式表现，联合安装提供所有层的统一视图，但里面的目录并不是和layer的id一一对应的。</p><p>&emsp;总的来说，aufs驱动特性有：</p><ul><li>总体性能不如 overlay2，但对于类似于PaaS这类高密度的应用而言是一个不错的选择，因为 aufs 可以在多个运行的容器之间实现高效的共享，加快容器的启动，减小磁盘占用；</li><li>aufs在镜像层和容器之间的共享文件非常有效地使用了页面缓存；</li><li>aufs存储驱动在容器写入的延迟更加明显，因为容器在首次写入文件时，需要先定位到该文件再将其复制到容器可写层，而且在该文件存在于很多layer中时或这些文件本身就很大，那这种延迟会越来越严重和复杂；</li></ul><p>如果场景确实需要使用aufs驱动，那最佳实践建议作如下的措施：</p><ul><li>使用SSD（Solid State Devices 固态硬盘）：它可以提供比磁盘更加快速的读、写速度；</li><li>对于写入频繁的应用使用 volume 挂载：数据卷可以为写入频繁的应用提供最佳也是最合适的性能，<font color="red">因为volume挂载绕过了存储驱动程序，并且不会产生任何精简配置和写时复制所带来的潜在开销。</font></li></ul><h3 id="5-3-BTRFS存储驱动"><a href="#5-3-BTRFS存储驱动" class="headerlink" title="5.3 BTRFS存储驱动"></a>5.3 BTRFS存储驱动</h3><p>&emsp;btrfs是下一代支持很多高级存储技术的写时复制文件系统（这对Docker很友好，但只支持Ubuntu和Debian上的社区版Docker和SLES上的社区版、企业版Docker），btrfs包含在Linux主线（及mainline，对应于内核有<code>-ml</code>标识的内核）内核中。btrfs驱动利用了很多btrfs特性来作镜像和容器的管理，像块级别的操作、快照的写时复制、精简配置、便于管理，可以轻松的将多个物理块设备组织成一个独立的btrfs文件系统。</p><p>&emsp;使用btrfs存储驱动有些前提条件：</p><ul><li>对于Docker社区版，如果要使用btrfs，那只推荐在Ubuntu和Dibian上使用；</li><li>对于Docker企业版，btrfs只支持SLES；</li><li>更改存储驱动会使已经运行的容器无法访问本地系统，<code>docker save &lt;container-id&gt;</code>可以存储容器并将已有的镜像推送到DockerHub或自定义的仓库，这样之后就不用重新创建了；</li><li>btrfs需要专用的块存储设备，比如物理磁盘，这些块设备必须因此进行格式化并且挂载到<code>var/lib/docker</code>下。默认SLES是已经格式化为btrfs了，不需要进行格式化，因此对于SLES，不需要使用单独的块设备，但是出于性能考虑，也可以选择使用它；</li><li>检验当前系统是否支持btrfs：<code>cat /proc/filesystem | grep btrfs</code>；</li><li>如果需要管理btrfs文件系统，需要安装<code>btrfsprogs</code>或<code>btrfs-tools</code>使用<code>btrfs</code>指令操作；</li></ul><p>&emsp;将btrfs配置为Docker的存储驱动，步骤如下：</p><ol><li>停止docker；</li><li>备份<code>var/lib/docker</code>目录：<code>cp -au var/lib/docker var/lib/docker.bk</code>，然后清空该目录：<code>rm -rf var/lib/docker</code>；</li><li>将块设备格式化为btrfs：<code>mkfs.btrfs -f &lt;块设备&gt;</code>；</li><li>将上面格式化好的设备挂载到<code>/var/lib/docker</code>：<code>mount -t btrfs &lt;块设备&gt; /var/lib/docker</code>；</li><li>将备份的内容复制到<code>var/lib/docker</code>：<code>cp -au var/lib/docker.bk var/lib/docker</code>；</li><li>创建（没有的话手动创建）配置<code>/etc/docker/daemon.json</code>或在已有文件里面添加：<code>&quot;storage-driver&quot;: &quot;btrfs&quot;</code>；</li><li>启动docker验证：<code>docker info</code>；</li><li>若要添加设备到btrfs：<code>btrfs device add &lt;设备&gt; /var/lib/docker</code>，然后<code>btrfs filesystem balance /var/lib/docker</code>；</li></ol><p>&emsp;btrfs驱动的工作原理，镜像和容器可写层都是存储在<code>var/lib/docker/btrfs/subvolumes</code>目录下，每个镜像或者容器可写层都在这个子目录下有一个自己的目录，从一个layer及其所有父级layer构建的统一文件系统，然后这些子卷都是本地写时复制的并且从基础存储池按需分配空间，特们之间可以是嵌套或者直接是一份快照，下面是一个具有4个子卷的图，其中子卷2、3是属于嵌套，而子卷4展示的是他自己内部的目录树：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/btfs_subvolume.jpg" alt="btfs_subvolume"></p><p>只有一个镜像的基础层可以作为一个子卷树存储，所有其他的层都是以快照的形式存储，这些快照仅仅包含在那个引入layer的差异部分，可以创建快照的快照：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/btfs_snapshots.jpg" alt="btfs_snapshots"></p><p>在磁盘上，快照看着就像是子卷，但实际上它们更小并且空间利用率更高，写时复制的策略就是为了最大化存储效率、最小化layer的体积，然后可以让容器可写层内容以块级别被管理，下面就是子卷以及它的快照共享数据的行为：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/btfs_pool.jpg" alt="btfs_pool"></p><p>为了最大化效率，容器需要更多的空间，以大约1GB的块分配，镜像底层的layer以子卷的形式存储，而其子级镜像layer以及容器则是以快照的形式存储，如下：</p><p><img src="https://fastly.jsdelivr.net/gh/Jacksonary/img_bed@main/blog/btfs_container_layer.jpg" alt="btfs_container_layer"></p><p>&emsp;运行btrfs驱动的Docker，它创建镜像或容器的层次为：</p><ol><li>镜像的基础层存储在 btrfs 的子卷下（<code>/var/lib/docker/btrfs/subvolumes</code>）；</li><li>后续的镜像层以 btrfs 快照的形式存储到父级层的子卷或快照下，但是随着这一层的变化，差异存储在块级别；</li><li>容器可写层是最后的layer的btrfs快照，以及运行容器的差异，也是存储在块级别的；</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;存储驱动允许用户在容器的可写层创建数据，但这些数据并不会持久化，随着容器的消亡而消亡，而且存储驱动的赋予这些文件读、写速度都比本地文件系统的性能要慢。&lt;/p&gt;
&lt;h2 id=&quot;1-关于-image-和-layer&quot;&gt;&lt;a href=&quot;#1-关于-image-和-layer&quot; class=&quot;headerlink&quot; title=&quot;1. 关于 image 和 layer&quot;&gt;&lt;/a&gt;1. 关于 image 和 layer&lt;/h2&gt;&lt;p&gt;&amp;emsp;Docker镜像是以一系列的layers为基础构建出来的，镜像中的每个layer都代表着一条指令，除最后一层其他每层都是只读的，所以镜像可以理解为是一个个的只读层堆积起来的。像下面的 Dokcerfile :&lt;/p&gt;
&lt;figure class=&quot;highlight dockerfile&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; ubuntu:&lt;span class=&quot;number&quot;&gt;18.04&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;COPY&lt;/span&gt; . /app&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RUN&lt;/span&gt; make /app&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CMD&lt;/span&gt; python /app/app.py&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Docker" scheme="https://jacksonary.github.io/tags/Docker/"/>
    
      <category term="存储驱动" scheme="https://jacksonary.github.io/tags/%E5%AD%98%E5%82%A8%E9%A9%B1%E5%8A%A8/"/>
    
      <category term="overlay" scheme="https://jacksonary.github.io/tags/overlay/"/>
    
  </entry>
  
  <entry>
    <title>FeignClient问题</title>
    <link href="https://jacksonary.github.io/posts/99b0ef0a.html"/>
    <id>https://jacksonary.github.io/posts/99b0ef0a.html</id>
    <published>2020-03-23T00:43:00.000Z</published>
    <updated>2022-11-08T09:07:57.349Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-主要依赖"><a href="#1-主要依赖" class="headerlink" title="1. 主要依赖"></a>1. 主要依赖</h2><p>&emsp;XXXClient主要依赖的是openfeign：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-openfeign<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.2.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="2-FeignClient不支持PATCH方法"><a href="#2-FeignClient不支持PATCH方法" class="headerlink" title="2. FeignClient不支持PATCH方法"></a>2. FeignClient不支持PATCH方法</h2><p>&emsp;引入httpclient依赖（注意时适配feign-core版本）：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.github.openfeign<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>feign-httpclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>10.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="3-关于服务熔断-hystrix"><a href="#3-关于服务熔断-hystrix" class="headerlink" title="3. 关于服务熔断 hystrix"></a>3. 关于服务熔断 hystrix</h2><p>&emsp;在微服务调用之间，使用FeignClient如果不使用服务熔断，只要xxxClient内部除了异常，调用方得到的信息始终是500（拿不到那些业务相关的异常），为了让xxxClient内部的异常直接抛到调用方，可以如下配置（就算调用方已经定义全局异常处理也不会捕获FeignClient的异常），使用方式如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 在定义client时加入fallbackFactory</span></span><br><span class="line"><span class="meta">@FeignClient</span>(value = <span class="string">"test-client"</span>, url = <span class="string">"http://localhost:8087/gjw-shop"</span>, fallbackFactory = TestFeignErrorFallback.class)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TestClient</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...各种方法</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">fun1</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 定义TestFeignErrorFallback类（建议一个Client定义一个）</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FeignErrorFallback</span> <span class="keyword">implements</span> <span class="title">FallbackFactory</span>&lt;<span class="title">TestClient</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(FeignErrorFallback.class);</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_ERR_MSG = <span class="string">"======= error occurred in server ======="</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TestClient <span class="title">create</span><span class="params">(Throwable throwable)</span> </span>&#123;</span><br><span class="line">        String msg = throwable == <span class="keyword">null</span> ? DEFAULT_ERR_MSG : throwable.getMessage();</span><br><span class="line">        <span class="keyword">if</span> (!StringUtils.isEmpty(msg)) &#123;</span><br><span class="line">            LOG.error(msg);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> TestClient() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fun1</span><span class="params">(Long shopComponentId)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(msg);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 在xxxClient调用方加入服务熔断配置</span></span><br><span class="line"># 开启熔断</span><br><span class="line">feign.hystrix.enabled = <span class="keyword">true</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-主要依赖&quot;&gt;&lt;a href=&quot;#1-主要依赖&quot; class=&quot;headerlink&quot; title=&quot;1. 主要依赖&quot;&gt;&lt;/a&gt;1. 主要依赖&lt;/h2&gt;&lt;p&gt;&amp;emsp;XXXClient主要依赖的是openfeign：&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;spring-cloud-starter-openfeign&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;2.2.2.RELEASE&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Feign" scheme="https://jacksonary.github.io/tags/Feign/"/>
    
      <category term="RPC" scheme="https://jacksonary.github.io/tags/RPC/"/>
    
      <category term="微服务" scheme="https://jacksonary.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Hystrix 配置说明</title>
    <link href="https://jacksonary.github.io/posts/732dbc14.html"/>
    <id>https://jacksonary.github.io/posts/732dbc14.html</id>
    <published>2020-03-20T00:41:00.000Z</published>
    <updated>2022-11-08T09:07:57.352Z</updated>
    
    <content type="html"><![CDATA[<p>openFeign先要开启 hystrix 的请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 开启服务熔断</span><br><span class="line">feign.hystrix.enabled=true</span><br></pre></td></tr></table></figure><p>主要命令有2个：<a id="more"></a></p><ul><li>HystrixCommand：用于真正执行的hystrix命令；</li><li>HystrixObserableCommand：用于监测hystrix命令的执行结果，如果请求有返回结果的话；</li></ul><p>主要流程如下：调用方在发出请求 —&gt; 监测（observe）该请求 –&gt; 查看cache response 是否存在（存在就直接返回） —&gt; 查看断路器 circuit-breaker 是否开启（若开启直接短路请求尝试返回fallback） –&gt; 检测ThreadPool的队列是否已经开始拒绝请求（即线程池的等待队列已满且线程池中达到最大线程数，若已经开始拒绝请求尝试返回fallback） –&gt; 构建 Command 执行。</p><p>hystrix的相关配置有4个级别：</p><ol><li>全局默认配置，用户不手动配置任何属性，直接使用默认值；</li><li>动态配置默认属性，即下面配置都带有<code>default</code>关键字的属性（推荐）；</li><li>代码中的实例属性，示例见下方；</li><li>动态实例属性（推荐，优先级别最高），可以动态设置特定实例的值，这些值将覆盖前面的三个默认级别，如 <code>hystrix.command.HystrixCommandKey.execution.isolation.strategy</code>；</li></ol><p>注： 代码中实例属性示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(<span class="keyword">int</span> value)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HystrixCommandInstance</span><span class="params">(<span class="keyword">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(<span class="string">"ExampleGroup"</span>))</span><br><span class="line">        .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()</span><br><span class="line">               .withExecutionTimeoutInMilliseconds(<span class="number">500</span>)));</span><br><span class="line">    <span class="keyword">this</span>.id = id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HystrixCommandInstance</span><span class="params">(<span class="keyword">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(HystrixCommandGroupKey.Factory.asKey(<span class="string">"ExampleGroup"</span>), <span class="number">500</span>);</span><br><span class="line">    <span class="keyword">this</span>.id = id;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-Command-属性相关属性"><a href="#1-Command-属性相关属性" class="headerlink" title="1. Command 属性相关属性"></a>1. Command 属性相关属性</h2><p>&emsp;以下均为hystrix默认使用的属性，如果不配置该属性，也可以直接动态配置实例属性，即将属性中的<code>default</code>换成<code>HystrixCommandKey</code>即可，如默认属性为 <code>hystrix.command.default.execution.isolation.strategy</code>，那它对应的实例属性就为<code>hystrix.command.HystrixCommandKey.execution.isolation.strategy</code>，其他属性类似。</p><h3 id="1-1-execution相关配置"><a href="#1-1-execution相关配置" class="headerlink" title="1.1 execution相关配置"></a>1.1 execution相关配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># thread 通过线程数量来限制并发请求数，可以提供额外的保护，但有一定的延迟。一般用于网络调用</span><br><span class="line"># semaphore 通过semaphore count来限制并发请求数，适用于无网络的高并发请求</span><br><span class="line"># 默认隔离策略，默认是Thread, 可选 THREAD（推荐，在调用线程之外的另一个线程上单独执行，并发量受限于线程池）｜SEMAPHORE （在调用线程上执行，并发请求受到信号量的限制）</span><br><span class="line">hystrix.command.default.execution.isolation.strategy=THREAD</span><br><span class="line"></span><br><span class="line"># 定义hystrix是否开启超时配置，默认为true</span><br><span class="line">hystrix.command.HystrixCommandKey.execution.timeout.enabled=true</span><br><span class="line"></span><br><span class="line"># 定义hystrix是否允许在超时时允许被打断，默认为true</span><br><span class="line">hystrix.command.default.execution.isolation.thread.interruptOnTimeout=true</span><br><span class="line"></span><br><span class="line"># 定义hystrix是否响应取消操作，默认为false（即hystrix command 在执行时是否可以执行取消行为）</span><br><span class="line">hystrix.command.default.execution.isolation.thread.interruptOnCanc=false</span><br><span class="line"></span><br><span class="line"># 默认调用线程的超时时间（调用方会一直观察该请求直至获取结果或到超时），默认缺省为1000ms</span><br><span class="line">hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000</span><br><span class="line"></span><br><span class="line"># 定义在使用 ExecutionIsolationStrategy.SEMAPHORE 隔离策略时最大允许并发运行的hystrix command命令数（超出的直接丢弃），默认为10</span><br><span class="line">hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests=10</span><br></pre></td></tr></table></figure><h3 id="1-2-fallback相关配置（控制运行-hystrixCommand-getFallback-方法）"><a href="#1-2-fallback相关配置（控制运行-hystrixCommand-getFallback-方法）" class="headerlink" title="1.2 fallback相关配置（控制运行 hystrixCommand.getFallback() 方法）"></a>1.2 fallback相关配置（控制运行 hystrixCommand.getFallback() 方法）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 定义是否在请求失败或被丢弃时尝试去调用getFallback()方法，默认为true</span><br><span class="line">hystrix.command.default.fallback.enabled=true</span><br><span class="line"></span><br><span class="line"># 定义某个调用线程调用hystrixCommand.getFallback()的最大次数，默认为10</span><br><span class="line"># 若达到最大并发请求数，后面的请求将直接被丢弃，此时不会取回定义的fallback</span><br><span class="line">hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests=10</span><br></pre></td></tr></table></figure><h3 id="1-3-断路器-circuit-breaker-相关"><a href="#1-3-断路器-circuit-breaker-相关" class="headerlink" title="1.3 断路器 circuit breaker 相关"></a>1.3 断路器 circuit breaker 相关</h3><p>&emsp;断路器的工作流程如下：</p><ol><li>检测 requestVolumeThreshold 是否达到阈值；</li><li>检测失败请求百分比是否达到 errorThresholdPercentag；</li><li>若1、2只要一个达标，则将断路器的状态置为 OPEN；</li><li>断路器状态为 OPEN，它将拦截到所有后续的请求；</li><li>断路器拦截了指定时间（sleepWindowInMilliseconds）后，它将尝试让1个请求通过（此时断路器处于 HALF-OPEN 半开状态）；</li><li>如果5中释放的那个请求失败了，那断路器健康检测直接返回true，表明断路器处于打开状态，然后重复5步骤；</li><li>如果5中释放的那个请求成功了，则将断路器的闭合状态置成关闭状态，后续的请求又重1步骤开始；</li></ol><p>断路器的各个属性配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 定义是否使用断路器去做断路器的健康检测以及在短路请求时进行跳闸，默认为true</span><br><span class="line"># 这里的健康检测特指hystrix断路器的健康，即检测断路器的开、闭状态</span><br><span class="line">hystrix.command.default.circuitBreaker.enabled=true</span><br><span class="line"></span><br><span class="line"># 定义在一个滚动窗口中触发断路器的最小请求数（阈值），默认为20</span><br><span class="line">hystrix.command.default.circuitBreaker.requestVolumeThreshold=20</span><br><span class="line"></span><br><span class="line"># 定义触发断路器开启的失败请求百分比，默认50，即50%</span><br><span class="line"># X%的请求都失败了就会触发回路短路，此时尝试返回fallback逻辑</span><br><span class="line">hystrix.command.default.circuitBreaker.errorThresholdPercentag=50</span><br><span class="line"></span><br><span class="line"># 定义电路跳闸后拒绝请求的时间，然后允许再次尝试确定电路是否应再次闭合，默认为5000ms</span><br><span class="line">hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds=5000</span><br><span class="line"></span><br><span class="line"># 定义断路器的强制开启状态，默认为false</span><br><span class="line"># 如果为true，它将迫使断路器进入断开（跳闸）状态，在该状态下断路器将拒绝所有请求</span><br><span class="line">hystrix.command.default.circuitBreaker.forceOpen=false</span><br><span class="line"></span><br><span class="line"># 定义断路器的强制关闭状态，默认为false </span><br><span class="line"># 如果为true，它将迫使断路器进入关闭状态，在该状态下断路器将接受所有请求（无论失败请求是否达到触发短路的百分比）</span><br><span class="line">hystrix.command.default.circuitBreaker.forceClosed=false</span><br></pre></td></tr></table></figure><h3 id="1-4-指标-metrics-相关"><a href="#1-4-指标-metrics-相关" class="headerlink" title="1.4  指标 metrics 相关"></a>1.4  指标 metrics 相关</h3><p>&emsp;主要是计算hystrixCommand和HystrixObservableCommand（调用方在请求后会检测请求结果）指标。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 定义统计滚动窗口的持续时间（毫秒），这时间是Hystrix保留断路器使用和发布指标的时间</span><br><span class="line">hystrix.command.default.metrics.rollingStats.timeInMilliseconds=10000</span><br><span class="line"></span><br><span class="line"># 定义滚动统计窗口分为的存储桶数，默认为10</span><br><span class="line"># 注： metrics.rollingStats.timeInMilliseconds % metrics.rollingStats.numBuckets == 0 （否则会抛异常）</span><br><span class="line">hystrix.command.default.metrics.rollingStats.numBuckets=10</span><br><span class="line"></span><br><span class="line"># 定义是否跟踪执行延迟并将其计算为百分数，默认为true</span><br><span class="line"># 若禁用，则所有摘要统计信息（平均值，百分位数）都返回-1</span><br><span class="line">hystrix.command.default.metrics.rollingPercentile.enabled=true</span><br><span class="line"></span><br><span class="line"># 定义滚动窗口的持续时间，在该持续时间中保留执行时间进行百分比计算，默认为60000ms</span><br><span class="line">hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds=60000</span><br><span class="line"></span><br><span class="line"># 定义 rollingPercentile 窗口分割成的桶数，默认为6</span><br><span class="line"># 注：metrics.rollingPercentile.timeInMilliseconds % metrics.rollingPercentile.numBuckets == 0 （否则会抛异常）</span><br><span class="line">hystrix.command.default.metrics.rollingPercentile.numBuckets=6</span><br><span class="line"></span><br><span class="line"># 定义每个存储区保留的最大执行时间，如果在这段时间内发生了更多的执行超出了桶的容量，它们将覆盖存储桶的头部内容</span><br><span class="line"># 如果存储桶大小设置为100，并且表示10秒的存储桶窗口，但10s内发生了500次执行，则在该10秒存储桶中将仅保留最近的100次执行</span><br><span class="line"># 加大这个属性值将会需要更多的内存存储以及更多的时间进行排序</span><br><span class="line">hystrix.command.default.metrics.rollingPercentile.bucketSize=100</span><br><span class="line"></span><br><span class="line"># 定义允许进行运行状况快照之间的等待时间（毫秒），该运行状况快照可计算成功率和错误率百分比并影响断路器状态</span><br><span class="line">hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds=500</span><br></pre></td></tr></table></figure><h3 id="1-5-请求上下文-HystrixRequestContext-相关"><a href="#1-5-请求上下文-HystrixRequestContext-相关" class="headerlink" title="1.5 请求上下文 HystrixRequestContext 相关"></a>1.5 请求上下文 HystrixRequestContext 相关</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 定义HystrixCommand.getCacheKey()是否应与HystrixRequestCache一起使用</span><br><span class="line"># 这样可以通过请求范围的缓存提供重复数据删除功能，默认为true</span><br><span class="line">hystrix.command.default.requestCache.enabled=true</span><br><span class="line"></span><br><span class="line"># 定义是否将HystrixCommand的执行和事件记录到HystrixRequestLog，默认为true</span><br><span class="line">hystrix.command.default.requestLog.enabled=true</span><br></pre></td></tr></table></figure><h2 id="2-请求合并-request-collapser-相关属性"><a href="#2-请求合并-request-collapser-相关属性" class="headerlink" title="2. 请求合并 request collapser 相关属性"></a>2. 请求合并 request collapser 相关属性</h2><p>&emsp;request collapser 是 hystrix 提供批量请求的合并，及多个<code>Command.execute()/queue()</code>合并成一个 Collapser 然后获取线程池中的一个线程去执行，而不是像通常的一个<code>Command.execute()/queue()</code>就各自占用一个线程去执行，这样可以节省网络带宽和减少线程消耗。</p><p>&emsp;控制HystrixCollapser的行为，以下均为hystrix Collapser 默认使用的属性。如果不配置该属性，需要配置实例属性，即将属性中的<code>default</code>换成<code>HystrixCollapserKey</code>即可，如默认属性为 <code>hystrix.collapser.default.maxRequestsInBatch</code>，那它对应的实例属性就为<code>hystrix.collapser.HystrixCollapserKey.maxRequestsInBatch</code>，其他属性类似。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 定义在触发批量请求时允许的最大请求数，默认值 Integer.MAX_VALUE</span><br><span class="line">hystrix.collapser.default.maxRequestsInBatch=Integer.MAX_VALUE</span><br><span class="line"></span><br><span class="line"># 定义在创建批量请求触发时执行的毫秒数</span><br><span class="line">hystrix.collapser.default.timerDelayInMilliseconds=10</span><br><span class="line"></span><br><span class="line"># 设置是否为HystrixCollapser.execute（）和HystrixCollapser.queue（）调用启用请求缓存，默认为true</span><br><span class="line">hystrix.collapser.default.requestCache.enabled=true</span><br></pre></td></tr></table></figure><h2 id="3-线程池ThreadPool相关属性"><a href="#3-线程池ThreadPool相关属性" class="headerlink" title="3. 线程池ThreadPool相关属性"></a>3. 线程池ThreadPool相关属性</h2><p>&emsp;控制Hystrix的ThreadPool属性，hystrix线程池相关概念和Java中的线程池保持一致：核心线程数、最大线程数、队列长度等。以下均为hystrix默认使用的属性，如果不配置该属性，需要配置实例属性，即将属性中的<code>default</code>换成<code>HystrixThreadPoolProperties</code>即可，如 默认属性为 <code>hystrix.threadpool.default.coreSize=10</code>，那它对应的实例属性就为<code>hystrix.threadpool.HystrixThreadPoolProperties.coreSize=10</code>，其他属性类似。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 定义线程池的核心线程数，默认10，它可以处理99%的请求，健康状态下，线程池中通常只有一两个存活的线程去服务40ms的调用</span><br><span class="line"># 该数值若要调大，应匹配公式：健康时每秒请求数的峰值 * 99%的延迟（以秒为单位）+一些缓冲数值（可以适度定义）</span><br><span class="line"># 上述公式的是让线程池尽可能的小，因为线程池是减轻负载并防止资源发生延迟的主要手段</span><br><span class="line"># 当该属性正确配置时，HystrixCommand超时现象应该是极少的，但是还是需要有保护措施来减少网络延迟的影响，尤其是在最坏的情况下，connect + read + retry + connect + read的组合仍会超过配置的总体超时</span><br><span class="line">hystrix.threadpool.default.coreSize=10</span><br><span class="line"></span><br><span class="line"># 定义等待队列的容量，若设为-1则使用SynchronousQueue队列，若为正数则使用LinkedBlockingQueue队列并设置为它的容量</span><br><span class="line"># 注：队列容量在初始化后就不能进行resize了，若期望动态控制队列长度，需要配置 queueSizeRejectionThreshold 属性</span><br><span class="line">hystrix.threadpool.default.maxQueueSize=-1</span><br><span class="line"></span><br><span class="line"># 定义拒绝队列的阈值，默认为5，人为设置的最大队列长度，即使尚未达到 maxQueueSize，也会拒绝请求</span><br><span class="line"># 该属性是为了解决BlockingQueue不能动态resize的问题，所以只有hystrix.threadpool.default.maxQueueSize属性为正值时才生效</span><br><span class="line">hystrix.threadpool.default.queueSizeRejectionThreshold=5</span><br><span class="line"></span><br><span class="line"># 定义线程池中线程的存活时间（分钟），默认为1</span><br><span class="line">hystrix.threadpool.default.keepAliveTimeMinutes=1</span><br><span class="line"></span><br><span class="line"># 定义是否启用 maximumSize 属性，默认为false</span><br><span class="line">hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize=false</span><br><span class="line"># 定义线程池的最大线程数，该数值可以大于等于核心线程数，如果该值大于核心线程数时可以维持 maximumSize 的并发，但在不活跃期间可以返回线程，默认为10</span><br><span class="line"># 该参数只有同时配置了 allowMaximumSizeToDivergeFromCoreSize=true参数才会生效</span><br><span class="line">hystrix.threadpool.default.maximumSize=10</span><br><span class="line"></span><br><span class="line"># 定义统计滚动窗口的持续时间（毫秒），默认为10000</span><br><span class="line">hystrix.threadpool.default.metrics.rollingStats.timeInMilliseconds=10000</span><br><span class="line"># 定义滚动统计窗口划分为的桶数，默认为10</span><br><span class="line"># 注：必须满足条件 metrics.rollingStats.timeInMilliseconds % metrics.rollingStats.numBuckets == 0，否则会抛异常</span><br><span class="line">hystrix.threadpool.default.metrics.rollingStats.numBuckets=10</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;openFeign先要开启 hystrix 的请求：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 开启服务熔断&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;feign.hystrix.enabled=true&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;主要命令有2个：
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hystrix" scheme="https://jacksonary.github.io/tags/Hystrix/"/>
    
      <category term="限流组件" scheme="https://jacksonary.github.io/tags/%E9%99%90%E6%B5%81%E7%BB%84%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>关于Docker的挂载</title>
    <link href="https://jacksonary.github.io/posts/d135925c.html"/>
    <id>https://jacksonary.github.io/posts/d135925c.html</id>
    <published>2020-01-09T02:48:00.000Z</published>
    <updated>2022-11-08T09:07:57.376Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>底层原理不懂就上手，上手出了问题就懵逼，最近在对接阿里云时遇到Docker存储驱动的神坑，爬了几天爬不出来，最后发现是节点中Docker存储驱动的问题，由此引发此次学习，避免类似问题再次懵逼。<br><a id="more"></a></p></blockquote><p>&emsp;关于镜像images，核心首先必须明确一点，<font color="red">镜像都是只读的</font>，如果需要进行写操作，必须在该镜像上创建一个新的镜像层（我们所有的写操作其实都是在一个可写的镜像层上操作的）。同时镜像也是共享的，那些依赖于同一个 image 的多个容器，并不会将单独复制需要的镜像到自己的容器中进行启动，那样会浪费巨大的空间，实际节点上只会有一个镜像，多个容器是共享这一个镜像的。存储驱动可以将容器中的数据进行持久化同时避免性能问题。存储驱动允许我们在容器的可写层创建数据，这些数据在容器销毁后也就没有了，且这些文件的读写速度都比本地文件系统的性能低。</p><p>&emsp;默认情况下，容器内所有创建的文件都存储在一个可写层，所以这些文件仅仅存活于容器运行时，一旦容器被销毁这些文件也会被销毁。容器的可写层和宿主机器紧密耦合，很难将可写层的文件或数据迁移到非宿主机器外的地方。要将数据写入容器的可写层必须要有一个存储驱动（storage driver）来管理文件系统，存储驱动程序使用Linux内核提供的联合文件系统，这种方式与使用直接写入主机文件系统的数据卷相比降低了性能。Docker提供几种种持久化容器中数据或文件的方式：</p><ul><li><code>volumes</code>：Volumes是持久化Docker中数据最好的方式，存在于宿主机器文件系统的一部分（Linux中位于<code>/var/lib/docker/volumes/</code>目录下的<code>xx.db</code>文件），由Docker自己管理，非Docker进程去修改这部分的文件；</li><li><code>bind mounts</code>：这种方式可以将容器中的数据持久化到宿主机器的任何位置（文件或目录），任何进程都可以进行修改</li><li><code>tmpfs mount</code>：Linux 上专用，tmpfs挂载仅存储在主机系统的内存中，永远不会写入主机系统的文件系统；</li><li><code>named pipe</code>：windowns 上专用，同上；</li></ul><p>关于上述的几种方式的区别，官网形象的图文解释：</p><p><img src="https://img-blog.csdnimg.cn/20200109193632702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phY2tzb25hcnk=,size_16,color_FFFFFF,t_70" alt="几种持久化方式"></p><h3 id="1-Volumes（最推荐的挂载方式）"><a href="#1-Volumes（最推荐的挂载方式）" class="headerlink" title="1. Volumes（最推荐的挂载方式）"></a>1. Volumes（最推荐的挂载方式）</h3><p>&emsp;Volumes（数据卷） 由 Docker 自行创建和管理，可以使用<code>docker volume create</code>显式的创建一个Volume，当然如果不人为创建，Docker会在创建容器或服务时自行创建。在使用<code>docker volume create xxx</code>创建 Volume 时，Docker会在宿主机器的<code>/var/lib/docker/volumes/</code>目录下创建<code>xxx</code>文件夹用于容器数据的持久化。当将<code>xxx</code>的Volume挂载到容器上时，此目录就是容器中对应的目录。这种方式和<code>bind mounts</code>很相似，但 Volumes 方式是和宿主机器核心功能隔离并且是由Docker自己管理的。注意<font color="red">同一个Volume是可以同时挂载到多个容器内</font>的，当没有使用该存储卷的容器时，该存储卷并不会自动销毁（因为主要是解决容器可写层数据持久化的问题，当然不会自动销毁），如果需要删除某个存储卷需要手动调用<code>docker volume prune</code>命令，这个命令将会移除所有宿主机器本地的Volumes（谨慎操作）。</p><p>&emsp;当挂载一个 Volume 时，该存储卷可以进行命名或直接匿名，匿名存储卷首次挂载到容器时并不会显式的给它一个名字，而是Docker给它们一个随机名字，且保证该名字是Docker主机中唯一的，匿名和命名的存储卷唯一的区别就是它们名字。</p><p>&emsp;Volumes 是支持 volume driver 的，它允许使用远程主机的存储卷或者其他云供应商提供的数据卷或者其他的存储形式。</p><p>下面是一个示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建数据卷</span></span><br><span class="line">docker volume create testvolumes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 直接拉一个ubuntu镜像来实验</span></span><br><span class="line">docker pull ubuntu</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过 <span class="string">'-v/--volume 存储卷'</span> 的方式即可挂载  /var/lib/docker/volumes/testvolumes:</span></span><br><span class="line">docker run -it -v testvolumes ubuntu:latest</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在容器中的 /testvolumes/_data 目录下创建空文件 addDatas，退出容器并查看宿主机器的 /var/lib/docker/volumes/testvolumes/_data 创建成功</span></span><br><span class="line">touch addDatas</span><br></pre></td></tr></table></figure><p>&emsp;Volum应用场景包含：</p><ul><li>Volume可以让多容器共享的数据（读写或只读），若不显式创建它，会在被挂载前自动创建，Volume只有在显式移除时才会被移除；</li><li>Docker宿主机不具备目录结构或者文件系统，Voulme 可以帮助将Docker宿主机的配置从容器运行时解耦；</li><li>远程存储，这点应该是最广泛的场景，目前很多应用都“上云”，使用的是云提供商或者远程机器，而不是宿主机器本身的存储；</li><li>Volume可以在备份、还原、迁移Dokcer宿主机发挥很人性化的优势，可以先停止使用某个Volume的容器，然后备份Volume（通常目录为<code>/var/lib/docker/volumes/&lt;volume-name&gt;</code>）即可；</li></ul><p>&emsp;Volume 方式有点注意点：</p><ul><li>当将一个空数据卷（volume）挂载到容器中某个已存在的文件或目录时，那么容器该文件或目录中的内容将会被复制到这个空数据卷中；</li><li>当挂载一个不存在的数据卷时，Docker会自动创建一个空的数据卷，这是预先填充另一个容器所需数据的好方法，比如B容器需要一个数据卷VolumeX，他会去检测VolumeX是否存在，那如果A容器在B容器之前启动并且创建了一个VolumeX，那么B的检测就能通过；</li></ul><p>&emsp;数据卷驱动，当创建数据卷<code>docker volume create xxx</code>或启动容器挂载一个还未创建的数据卷时，此时可以指定一个数据卷驱动。下面是一个示例</p><p>&emsp;数据卷 Volume 支持<code>--mount</code>和<code>--volume/-v</code>的语法，当和服务（即swarm services）一起使用数据卷时，仅支持<code>--mount</code>参数，所以官方也是一直推荐使用<code>--mount</code>，完整的示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 单个容器的示例</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建数据卷</span></span><br><span class="line">docker volume create my-vol</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看数据卷列表</span></span><br><span class="line">docker volume ls</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用ubuntu镜像创建一个容器devtest，将数据卷my-vol挂载到目录/app下，并且该数据卷是只读的</span></span><br><span class="line">docker run -d --name devtest --mount src=my-vol,dst=/app,readonly ubuntu:latest</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检查容器信息（注意查看 Mounts 字段是否和期望的一样）</span></span><br><span class="line">docker volume inspect devtest</span><br><span class="line"><span class="meta">#</span><span class="bash"> 移除数据卷</span></span><br><span class="line">docker container stop devtest</span><br><span class="line">docker container rm devtest</span><br><span class="line">docker volume rm my-vol</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 容器服务的示例</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将当前节点进行 swarm 初始化，并且成为master</span></span><br><span class="line">docker swarm init</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建副本为4的service，service仅支持--mount，不支持-v/--volume的形式</span></span><br><span class="line">docker service create -d --replicas=4 --name devtest-service --mount src=my-vol,dst=/app/test ubuntu:latest</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看service的状态</span></span><br><span class="line">docker service ps devtest-service</span><br><span class="line"><span class="meta">#</span><span class="bash"> 移除所有 devtest-service 的task</span></span><br><span class="line">docker service rm devtest-service</span><br></pre></td></tr></table></figure><h3 id="2-Bind-mounts"><a href="#2-Bind-mounts" class="headerlink" title="2. Bind mounts"></a>2. Bind mounts</h3><p>&emsp;Bind mounts （绑定加载）的方式在Dokcer早期版本就提供了，相对于 Volumes 方式功能有限。Bind mounts 就是将宿主机器中一个文件或者目录挂载到容器中，挂载时必须以该文件或目录的绝对路径指定，而且指定的宿主机器上的路径不一定非要在宿主机器上存在，Docker在加载时会去按需创建，而且绑定加载的性能非常好，但它依赖于宿主机器上特定的目录结构。所以目前为官网还是推荐使用数据卷（Volumes）的形式来作存储驱动。此外，bind mounts 不能使用使用Dokcer命令行直接管理这些绑定加载（bind mounts）。</p><p>&emsp;此外 bind mounts 方式必须对一些敏感文件（比如host文件）有权限，可以通过运行在容器中的进程修改（增长改查）系统host文件，这个功能可能会引发安全问题，因为此时Dokcer对宿主机器上非Docker进程甚至系统级别的文件都可以随意更改。</p><p>下面是一个示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 通过 `-v/--volume 宿主机目录:容器目录` 的形式将宿主机器的 /root/helm 目录挂载到容器的 /usr/<span class="built_in">local</span>/helm 目录</span></span><br><span class="line">docker run --volume /root/helm:/usr/local/helm -it ubuntu:latest</span><br></pre></td></tr></table></figure><p>&emsp;绑定挂载适用的场景有：</p><ul><li>给容器共享宿主机上的配置文件，这也是 Docker 通过将宿主机上的<code>/etc/resolv.conf</code>挂载到容器内从而给容器提供的默认DNS策略；</li><li>在开发环境的宿主机器和容器之间共享代码或者构建的jar包、war包，比如对于maven项目，直接将服务模块的<code>target</code>目录绑定挂载到容器中，这样就不需要要在容器内再次构建了；</li><li>当确保Docker主机的文件或目录结构与绑定挂载所需的容器目录一致时；</li></ul><p>&emsp;绑定挂载和数据卷同时有一个注意点，如果将一个非空宿主机目录挂载到容器中已存在的文件或者目录，那么容器内的这些文件或目录将会被宿主机的文件或者目录将会被遮挡，就像你把文件存在宿主机的<code>/mnt</code>目录，然后将一个USB驱动也挂载到<code>/mnt</code>，那此时<code>/mnt</code>目录中的内容将会被USB驱动遮挡直到USB驱动取消挂载，被遮挡的文件或目录并不会被移除或修改，只是使用绑定挂载或者数据卷形式时这些文件是不可得的；</p><h3 id="3-tmpfs-mounts"><a href="#3-tmpfs-mounts" class="headerlink" title="3. tmpfs mounts"></a>3. tmpfs mounts</h3><p>&emsp;<code>tmpfs</code>挂载不会持久化在磁盘上持久化，也不会存储在宿主机器上，可以在容器的生命声明周期内使用，用于存储不需要持久化或者一些敏感信息，典型应用在内部，群集服务使用<code>tmpfs</code>挂载将机密安装到服务的容器中。使用<code>--tmpfs</code>参数进行挂载。</p><p>&emsp;<code>tmpfs</code>挂载适用于那些不需要在宿主机器或容器中持久化数据的场景，比如可能为了安全原因或者是为了在application 需要写大量非持久化数据时保证容器的性能（我觉得这个原因靠谱点）。</p><h3 id="4-named-pipes"><a href="#4-named-pipes" class="headerlink" title="4. named pipes"></a>4. named pipes</h3><p>&emsp;<code>npipe</code>挂载可以用于宿主机器和Docker容器的通信，典型应用就是在容器中运行第三方工具时使用<code>named pipe</code>连接 Docker Engine 的 API。</p><p>注：上述4种挂载方式在语法上不太一样，使用<code>-v/--volume</code>来使用，在17.06+可以不区分挂载方式直接使用<code>--mount</code>进行挂载（本来这个参数是用于 swarm services，而单个容器使用<code>-v/--volume</code>），因为之前使用的 <code>-v/--volume</code> 参数名和数据卷Volume的形式一样，很容易误导开发者是转专用于数据挂载方式的参数，而且对于参数的定义较为严格，使用<code>--mount</code>参数语义更加清晰，诸如：<code>docker run -it --mount source=testvolumes,target=/usr/local/helm ubuntu:latest</code>（前提是建立自己的Volume）。</p><h3 id="5-关于语法"><a href="#5-关于语法" class="headerlink" title="5.关于语法"></a>5.关于语法</h3><h4 id="5-1-v-–volume"><a href="#5-1-v-–volume" class="headerlink" title="5.1 -v/–volume"></a>5.1 -v/–volume</h4><p>&emsp;<code>-v/--volume</code>命令实际是有三个参数的，之间以<code>:</code>分隔，而且必须以规定的顺序出现，三个参数的具体含义为：</p><ul><li>第一个参数：对于有名字的数据卷表示数据卷的名字，该名字必须在宿主机上唯一；对于匿名数据卷，第一个参数需要省略；</li><li>第二个参数：挂载到容器内的路径；</li><li>第三个参数（可选）：是一系列以<code>,</code>分隔的参数；</li></ul><h4 id="5-2-–mount"><a href="#5-2-–mount" class="headerlink" title="5.2 –mount"></a>5.2 –mount</h4><p>&emsp;<code>--mount</code>命令参数是由多个<code>&lt;key&gt;=&lt;value&gt;</code>形式的键值对组成，之间以<code>,</code>分隔，不要求顺序，主要参数的键值对有：</p><ul><li><code>type=xxx</code>：<code>type</code>参数用来表示挂载的方式，value可以是<code>volume</code>、<code>bind</code>或者<code>tmpfs</code>；</li><li><code>source/src=xxx</code>：<code>source</code>或者<code>src</code>参数表示数据卷（有名字的，匿名数据卷该参数省略），value为数据卷的名字；</li><li><code>target/destination/dst=xxx</code>：<code>target</code>或者<code>destination</code>或者<code>dst</code>参数表示内容器的挂载路径，value即为容器内的目录；</li><li><code>readonly</code>：表示绑定挂载是否只读<code>bind mount</code>，如果出现（该字段非键值对），那容器内对该文件/目录只具备读的能力；</li><li><code>volume-opt</code>：表示除上述参数之外的其他参数，可以出现多个<code>volume-opt</code>参数，每个都以键值对的形式出现；</li></ul><p>&emsp;如果数据卷驱动可以接受多个以<code>,</code>分隔的数组，那在传参时必须在CSV编译器检查语法时正常通过，为此用双引号<code>&quot;&quot;</code>将<code>volume-opt</code>这个参数对象包裹起来，然后整个<code>--mount</code>参数对象使用单引号<code>&#39;&#39;</code>包裹，示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> docker service create \</span></span><br><span class="line">     --mount 'type=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;,"volume-opt=o=addr=&lt;nfs-address&gt;,vers=4,soft,timeo=180,bg,tcp,rw"'</span><br><span class="line">    --name myservice \</span><br><span class="line">    &lt;IMAGE&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;底层原理不懂就上手，上手出了问题就懵逼，最近在对接阿里云时遇到Docker存储驱动的神坑，爬了几天爬不出来，最后发现是节点中Docker存储驱动的问题，由此引发此次学习，避免类似问题再次懵逼。&lt;br&gt;
    
    </summary>
    
      <category term="学习" scheme="https://jacksonary.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="docker" scheme="https://jacksonary.github.io/tags/docker/"/>
    
  </entry>
  
</feed>
